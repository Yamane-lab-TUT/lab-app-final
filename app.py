# -*- coding: utf-8 -*-
"""
bennriyasann3_fixed_v2_part1.py
Yamane Lab Convenience Tool - ä¿®æ­£ç‰ˆãƒ‘ãƒ¼ãƒˆ1ï¼ˆå…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»èªè¨¼ãƒ»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ç­‰ï¼‰
"""


import streamlit as st
import gspread
import pandas as pd
import os
import io
import re
import json
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime, date, timedelta
from urllib.parse import quote as url_quote
from io import BytesIO
import calendar
import matplotlib.font_manager as fm

# Google Calendar APIã®ãŸã‚ã®æ–°ã—ã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from datetime import date, datetime
import streamlit as st

# Optional: google cloud client import
try:
    from google.cloud import storage
except Exception:
    storage = None  # GCS ãŒç„¡ã„ç’°å¢ƒã§ã‚‚èµ·å‹•å¯èƒ½

# --- Matplotlib æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ (å®‰å…¨ã«è¨­å®š) ---
try:
    plt.rcParams['font.family'] = 'sans-serif'
    plt.rcParams['font.sans-serif'] = [
        'Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meiryo',
        'TakaoGothic', 'IPAexGothic', 'Noto Sans CJK JP'
    ]
    plt.rcParams['axes.unicode_minus'] = False
except Exception:
    pass

# --- Streamlit ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å±±æ ¹ç ” ä¾¿åˆ©å±‹ã•ã‚“", layout="wide")

# ---------------------------
# --- Global constants ------
# ---------------------------
CLOUD_STORAGE_BUCKET_NAME = "yamane-lab-app-files"  # å¿…è¦ã«å¿œã˜ã¦ç½®ãæ›ãˆã¦ãã ã•ã„
SPREADSHEET_NAME = "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ"

# --- ã‚·ãƒ¼ãƒˆå & ã‚«ãƒ©ãƒ åï¼ˆæ—¢å­˜ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ§‹æˆã«åˆã‚ã›ã¦ã„ã¾ã™ï¼‰ ---
SHEET_EPI_DATA = 'ã‚¨ãƒ”ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿'
EPI_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
EPI_COL_NOTE_TYPE = 'ãƒãƒ¼ãƒˆç¨®åˆ¥'
EPI_COL_CATEGORY = 'ã‚«ãƒ†ã‚´ãƒª'
EPI_COL_MEMO = 'ãƒ¡ãƒ¢'
EPI_COL_FILENAME = 'ãƒ•ã‚¡ã‚¤ãƒ«å'
EPI_COL_FILE_URL = 'å†™çœŸURL'

SHEET_MAINTE_DATA = 'ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿'
MAINT_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
MAINT_COL_NOTE_TYPE = 'ãƒãƒ¼ãƒˆç¨®åˆ¥'
MAINT_COL_MEMO = 'ãƒ¡ãƒ¢'
MAINT_COL_FILENAME = 'ãƒ•ã‚¡ã‚¤ãƒ«å'
MAINT_COL_FILE_URL = 'å†™çœŸURL'

SHEET_MEETING_DATA = 'è­°äº‹éŒ²_ãƒ‡ãƒ¼ã‚¿'
MEETING_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
MEETING_COL_TITLE = 'ä¼šè­°ã‚¿ã‚¤ãƒˆãƒ«'
MEETING_COL_AUDIO_NAME = 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å'
MEETING_COL_AUDIO_URL = 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«URL'
MEETING_COL_CONTENT = 'è­°äº‹éŒ²å†…å®¹'

SHEET_HANDOVER_DATA = 'å¼•ãç¶™ã_ãƒ‡ãƒ¼ã‚¿'
HANDOVER_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
HANDOVER_COL_TYPE = 'ç¨®é¡'
HANDOVER_COL_TITLE = 'ã‚¿ã‚¤ãƒˆãƒ«'
HANDOVER_COL_MEMO = 'ãƒ¡ãƒ¢'

SHEET_QA_DATA = 'çŸ¥æµè¢‹_ãƒ‡ãƒ¼ã‚¿'
QA_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
QA_COL_TITLE = 'è³ªå•ã‚¿ã‚¤ãƒˆãƒ«'
QA_COL_CONTENT = 'è³ªå•å†…å®¹'
QA_COL_CONTACT = 'é€£çµ¡å…ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'
QA_COL_FILENAME = 'æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å'
QA_COL_FILE_URL = 'æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«URL'
QA_COL_STATUS = 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'
SHEET_QA_ANSWER = 'çŸ¥æµè¢‹_è§£ç­”'

SHEET_CONTACT_DATA = 'ãŠå•ã„åˆã‚ã›_ãƒ‡ãƒ¼ã‚¿'
CONTACT_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
CONTACT_COL_TYPE = 'ãŠå•ã„åˆã‚ã›ã®ç¨®é¡'
CONTACT_COL_DETAIL = 'è©³ç´°å†…å®¹'
CONTACT_COL_CONTACT = 'é€£çµ¡å…ˆ'

SHEET_TROUBLE_DATA = 'ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š_ãƒ‡ãƒ¼ã‚¿'
TROUBLE_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
TROUBLE_COL_DEVICE = 'æ©Ÿå™¨/å ´æ‰€'
TROUBLE_COL_OCCUR_DATE = 'ç™ºç”Ÿæ—¥'
TROUBLE_COL_OCCUR_TIME = 'ãƒˆãƒ©ãƒ–ãƒ«ç™ºç”Ÿæ™‚'
TROUBLE_COL_CAUSE = 'åŸå› /ç©¶æ˜'
TROUBLE_COL_SOLUTION = 'å¯¾ç­–/å¾©æ—§'
TROUBLE_COL_PREVENTION = 'å†ç™ºé˜²æ­¢ç­–'
TROUBLE_COL_REPORTER = 'å ±å‘Šè€…'
TROUBLE_COL_FILENAME = 'ãƒ•ã‚¡ã‚¤ãƒ«å'
TROUBLE_COL_FILE_URL = 'ãƒ•ã‚¡ã‚¤ãƒ«URL'
TROUBLE_COL_TITLE = 'ä»¶å/ã‚¿ã‚¤ãƒˆãƒ«'

# --- ç ”ç©¶å®¤ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæ–°ã—ã„ã‚·ãƒ¼ãƒˆãŒå¿…è¦ï¼‰ ---
SHEET_SCHEDULE_DATA = "Schedule"
SCH_COL_TIMESTAMP = "ç™»éŒ²æ—¥æ™‚"
SCH_COL_TITLE = "ã‚¿ã‚¤ãƒˆãƒ«"
SCH_COL_DETAIL = "è©³ç´°"
SCH_COL_START_DATETIME = "é–‹å§‹æ—¥æ™‚"
SCH_COL_END_DATETIME = "çµ‚äº†æ—¥æ™‚"
SCH_COL_USER = "ç™»éŒ²è€…"

try:
    CALENDAR_ID
except NameError:
    # æš«å®šçš„ãªå®šç¾©ï¼ˆã‚¨ãƒ©ãƒ¼é˜²æ­¢ï¼‰
    CALENDAR_ID = "yamane.lab.6747@gmail.com"

# --- äºˆç´„/ä½œæ¥­ã®ã‚«ãƒ†ã‚´ãƒªï¼ˆã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ï¼‰ ---
CATEGORY_OPTIONS = [
    "D1ã‚¨ãƒ”", "D2ã‚¨ãƒ”", "MBEãƒ¡ãƒ³ãƒ†", "XRD", "PL", "AFM", "ãƒ•ã‚©ãƒˆãƒªã‚½", "ã‚¢ãƒ‹ãƒ¼ãƒ«", "è’¸ç€", "ãã®ä»–å…¥åŠ›"
]

# --- Google Calendar APIé€£æºç”¨å®šæ•° ---
# éµãƒ•ã‚¡ã‚¤ãƒ«ã¯ st.secrets ã‹ã‚‰èª­ã¿è¾¼ã‚€ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«åã¯ä¸è¦ã§ã™
SCOPES = ['https://www.googleapis.com/auth/calendar']
CALENDAR_ID = "yamane.lab.6747@gmail.com" # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ID

# ---------------------------
# --- Google Service Stubs ---
# ---------------------------
class DummyGSClient:
    """èªè¨¼å¤±æ•—æ™‚ç”¨ãƒ€ãƒŸãƒ¼ gspread ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def open(self, name): return self
    def worksheet(self, name): return self
    def get_all_records(self): return []
    def get_all_values(self): return []
    def append_row(self, values): pass

class DummyStorageClient:
    """èªè¨¼å¤±æ•—æ™‚ç”¨ãƒ€ãƒŸãƒ¼ GCS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def bucket(self, name): return self
    def blob(self, name): return self
    def upload_from_file(self, file_obj, content_type): pass
    def list_blobs(self, **kwargs): return []

# ã‚°ãƒ­ãƒ¼ãƒãƒ«åˆæœŸå€¤ï¼ˆèªè¨¼ã•ã‚Œã¦ã„ãªã„çŠ¶æ…‹ã§ã‚‚UIã¯èµ·å‹•ã™ã‚‹ï¼‰
gc = DummyGSClient()
storage_client = DummyStorageClient()

# ---------------------------
# --- Google èªè¨¼åˆæœŸåŒ– ---
# ---------------------------
@st.cache_resource(ttl=3600)
def initialize_google_services():
    global storage
    if storage is None:
        # google.cloud.storage ãŒ import ã§ããªã„ç’°å¢ƒ
        st.sidebar.warning("âš ï¸ `google-cloud-storage` ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã¯åˆ¶é™ã•ã‚Œã¾ã™ã€‚")
        return DummyGSClient(), DummyStorageClient()

    if "gcs_credentials" not in st.secrets:
        st.sidebar.info("Streamlit secrets ã« `gcs_credentials` ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§ã‚‚ä¸€éƒ¨æ©Ÿèƒ½ã¯å‹•ãã¾ã™ï¼‰ã€‚")
        return DummyGSClient(), DummyStorageClient()

    try:
        raw = st.secrets["gcs_credentials"]
        # ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
        cleaned = raw.strip().replace('\t', '').replace('\r', '').replace('\n', '')
        info = json.loads(cleaned)
        gc_real = gspread.service_account_from_dict(info)
        storage_real = storage.Client.from_service_account_info(info)
        st.sidebar.success("âœ… Googleã‚µãƒ¼ãƒ“ã‚¹èªè¨¼ æˆåŠŸ")
        return gc_real, storage_real
    except json.JSONDecodeError as e:
        st.sidebar.error(f"èªè¨¼æƒ…å ±ã®JSONãŒä¸æ­£ã§ã™: {e}")
        return DummyGSClient(), DummyStorageClient()
    except Exception as e:
        st.sidebar.error(f"Googleã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return DummyGSClient(), DummyStorageClient()

# å®Ÿéš›ã«åˆæœŸåŒ–ã—ã¦ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚’æ›¸ãæ›ãˆ
gc, storage_client = initialize_google_services()

# ---------------------------
# --- Spreadsheet é–¢é€£ ---
# ---------------------------
@st.cache_data(ttl=600, show_spinner="ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
def get_sheet_as_df(spreadsheet_name, sheet_name):
    global gc
    try:
        if isinstance(gc, DummyGSClient):
            # èªè¨¼ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ç©ºDFã‚’è¿”ã™ï¼ˆUIãƒ†ã‚¹ãƒˆç”¨ï¼‰
            return pd.DataFrame()
        ws = gc.open(spreadsheet_name).worksheet(sheet_name)
        data = ws.get_all_values()
        if not data or len(data) <= 1:
            return pd.DataFrame(columns=data[0] if data else [])
        df = pd.DataFrame(data[1:], columns=data[0])
        return df
    except Exception:
        return pd.DataFrame()

# ---------------------------
# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚³ã‚¢ ---
# ---------------------------
def _load_two_column_data_core(uploaded_bytes, column_names):
    try:
        text = uploaded_bytes.decode('utf-8', errors='ignore').splitlines()
        # ã‚³ãƒ¡ãƒ³ãƒˆ/ç©ºè¡Œã‚’é™¤ã
        data_lines = []
        is_first_data_line = True # ã€è¿½åŠ ã€‘ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹ãŸã‚ã®ãƒ•ãƒ©ã‚°
        for line in text:
            s = line.strip()
            if not s:
                continue
            if s.startswith(('#', '!', '/')):  # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œ
                continue
            
            # ã€ä¿®æ­£ã€‘æœ€åˆã«è¦‹ã¤ã‹ã£ãŸéã‚³ãƒ¡ãƒ³ãƒˆ/éç©ºè¡Œï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡Œï¼‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
            if is_first_data_line:
                is_first_data_line = False
                continue
                
            data_lines.append(line)
            
        if not data_lines:
            return None
        # pandas ã«æ¸¡ã™
        df = pd.read_csv(io.StringIO("\n".join(data_lines)),
                         sep=r'\s+|,|\t', engine='python', header=None)
        if df.shape[1] < 2:
            return None
        df = df.iloc[:, :2]
        df.columns = column_names
        # æ•°å€¤å¤‰æ›
        df[column_names[0]] = pd.to_numeric(df[column_names[0]], errors='coerce')
        df[column_names[1]] = pd.to_numeric(df[column_names[1]], errors='coerce')
        
        # ã€ä¿®æ­£ã€‘å¾€è·¯/å¾©è·¯è§£æã®ãŸã‚ã«ã‚½ãƒ¼ãƒˆï¼ˆ.sort_valuesï¼‰ã‚’å‰Šé™¤ã—ã€dropnaã®ã¿ã‚’è¡Œã†
        df = df.dropna().reset_index(drop=True)
        
        if df.empty:
            return None
        return df
    except Exception:
        # èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯ None ã‚’è¿”ã™ï¼ˆå…ƒã®æŒ™å‹•ã‚’ç¶­æŒï¼‰
        return None
# ---------------------------
# --- IV / PL å°‚ç”¨èª­ã¿è¾¼ã¿ ---
# ---------------------------
@st.cache_data(show_spinner="IVãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­...", max_entries=128)
def load_data_file(uploaded_bytes, uploaded_filename):
    # ä¿®æ­£æ¸ˆã¿: å…¨è§’æ‹¬å¼§ã‚’åŠè§’æ‹¬å¼§ã«ä¿®æ­£
    """IVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ Axis_X ã¨ filename åˆ—ã‚’è¿”ã™ (uploaded_bytes: bytes)"""
    return _load_two_column_data_core(uploaded_bytes, ['Axis_X', uploaded_filename])

@st.cache_data(show_spinner="PLãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­...", max_entries=128)
def load_pl_data(uploaded_file):
    """
    PLãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°ï¼ˆæœ€çµ‚å®‰å®šç‰ˆï¼‰ã€‚
    ã‚³ãƒ¡ãƒ³ãƒˆè¡Œ(#,!,/)ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€ã‚«ãƒ³ãƒãƒ»ã‚¹ãƒšãƒ¼ã‚¹ãƒ»ã‚¿ãƒ–åŒºåˆ‡ã‚Šã™ã¹ã¦ã«å¯¾å¿œã€‚
    ä¾‹: '1, 303' / '1 303' / '1\t303'
    """
    try:
        # èª­ã¿è¾¼ã¿
        content = uploaded_file.getvalue().decode('utf-8', errors='ignore').splitlines()

        # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œãƒ»ç©ºè¡Œã‚¹ã‚­ãƒƒãƒ—
        data_lines = []
        for line in content:
            s = line.strip()
            if not s or s.startswith(('#', '!', '/')):
                continue
            data_lines.append(s)

        if not data_lines:
            st.warning(f"'{uploaded_file.name}' ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return None

        # --- ãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€å½¢å¼ã«æ•´å½¢ ---
        # ã€Œ, ã€ã‚„ã€Œ ,ã€ãªã©ã‚’çµ±ä¸€ã—ã¦ã‚«ãƒ³ãƒã¾ãŸã¯ç©ºç™½ã«å¤‰æ›
        normalized = []
        for line in data_lines:
            # ã‚«ãƒ³ãƒâ†’ã‚¹ãƒšãƒ¼ã‚¹ã«çµ±ä¸€
            line = line.replace(',', ' ')
            # ã‚¿ãƒ–ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«å¤‰æ›
            line = line.replace('\t', ' ')
            # ä½™åˆ†ãªã‚¹ãƒšãƒ¼ã‚¹ã‚’1ã¤ã«
            line = re.sub(r'\s+', ' ', line.strip())
            normalized.append(line)

        df = pd.read_csv(io.StringIO("\n".join(normalized)),
                         sep=' ', header=None, names=['pixel', 'intensity'])

        # æ•°å€¤å¤‰æ›
        df['pixel'] = pd.to_numeric(df['pixel'], errors='coerce')
        df['intensity'] = pd.to_numeric(df['intensity'], errors='coerce')
        df.dropna(inplace=True)

        if df.empty:
            st.warning(f"'{uploaded_file.name}' ã«æœ‰åŠ¹ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return None

        return df

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ï¼š'{uploaded_file.name}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚({e})")
        return None


# ---------------------------
# --- IV ãƒ‡ãƒ¼ã‚¿çµåˆï¼ˆè£œé–“ï¼‰ ---
# ---------------------------
@st.cache_data(show_spinner="IVãƒ‡ãƒ¼ã‚¿ã‚’çµåˆä¸­...", max_entries=64)
def combine_dataframes(dataframes, filenames, num_points=500):
    """
    è¤‡æ•°ã®IVãƒ‡ãƒ¼ã‚¿ã‚’å…±é€šé›»åœ§è»¸ã§ç·šå½¢è£œé–“ã—ã¦çµåˆï¼ˆæ¬ æã‚’ä½œã‚‰ãªã„ï¼‰ã€‚
    - dataframes: list of DataFrame (each has 'Axis_X' and a second column)
    - filenames: list of str (åˆ—åã«ä½¿ç”¨)
    """
    if not dataframes:
        return None

    # å„DFã® Axis_X ã‚’é›†ã‚ã‚‹
    try:
        all_x = np.concatenate([df['Axis_X'].values for df in dataframes if 'Axis_X' in df.columns])
    except Exception:
        return None

    if all_x.size == 0:
        return None

    x_common = np.linspace(all_x.min(), all_x.max(), num_points)
    combined_df = pd.DataFrame({'X_Axis': x_common})

    for df, name in zip(dataframes, filenames):
        # df ã¯ Axis_X, <value> ã®2åˆ—æ§‹æˆã‚’ä»®å®š
        df_sorted = df.sort_values('Axis_X')
        y_vals = df_sorted.iloc[:, 1].values
        x_vals = df_sorted['Axis_X'].values
        # ç·šå½¢è£œé–“ï¼ˆå¢ƒç•Œå¤–ã¯æœ€å¤–ç«¯ã®å€¤ã‚’ä½¿ç”¨ï¼‰
        y_interp = np.interp(x_common, x_vals, y_vals, left=y_vals[0], right=y_vals[-1])
        combined_df[name] = y_interp

    return combined_df

# ---------------------------
# --- ç½²åä»˜ãURLç”Ÿæˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---
# ---------------------------
def generate_signed_url(gcs_path, expiration_minutes=60):
    """
    éå…¬é–‹GCSã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã«å¯¾ã—ã¦ã€æœ‰åŠ¹æœŸé™ä»˜ãã®ç½²åä»˜ãURLã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    if isinstance(storage_client, DummyStorageClient) or storage is None:
        return None

    try:
        bucket_name = CLOUD_STORAGE_BUCKET_NAME
        blob_name = gcs_path
        
        # ç½²åä»˜ãURLã‚’ç”Ÿæˆ
        bucket = storage_client.bucket(bucket_name)
        blob = bucket.blob(blob_name)
        
        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ç½²å
        signed_url = blob.generate_signed_url(
            version="v4",
            # æœ‰åŠ¹æœŸé™: 60åˆ†
            expiration=timedelta(minutes=expiration_minutes), 
            method="GET"
        )
        return signed_url
    except Exception as e:
        st.error(f"ç½²åä»˜ãURLã®ç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None
        
# ---------------------------
# --- GCS ã¸ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ ---
# ---------------------------
def upload_file_to_gcs(uploaded_file, folder_name=""):
    """Streamlitã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã®ãƒ«ãƒ¼ãƒˆã«ä¿å­˜ã—ã€å…¬é–‹URLã‚’è¿”ã™ã€‚"""
    if isinstance(storage_client, DummyStorageClient) or storage is None:
        st.warning("GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒèªè¨¼ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¹ã‚­ãƒƒãƒ—ã€‚")
        return None, None

    try:
        current_time = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_filename = uploaded_file.name.replace("/", "_").replace("\\", "_")

        # ã€ä¿®æ­£ã€‘ãƒ•ã‚©ãƒ«ãƒ€åˆ†ã‘ã‚’ã›ãšã€å¸¸ã«ãƒ«ãƒ¼ãƒˆ ('') ã«ä¿å­˜ã™ã‚‹
        # gcs_filenameã«ã¯ãƒ•ã‚©ãƒ«ãƒ€åã‚’å«ã‚ãªã„
        gcs_filename = f"{current_time}_{safe_filename}"
        
        bucket = storage_client.bucket(CLOUD_STORAGE_BUCKET_NAME)
        blob = bucket.blob(gcs_filename)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ¡ãƒ¢ãƒªã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        blob.upload_from_file(uploaded_file, rewind=True)
        
        # make_public() ã¯ä¸è¦ã€‚éå…¬é–‹ã®ã¾ã¾ã€æ—¢å­˜ã®èªè¨¼æ¸ˆã¿ãƒ­ã‚¸ãƒƒã‚¯ã§ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹
        
        # å…¬é–‹URLã‚’ç”Ÿæˆ
        public_url = f"https://storage.googleapis.com/{CLOUD_STORAGE_BUCKET_NAME}/{url_quote(gcs_filename)}"
        
        return gcs_filename, public_url

    except Exception as e:
        st.error(f"GCSã¸ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None, None

# ---------------------------
# --- GCS ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆå–å¾—ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---
# ---------------------------
def get_note_files_from_gcs(folder_type):
    """
    æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚©ãƒ«ãƒ€ã‚¿ã‚¤ãƒ—ã«å¯¾å¿œã™ã‚‹GCSãƒ‘ã‚¹ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã€‚
    ãƒ«ãƒ¼ãƒˆ ('')ã€ep_notes/ã€mainte_notes/ ã®è¤‡æ•°ãƒ‘ã‚¹ã‚’æ¤œç´¢ã™ã‚‹ã€‚
    Returns: list of (file_name, full_gcs_path, public_url)
    """
    if isinstance(storage_client, DummyStorageClient) or storage is None:
        st.info("GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒèªè¨¼ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return []

    search_prefixes = []
    if folder_type == "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ":
        # ãƒ«ãƒ¼ãƒˆ ('') ã¨ ep_notes/ ã®ä¸¡æ–¹ã‚’æ¤œç´¢
        search_prefixes = ["", "ep_notes/"] 
    elif folder_type == "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ":
        # ãƒ«ãƒ¼ãƒˆ ('') ã¨ mainte_notes/ ã®ä¸¡æ–¹ã‚’æ¤œç´¢
        search_prefixes = ["", "mainte_notes/"] 
    # ãã®ä»–ã®ã‚¿ã‚¤ãƒ—ã‚‚å¿…è¦ã«å¿œã˜ã¦è¿½åŠ 

    all_files = {} # {è¡¨ç¤ºå: (ãƒ•ãƒ«ãƒ‘ã‚¹, URL)}

    try:
        bucket = storage_client.bucket(CLOUD_STORAGE_BUCKET_NAME)
        
        for prefix in search_prefixes:
            # GCS Blobã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆã‚’å–å¾—
            blobs = bucket.list_blobs(prefix=prefix)
            
            for blob in blobs:
                # ãƒ•ã‚©ãƒ«ãƒ€è‡ªä½“ï¼ˆä¾‹: 'ep_notes/'ï¼‰ã¯é™¤å¤–
                if blob.name.endswith('/'):
                    continue
                
                # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å–å¾— (prefixéƒ¨åˆ†ã‚’å‰Šé™¤)
                file_name_display = blob.name.replace(prefix, '')
                
                # ãƒ«ãƒ¼ãƒˆç›´ä¸‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
                if not file_name_display and prefix == "":
                     file_name_display = blob.name

                # public_urlã‚’ä½œæˆ (url_quoteã‚’ä½¿ç”¨)
                public_url = f"https://storage.googleapis.com/{CLOUD_STORAGE_BUCKET_NAME}/{url_quote(blob.name)}"
                
                # åŒã˜ãƒ•ã‚¡ã‚¤ãƒ«åãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã€æ–°ã—ã„ãƒ‘ã‚¹ï¼ˆé€šå¸¸ã¯ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ï¼‰ã‚’å„ªå…ˆ
                if file_name_display not in all_files:
                    all_files[file_name_display] = (blob.name, public_url)

        # ãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚½ãƒ¼ãƒˆã—ã¦è¿”ã™ (list of (file_name, full_gcs_path, public_url))
        # ãƒ•ã‚¡ã‚¤ãƒ«åé †ã®é™é †ã§ã€æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆé€šå¸¸ã¯æ–°ã—ã„ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰ãŒä¸Šã«æ¥ã‚‹ã‚ˆã†ã«ã™ã‚‹
        return sorted([
            (name, path_url[0], path_url[1]) 
            for name, path_url in all_files.items()
        ], key=lambda x: x[0], reverse=True) 

    except Exception as e:
        st.error(f"GCSãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []

# ---------------------------
# --- GCSãƒ•ã‚¡ã‚¤ãƒ«é–²è¦§æ©Ÿèƒ½ ---
# ---------------------------
# ---------------------------
# --- GCSãƒ•ã‚¡ã‚¤ãƒ«é–²è¦§æ©Ÿèƒ½ ---
# ---------------------------
def display_gcs_files(folder_type):
    st.markdown("#### ğŸ“‚ GCS ãƒ•ã‚¡ã‚¤ãƒ«ãƒ–ãƒ©ã‚¦ã‚¶ (ç›´æ¥ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§)")
    st.caption(f"GCSãƒã‚±ãƒƒãƒˆ ({CLOUD_STORAGE_BUCKET_NAME}) ã®ãƒ«ãƒ¼ãƒˆã¨ /{folder_type}/ ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™ã€‚")
    
    # get_note_files_from_gcs ã¯ä»¥å‰ã®ä¿®æ­£ã§å®šç¾©æ¸ˆã¿ã¨ä»®å®š
    file_list = get_note_files_from_gcs(folder_type)

    if not file_list:
        st.info("GCSã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return
        
    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã®ãƒªã‚¹ãƒˆã§é¸æŠãƒœãƒƒã‚¯ã‚¹ã‚’ä½œæˆ
    selected_file_name = st.selectbox(
        f"GCSå†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ (åˆè¨ˆ {len(file_list)} ä»¶)", 
        options=[item[0] for item in file_list],
        key=f"{folder_type}_gcs_browser"
    )
    
    if selected_file_name:
        # é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’æ¤œç´¢ (name, gcs_path, url)
        selected_info = next((item for item in file_list if item[0] == selected_file_name), None)
        
        if selected_info:
            file_name, gcs_path, public_url = selected_info
            
            # **ã€é‡è¦ä¿®æ­£ã€‘éå…¬é–‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã®ãŸã‚ã€ç½²åä»˜ãURLã‚’ç”Ÿæˆ**
            signed_url = generate_signed_url(gcs_path, expiration_minutes=5) # æœ‰åŠ¹æœŸé™5åˆ†
            
            if signed_url is None:
                st.error("èªè¨¼æ¸ˆã¿ã‚¢ã‚¯ã‚»ã‚¹ãƒªãƒ³ã‚¯ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚GCSèªè¨¼è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                return
            
            # --- ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º ---
            st.markdown("---")
            st.markdown(f"**ãƒ•ã‚¡ã‚¤ãƒ«å:** `{file_name}`")
            st.markdown(f"**GCSãƒ‘ã‚¹:** `{gcs_path}`")
            st.warning("â€»ã“ã®ãƒªãƒ³ã‚¯ã¯ç½²åä»˜ãURLã§ã‚ã‚Šã€5åˆ†é–“ã®æœ‰åŠ¹æœŸé™ãŒã‚ã‚Šã¾ã™ã€‚")
            
            # display_attached_files ãŒæœŸå¾…ã™ã‚‹å½¢å¼ã«åˆã‚ã›ã‚‹
            pseudo_row = {
                'url': json.dumps([signed_url]), # ç½²åä»˜ãURLã‚’ä½¿ç”¨
                'filename': json.dumps([file_name])
            }
            
            # display_attached_files(row_dict, col_url_key, col_filename_key)
            display_attached_files(pseudo_row, 'url', 'filename')
        else:
            st.error("ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
# ... (å¾Œç•¥: page_mainte_list ãªã©ã€ä»–ã®ãƒªã‚¹ãƒˆè¡¨ç¤ºé–¢æ•°ã‚‚ã™ã¹ã¦ page_data_list ã‚’å‘¼ã³å‡ºã—ã¦ãŠã‚Šã€page_data_list ãŒ display_attached_files ã‚’å‘¼ã³å‡ºã—ã¦ã„ã‚‹ãŸã‚ã€è‡ªå‹•çš„ã«æ–°ã—ã„è¡¨ç¤ºæ–¹æ³•ãŒé©ç”¨ã•ã‚Œã¾ã™ã€‚) ...

# ---------------------------
# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£å‚ç…§ ---
# ---------------------------
# å‰åŠéƒ¨ã‚’åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ãªã„å ´åˆã¯ import ã§å‘¼ã¶ï¼ˆä¾‹: from bennriyasann3_fixed_v2_part1 import *ï¼‰
# ã“ã“ã§ã¯ã€ŒåŒä¸€å®Ÿè¡Œç’°å¢ƒã«part1ãŒãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã€ã¨ä»®å®šã—ã¾ã™ã€‚

# ---------------------------
# --- æ±ç”¨çš„ãªä¸€è¦§è¡¨ç¤ºé–¢æ•° ---
# ---------------------------
def page_data_list(sheet_name, title, col_time, col_filter=None, col_memo=None, col_url=None, detail_cols=None, col_filename=None):
    """æ±ç”¨çš„ãªãƒ‡ãƒ¼ã‚¿ä¸€è¦§ãƒšãƒ¼ã‚¸"""
    st.header(f"ğŸ“š {title} ä¸€è¦§")
    df = get_sheet_as_df(SPREADSHEET_NAME, sheet_name)

    if df.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    st.subheader("çµã‚Šè¾¼ã¿ã¨æ¤œç´¢")

    # ãƒ•ã‚£ãƒ«ã‚¿åˆ—ãŒã‚ã‚Œã°é¸æŠè‚¢ã‚’è¡¨ç¤º
    if col_filter and col_filter in df.columns:
        df[col_filter] = df[col_filter].fillna('ãªã—')
        options = ["ã™ã¹ã¦"] + sorted(list(df[col_filter].unique()))
        sel = st.selectbox(f"ã€Œ{col_filter}ã€ã§çµã‚Šè¾¼ã¿", options)
        if sel != "ã™ã¹ã¦":
            df = df[df[col_filter] == sel]

    # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åˆ—ãŒã‚ã‚‹å ´åˆï¼‰
    if col_time and col_time in df.columns:
        try:
            df['date_only'] = pd.to_datetime(
                df[col_time].astype(str).str.replace(r'[^0-9]', '', regex=True).str[:8],
                errors='coerce', format='%Y%m%d'
            ).dt.date
        except Exception:
            df['date_only'] = pd.NaT

        df_valid = df.dropna(subset=['date_only'])
        if not df_valid.empty:
            min_date = df_valid['date_only'].min()
            max_date = df_valid['date_only'].max()
            # å­˜åœ¨ã—ãªã„æ—¥ä»˜ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ã™ã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŸã‚ã€é©åˆ‡ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’è¨­å®š
            default_start = min(date(2025, 4, 1), max_date) if isinstance(max_date, date) else date(2025, 4, 1)
            start_date = st.date_input("é–‹å§‹æ—¥", value=max(min_date, default_start) if isinstance(min_date, date) else default_start)
            end_date = st.date_input("çµ‚äº†æ—¥", value=max_date)
            df = df_valid[(df_valid['date_only'] >= start_date) & (df_valid['date_only'] <= end_date)].drop(columns=['date_only'])

    if df.empty:
        st.info("çµã‚Šè¾¼ã¿æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df = df.sort_values(by=col_time, ascending=False).reset_index(drop=True)

    st.markdown("---")
    st.subheader(f"æ¤œç´¢çµæœ ({len(df)} ä»¶)")

    # è¡¨ç¤ºç”¨ã®é¸æŠãƒœãƒƒã‚¯ã‚¹ï¼ˆè¡Œã‚’é¸ã¶ã¨è©³ç´°è¡¨ç¤ºï¼‰
    df['display_index'] = df.index
    def fmt(i):
        row = df.loc[i]
        t = str(row[col_time]) if col_time in row and pd.notna(row[col_time]) else ""
        filt = row[col_filter] if col_filter and col_filter in row and pd.notna(row[col_filter]) else ""
        memo_preview = row[col_memo].split('\n')[0] if col_memo and col_memo in row and pd.notna(row[col_memo]) else ""
        return f"[{t.split('_')[0]}] {filt} - {memo_preview[:50]}"

    sel_idx = st.selectbox("è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹è¨˜éŒ²ã‚’é¸æŠ", options=df['display_index'], format_func=fmt)

    if sel_idx is not None:
        row = df.loc[sel_idx]
        st.markdown(f"#### é¸æŠã•ã‚ŒãŸè¨˜éŒ² (ID: {sel_idx+1})")
        
        # ğŸ‘‡ NameErrorã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€ã“ã“ã§å®šç¾©ã—ã¾ã™
        cols_to_skip = [col_url, col_filename] 
        
        if detail_cols:
            for c in detail_cols:
                # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—ã§ã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
                if c in cols_to_skip:
                    continue
                    
                if c in row and pd.notna(row[c]):
                    # ãƒ¡ãƒ¢ã‚„é•·æ–‡ã¯ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
                    if col_memo == c or 'å†…å®¹' in c or len(str(row[c])) > 200:
                        st.markdown(f"**{c}:**")
                        st.text(row[c])
                    else:
                        st.write(f"**{c}:** {row[c]}")

        # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤º
        if col_url and col_url in row:
            st.markdown("##### æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«")
            display_attached_files(row, col_url, col_filename)
# ---------------------------
# --- ã‚¨ãƒ”ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸ ---
# ---------------------------
# app (4).py: ç´„842è¡Œç›®ã‹ã‚‰
def page_epi_note_recording():
    st.markdown("#### ğŸ“ æ–°ã—ã„ã‚¨ãƒ”ãƒãƒ¼ãƒˆã‚’è¨˜éŒ²")
    
    # ãƒ•ã‚©ãƒ¼ãƒ å…¨ä½“
    with st.form(key='epi_note_form'):
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
        # (ã“ã“ã§ã¯æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã®å†…å®¹ã‚’æ­£ç¢ºã«å†ç¾ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚ä¸è¶³ã—ã¦ã„ã‚‹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‹ã‚‰è£œå®Œã—ã¦ãã ã•ã„)
        
        ep_title = st.text_input("ã‚¿ã‚¤ãƒˆãƒ«/ç•ªå· (ä¾‹: 791)", key="epi_title")
        ep_category = st.selectbox("ã‚«ãƒ†ã‚´ãƒª", ["æ¸¬å®š", "ä½œè£½", "ãƒ‡ãƒ¼ã‚¿æ•´ç†", "ãã®ä»–"], key="epi_category")
        ep_memo = st.text_area("è©³ç´°ãƒ¡ãƒ¢", height=200, key="epi_memo")
        
        uploaded_files = st.file_uploader(
            "æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« (ç”»åƒ, PDF, ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãªã©)", 
            type=None, 
            accept_multiple_files=True,
            key="epi_uploader"
        )
        
        st.markdown("---")
        
        # ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ expaneder (ã”æŒ‡æ‘˜ã®ã‚ã£ãŸã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼ã®ç™ºç”Ÿæº)
        with st.expander("ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"):
            # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ã€ãƒ€ãƒŸãƒ¼ã®å‡¦ç†ã¨ã—ã¦ pass ã‚’æŒ¿å…¥
            pass  
            
        # ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡ãƒœã‚¿ãƒ³
        submit_button = st.form_submit_button("è¨˜éŒ²ã‚’ä¿å­˜") 
        
    # ãƒ•ã‚©ãƒ¼ãƒ ã®å‡¦ç†ã¯ãƒ•ã‚©ãƒ¼ãƒ ã®å¤–å´ã§ã¯ãªãã€submit_button ã®æˆ»ã‚Šå€¤ã§åˆ¶å¾¡
    if submit_button:
        if not ep_title:
            st.warning("ç•ªå· (ä¾‹: 791) ã¯å¿…é ˆé …ç›®ã§ã™ã€‚")
            return
            
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    # ã€ä¿®æ­£æ¸ˆã¿ã€‘ãƒ•ã‚©ãƒ«ãƒ€åå¼•æ•°ã‚’å‰Šé™¤ã—ã€GCSãƒ«ãƒ¼ãƒˆã«ä¿å­˜
                    # storage_clientã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®š
                    filename, url = upload_file_to_gcs(storage_client, file_obj) 
                    
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)
                    else:
                        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_obj.name} ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        memo_content = f"{ep_title}\n{ep_memo}"
        
        # å®šæ•° (EPI_COL_NOTE_TYPE, SHEET_EPI_DATA, SPREADSHEET_NAME) ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®š
        EPI_COL_NOTE_TYPE = "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ" # ä»®ã®å®šæ•°
        SHEET_EPI_DATA = "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ"   # ä»®ã®å®šæ•°
        
        row_data = [timestamp, EPI_COL_NOTE_TYPE, ep_category, memo_content, filenames_json, urls_json]
        
        try:
            # gc ã¯ authenticate_gspread() ã§å–å¾—ã—ãŸã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ä»®å®š
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_EPI_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ã‚¨ãƒ”ãƒãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã¨ãƒªãƒ©ãƒ³ã¯ã€ Streamlit ã®ä»•æ§˜ã«å¾“ã„ã€é©åˆ‡ã«é…ç½®
            if 'st.cache_data' in st.__dict__:
                st.cache_data.clear()
            st.rerun()
            
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_epi_note_list():
    detail_cols = [EPI_COL_TIMESTAMP, EPI_COL_CATEGORY, EPI_COL_NOTE_TYPE, EPI_COL_MEMO, EPI_COL_FILENAME]
    page_data_list(
        sheet_name=SHEET_EPI_DATA,
        title="ã‚¨ãƒ”ãƒãƒ¼ãƒˆ",
        col_time=EPI_COL_TIMESTAMP,
        col_filter=EPI_COL_CATEGORY,
        col_memo=EPI_COL_MEMO,
        col_url=EPI_COL_FILE_URL,
        detail_cols=detail_cols,
        col_filename=EPI_COL_FILENAME
    )

def page_epi_note():
    st.header("ã‚¨ãƒ”ãƒãƒ¼ãƒˆæ©Ÿèƒ½")
    st.markdown("---")
    # æ—¢å­˜ã®tabã‚’ä¿®æ­£ã—ã€ã€ŒGCSé–²è¦§ã€ã‚’è¿½åŠ 
    tab_titles = ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§ (ã‚·ãƒ¼ãƒˆ)", "ğŸ“‚ GCSãƒ•ã‚¡ã‚¤ãƒ«é–²è¦§"]
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", tab_titles, key="epi_tab", horizontal=True)
    
    if tab == "ğŸ“ è¨˜éŒ²":
        page_epi_note_recording()
    elif tab == "ğŸ“š ä¸€è¦§ (ã‚·ãƒ¼ãƒˆ)":
        page_epi_note_list()
    elif tab == "ğŸ“‚ GCSãƒ•ã‚¡ã‚¤ãƒ«é–²è¦§":
        display_gcs_files("ã‚¨ãƒ”ãƒãƒ¼ãƒˆ") # æ–°è¦è¿½åŠ 

# ---------------------------
# --- ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸ ---
# ---------------------------
# app (4).py: ç´„911è¡Œç›®ã‹ã‚‰
def page_mainte_recording():
    st.markdown("#### ğŸ› ï¸ æ–°ã—ã„ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆã‚’è¨˜éŒ²")
    
    # ãƒ•ã‚©ãƒ¼ãƒ å…¨ä½“
    with st.form(key='mainte_note_form'):
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ (æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã«åŸºã¥ãå†ç¾)
        mainte_title = st.text_input("ãƒ¡ãƒ³ãƒ†ã‚¿ã‚¤ãƒˆãƒ« (ä¾‹: ãƒ—ãƒ­ãƒ¼ãƒ–èª¿æ•´)", key="mainte_title")
        mainte_device = st.selectbox("å¯¾è±¡è£…ç½®", ["MOCVD", "IV/PL", "ãã®ä»–"], key="mainte_device")
        memo_content = st.text_area("ä½œæ¥­è©³ç´°ãƒ¡ãƒ¢", height=200, key="mainte_memo")
        
        uploaded_files = st.file_uploader(
            "æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« (ç”»åƒ, PDF, ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãªã©)", 
            type=None, 
            accept_multiple_files=True,
            key="mainte_uploader"
        )
        
        st.markdown("---")
        
        # ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ expaneder (ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼ã®ç™ºç”Ÿæº)
        with st.expander("ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"):
            # ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚¨ãƒ©ãƒ¼å›é¿ã®ãŸã‚ pass ã‚’æŒ¿å…¥
            pass
            
        # ãƒ•ã‚©ãƒ¼ãƒ é€ä¿¡ãƒœã‚¿ãƒ³
        submit_button = st.form_submit_button("è¨˜éŒ²ã‚’ä¿å­˜")
        
    # ãƒ•ã‚©ãƒ¼ãƒ ã®å‡¦ç†
    if submit_button:
        if not mainte_title:
            st.warning("ãƒ¡ãƒ³ãƒ†ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
            
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    # ã€ä¿®æ­£æ¸ˆã¿ã€‘ãƒ•ã‚©ãƒ«ãƒ€åå¼•æ•°ã‚’å‰Šé™¤ã—ã€GCSãƒ«ãƒ¼ãƒˆã«ä¿å­˜
                    filename, url = upload_file_to_gcs(storage_client, file_obj)
                    
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)
                    else:
                        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ« {file_obj.name} ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        
        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        memo_to_save = f"[{mainte_title}]\n{memo_content}"
        
        # å®šæ•° (MAINTE_COL_NOTE_TYPE, SHEET_MAINTE_DATA, SPREADSHEET_NAME) ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«ã«å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®š
        MAINTE_COL_NOTE_TYPE = "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ" # ä»®ã®å®šæ•°
        SHEET_MAINTE_DATA = "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ"   # ä»®ã®å®šæ•°
        
        row_data = [timestamp, MAINTE_COL_NOTE_TYPE, mainte_device, memo_to_save, filenames_json, urls_json]
        
        try:
            # gc ã¯ authenticate_gspread() ã§å–å¾—ã—ãŸã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã¨ä»®å®š
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_MAINTE_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã¨ãƒªãƒ©ãƒ³
            if 'st.cache_data' in st.__dict__:
                st.cache_data.clear()
            st.rerun()
            
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_mainte_list():
    detail_cols = [MAINT_COL_TIMESTAMP, MAINT_COL_NOTE_TYPE, MAINT_COL_MEMO, MAINT_COL_FILENAME]
    page_data_list(
        sheet_name=SHEET_MAINTE_DATA,
        title="ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ",
        col_time=MAINT_COL_TIMESTAMP,
        col_filter=MAINT_COL_NOTE_TYPE,
        col_memo=MAINT_COL_MEMO,
        col_url=MAINT_COL_FILE_URL,
        detail_cols=detail_cols,
        col_filename=MAINT_COL_FILENAME
    )

def page_mainte_note():
    st.header("ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆæ©Ÿèƒ½")
    st.markdown("---")
    # æ—¢å­˜ã®tabã‚’ä¿®æ­£ã—ã€ã€ŒGCSé–²è¦§ã€ã‚’è¿½åŠ 
    tab_titles = ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§ (ã‚·ãƒ¼ãƒˆ)", "ğŸ“‚ GCSãƒ•ã‚¡ã‚¤ãƒ«é–²è¦§"]
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", tab_titles, key="mainte_tab", horizontal=True)
    
    if tab == "ğŸ“ è¨˜éŒ²":
        page_mainte_recording()
    elif tab == "ğŸ“š ä¸€è¦§ (ã‚·ãƒ¼ãƒˆ)":
        page_mainte_list()
    elif tab == "ğŸ“‚ GCSãƒ•ã‚¡ã‚¤ãƒ«é–²è¦§":
        display_gcs_files("ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ") # æ–°è¦è¿½åŠ 

# ---------------------------
# --- è­°äº‹éŒ²ãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_meeting_recording():
    st.markdown("#### ğŸ“ æ–°ã—ã„è­°äº‹éŒ²ã‚’è¨˜éŒ²")
    with st.form(key='meeting_form'):
        meeting_title = st.text_input(f"{MEETING_COL_TITLE} (ä¾‹: 2025-10-28 å®šä¾‹ä¼šè­°)", key='meeting_title_input')
        meeting_content = st.text_area(f"{MEETING_COL_CONTENT}", height=300, key='meeting_content_input')
        col1, col2 = st.columns(2)
        with col1:
            audio_name = st.text_input(f"{MEETING_COL_AUDIO_NAME} (ä¾‹: audio.m4a)", key='audio_name_input')
        with col2:
            audio_url = st.text_input(f"{MEETING_COL_AUDIO_URL} (Google Drive URLãªã©)", key='audio_url_input')
        submit_button = st.form_submit_button(label='è¨˜éŒ²ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜')
    if submit_button:
        if not meeting_title or not meeting_content:
            st.warning("ä¼šè­°ã‚¿ã‚¤ãƒˆãƒ«ã¨è­°äº‹éŒ²å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        row_data = [timestamp, meeting_title, audio_name, audio_url, meeting_content]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_MEETING_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… è­°äº‹éŒ²ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_meeting_list():
    detail_cols = [MEETING_COL_TIMESTAMP, MEETING_COL_TITLE, MEETING_COL_CONTENT, MEETING_COL_AUDIO_NAME, MEETING_COL_AUDIO_URL]
    page_data_list(
        sheet_name=SHEET_MEETING_DATA,
        title="è­°äº‹éŒ²",
        col_time=MEETING_COL_TIMESTAMP,
        col_filter=MEETING_COL_TITLE,
        col_memo=MEETING_COL_CONTENT,
        col_url=MEETING_COL_AUDIO_URL,
        detail_cols=detail_cols,
        col_filename=MEETING_COL_AUDIO_NAME
    )

def page_meeting_note():
    st.header("è­°äº‹éŒ²ãƒ»ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ãƒ¢æ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="meeting_tab", horizontal=True)
    if tab == "ğŸ“ è¨˜éŒ²":
        page_meeting_recording()
    else:
        page_meeting_list()

# ---------------------------
# --- çŸ¥æµè¢‹ãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_qa_recording():
    st.markdown("#### ğŸ’¡ æ–°ã—ã„è³ªå•ã‚’æŠ•ç¨¿")
    with st.form(key='qa_form'):
        qa_title = st.text_input(f"{QA_COL_TITLE} (ä¾‹: XRDã®æ¸¬å®šæ‰‹é †ã«ã¤ã„ã¦)", key='qa_title_input')
        qa_content = st.text_area(f"{QA_COL_CONTENT}", height=200, key='qa_content_input')
        col1, col2 = st.columns(2)
        with col1:
            qa_contact = st.text_input(f"{QA_COL_CONTACT} (ä»»æ„)", key='qa_contact_input')
        with col2:
            uploaded_files = st.file_uploader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], accept_multiple_files=True)
        st.markdown("---")
        submit_button = st.form_submit_button(label='è³ªå•ã‚’æŠ•ç¨¿')
    if submit_button:
        if not qa_title or not qa_content:
            st.warning("è³ªå•ã‚¿ã‚¤ãƒˆãƒ«ã¨è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    filename, url = upload_file_to_gcs(storage_client, file_obj, "qa_files")
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)
        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        row_data = [timestamp, qa_title, qa_content, qa_contact, filenames_json, urls_json, "æœªè§£æ±º"]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_QA_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… è³ªå•ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_qa_list():
    detail_cols = [QA_COL_TIMESTAMP, QA_COL_TITLE, QA_COL_CONTENT, QA_COL_CONTACT, QA_COL_STATUS, QA_COL_FILENAME]
    page_data_list(
        sheet_name=SHEET_QA_DATA,
        title="çŸ¥æµè¢‹ãƒ»è³ªå•ç®±",
        col_time=QA_COL_TIMESTAMP,
        col_filter=QA_COL_STATUS,
        col_memo=QA_COL_CONTENT,
        col_url=QA_COL_FILE_URL,
        detail_cols=detail_cols,
        col_filename=QA_COL_FILENAME
    )

def page_qa_box():
    st.header("çŸ¥æµè¢‹ãƒ»è³ªå•ç®±æ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ’¡ è³ªå•æŠ•ç¨¿", "ğŸ“š è³ªå•ä¸€è¦§"], key="qa_tab", horizontal=True)
    if tab == "ğŸ’¡ è³ªå•æŠ•ç¨¿":
        page_qa_recording()
    else:
        page_qa_list()

# ---------------------------
# --- å¼•ãç¶™ããƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_handover_recording():
    st.markdown("#### ğŸ¤ æ–°ã—ã„å¼•ãç¶™ããƒ¡ãƒ¢ã‚’è¨˜éŒ²")
    with st.form(key='handover_form'):
        handover_type = st.selectbox(f"{HANDOVER_COL_TYPE} (ã‚«ãƒ†ã‚´ãƒª)", ["ãƒãƒ‹ãƒ¥ã‚¢ãƒ«", "è£…ç½®è¨­å®š", "ãã®ä»–ãƒ¡ãƒ¢"])
        handover_title = st.text_input(f"{HANDOVER_COL_TITLE} (ä¾‹: D1 MBEèµ·å‹•æ‰‹é †)", key='handover_title_input')
        handover_memo = st.text_area(f"{HANDOVER_COL_MEMO}", height=150, key='handover_memo_input')
        st.markdown("---")
        submit_button = st.form_submit_button(label='è¨˜éŒ²ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜')
    if submit_button:
        if not handover_title:
            st.warning("ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        row_data = [timestamp, handover_type, handover_title, handover_memo, "", "", ""]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_HANDOVER_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… å¼•ãç¶™ããƒ¡ãƒ¢ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_handover_list():
    detail_cols = [HANDOVER_COL_TIMESTAMP, HANDOVER_COL_TYPE, HANDOVER_COL_TITLE, 'å†…å®¹1', 'å†…å®¹2', 'å†…å®¹3', HANDOVER_COL_MEMO]
    page_data_list(
        sheet_name=SHEET_HANDOVER_DATA,
        title="è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢",
        col_time=HANDOVER_COL_TIMESTAMP,
        col_filter=HANDOVER_COL_TYPE,
        col_memo=HANDOVER_COL_TITLE,
        col_url='å†…å®¹1',
        detail_cols=detail_cols,
        col_filename=None
    )

def page_handover_note():
    st.header("è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢æ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="handover_tab", horizontal=True)
    if tab == "ğŸ“ è¨˜éŒ²":
        page_handover_recording()
    else:
        page_handover_list()

# ---------------------------
# --- ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_trouble_recording():
    st.markdown("#### ğŸš¨ æ–°ã—ã„ãƒˆãƒ©ãƒ–ãƒ«ã‚’å ±å‘Š")
    DEVICE_OPTIONS = ["MBE", "XRD", "PL", "IV", "TEMãƒ»SEM", "æŠµæŠ—åŠ ç†±è’¸ç€", "RTA", "ãƒ•ã‚©ãƒˆãƒªã‚½", "ãƒ‰ãƒ©ãƒ•ã‚¿ãƒ¼", "ãã®ä»–"]
    with st.form(key='trouble_form'):
        st.subheader("åŸºæœ¬æƒ…å ±")
        col1, col2 = st.columns(2)
        with col1:
            report_date = st.date_input(f"{TROUBLE_COL_OCCUR_DATE} (ç™ºç”Ÿæ—¥)", datetime.now().date())
        with col2:
            device_to_save = st.selectbox(f"{TROUBLE_COL_DEVICE} (æ©Ÿå™¨/å ´æ‰€)", DEVICE_OPTIONS, key='device_input')
        report_title = st.text_input(f"{TROUBLE_COL_TITLE} (ä»¶å/ã‚¿ã‚¤ãƒˆãƒ«) (å¿…é ˆ)", key='trouble_title_input')
        occur_time = st.text_area(f"{TROUBLE_COL_OCCUR_TIME} (çŠ¶æ³è©³ç´°)", height=100)
        st.subheader("å¯¾å¿œã¨è€ƒå¯Ÿ")
        cause = st.text_area(f"{TROUBLE_COL_CAUSE} (åŸå› /ç©¶æ˜)", height=100)
        solution = st.text_area(f"{TROUBLE_COL_SOLUTION} (å¯¾ç­–/å¾©æ—§)", height=100)
        prevention = st.text_area(f"{TROUBLE_COL_PREVENTION} (å†ç™ºé˜²æ­¢ç­–)", height=100)
        col3, col4 = st.columns(2)
        with col3:
            reporter_name = st.text_input(f"{TROUBLE_COL_REPORTER} (å ±å‘Šè€…) (å¿…é ˆ)", key='reporter_input')
        with col4:
            uploaded_files = st.file_uploader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], accept_multiple_files=True)
        st.markdown("---")
        submit_button = st.form_submit_button(label='ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šã‚’ä¿å­˜')
    if submit_button:
        if not report_title or not reporter_name:
            st.warning("ã‚¿ã‚¤ãƒˆãƒ«ã¨å ±å‘Šè€…åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    filename, url = upload_file_to_gcs(storage_client, file_obj, "trouble_reports")
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)
        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        row_data = [timestamp, device_to_save, report_date.isoformat(), occur_time, cause, solution, prevention, reporter_name, filenames_json, urls_json, report_title]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_TROUBLE_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_trouble_list():
    detail_cols = [
        TROUBLE_COL_TIMESTAMP, TROUBLE_COL_TITLE, TROUBLE_COL_DEVICE, TROUBLE_COL_OCCUR_DATE,
        TROUBLE_COL_OCCUR_TIME, TROUBLE_COL_CAUSE, TROUBLE_COL_SOLUTION, TROUBLE_COL_PREVENTION,
        TROUBLE_COL_REPORTER, TROUBLE_COL_FILENAME
    ]
    page_data_list(
        sheet_name=SHEET_TROUBLE_DATA,
        title="ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š",
        col_time=TROUBLE_COL_TIMESTAMP,
        col_filter=TROUBLE_COL_DEVICE,
        col_memo=TROUBLE_COL_TITLE,
        col_url=TROUBLE_COL_FILE_URL,
        detail_cols=detail_cols,
        col_filename=TROUBLE_COL_FILENAME
    )

def page_trouble_report():
    st.header("ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šæ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="trouble_tab", horizontal=True)
    if tab == "ğŸ“ è¨˜éŒ²":
        page_trouble_recording()
    else:
        page_trouble_list()

# ---------------------------
# --- é€£çµ¡ãƒ»å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_contact_recording():
    st.markdown("#### âœ‰ï¸ æ–°ã—ã„å•ã„åˆã‚ã›ã‚’è¨˜éŒ²")
    with st.form(key='contact_form'):
        contact_type = st.selectbox(f"{CONTACT_COL_TYPE}", ["ãƒã‚°å ±å‘Š", "æ©Ÿèƒ½è¦æœ›", "ãƒ‡ãƒ¼ã‚¿ä¿®æ­£ä¾é ¼", "ãã®ä»–"])
        contact_detail = st.text_area(f"{CONTACT_COL_DETAIL}", height=150, key='contact_detail_input')
        contact_info = st.text_input(f"{CONTACT_COL_CONTACT} (ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã©ã€ä»»æ„)", key='contact_info_input')
        st.markdown("---")
        submit_button = st.form_submit_button(label='é€ä¿¡')
    if submit_button:
        if not contact_detail:
            st.warning("è©³ç´°å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        row_data = [timestamp, contact_type, contact_detail, contact_info]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_CONTACT_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ãŠå•ã„åˆã‚ã›ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_contact_list():
    detail_cols = [CONTACT_COL_TIMESTAMP, CONTACT_COL_TYPE, CONTACT_COL_DETAIL, CONTACT_COL_CONTACT]
    page_data_list(
        sheet_name=SHEET_CONTACT_DATA,
        title="é€£çµ¡ãƒ»å•ã„åˆã‚ã›",
        col_time=CONTACT_COL_TIMESTAMP,
        col_filter=CONTACT_COL_TYPE,
        col_memo=CONTACT_COL_DETAIL,
        detail_cols=detail_cols
    )

def page_contact_form():
    st.header("é€£çµ¡ãƒ»å•ã„åˆã‚ã›æ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="contact_tab", horizontal=True)
    if tab == "ğŸ“ è¨˜éŒ²":
        page_contact_recording()
    else:
        page_contact_list()

# ---------------------------
# --- IVãƒ‡ãƒ¼ã‚¿è§£æãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_iv_analysis():
    st.header("âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ")
    st.markdown("IVæ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ2åˆ—ãƒ‡ãƒ¼ã‚¿ï¼šXè»¸/Yè»¸ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ã‚½ãƒ¼ãƒˆã›ãšã«å¾€è·¯/å¾©è·¯ã®ç‰¹æ€§ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ã€‚")
    
    uploaded_files = st.file_uploader("IVæ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« (.txt) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['txt'], accept_multiple_files=True)
    if not uploaded_files:
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    data_frames = {}
    file_names = []
    
    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¨è§£æ")
    
    for uploaded_file in uploaded_files:
        # load_data_file ã¯ bytes ã‚’å—ã‘å–ã‚‹ 
        df = load_data_file(uploaded_file.getvalue(), uploaded_file.name)
        if df is not None and not df.empty:
            data_frames[uploaded_file.name] = df
            file_names.append(uploaded_file.name)
        else:
            # èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«åã‚’è¡¨ç¤º
            st.warning(f"{uploaded_file.name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸã‹ã€ãƒ‡ãƒ¼ã‚¿ãŒä¸æ­£ã§ã™ã€‚") 
            
    if not data_frames:
        st.error("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    st.success(f"{len(data_frames)} å€‹ã®æœ‰åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—2: ã‚°ãƒ©ãƒ•è¡¨ç¤º (å¾€è·¯/å¾©è·¯)")
    
    fig, ax = plt.subplots(figsize=(12, 7))
    
    # è»¸ãƒ©ãƒ™ãƒ«ã¯æœ€åˆã®DFã‹ã‚‰å–å¾— (ãƒ‡ãƒ¼ã‚¿ãŒ2åˆ—ã§ã‚ã‚‹ã“ã¨ã‚’å‰æ)
    x_col = data_frames[file_names[0]].columns[0] # Axis_X
    y_col = data_frames[file_names[0]].columns[1] # <ãƒ•ã‚¡ã‚¤ãƒ«å>
    
    for name, df in data_frames.items():
        # Xè»¸ãƒ‡ãƒ¼ã‚¿
        x_data = df.iloc[:, 0] 
        
        # å¾€è·¯/å¾©è·¯ã®åˆ†å‰²ç‚¹ã‚’ç‰¹å®š: Xè»¸ã®æœ€å¤§å€¤ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
        if x_data.empty:
             continue
             
        max_index = x_data.idxmax()

        # å¾€è·¯ (Forward: ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã‹ã‚‰æœ€å¤§å€¤ã¾ã§)
        df_forward = df.iloc[:max_index + 1]
        if not df_forward.empty:
            ax.plot(df_forward.iloc[:, 0], df_forward.iloc[:, 1], 
                    label=f"{name} (å¾€è·¯)", linestyle='-', marker='o', markersize=3, alpha=0.7)

        # å¾©è·¯ (Reverse: æœ€å¤§å€¤ã®æ¬¡ã‹ã‚‰æœ€å¾Œã¾ã§)
        df_reverse = df.iloc[max_index + 1:]
        if not df_reverse.empty:
            ax.plot(df_reverse.iloc[:, 0], df_reverse.iloc[:, 1], 
                    label=f"{name} (å¾©è·¯)", linestyle='--', marker='x', markersize=3, alpha=0.7)

    # ã‚°ãƒ©ãƒ•ã®è£…é£¾
    ax.set_xlabel(x_col)
    ax.set_ylabel(y_col)
    ax.set_title("IVç‰¹æ€§æ¯”è¼ƒ (ã‚½ãƒ¼ãƒˆãªã—ã€å¾€è·¯/å¾©è·¯è¡¨ç¤º)")
    ax.legend(title="ãƒ•ã‚¡ã‚¤ãƒ«å", loc='best')
    ax.grid(True)
    st.pyplot(fig, use_container_width=True)
    plt.close(fig) # ãƒ¡ãƒ¢ãƒªè§£æ”¾
    
    st.info("â€» ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è¦æœ›ã«åŸºã¥ãã€ãƒ‡ãƒ¼ã‚¿çµåˆï¼ˆè£œé–“ï¼‰ãŠã‚ˆã³Xè»¸ã§ã®ã‚½ãƒ¼ãƒˆå‡¦ç†ã¯è¡Œã£ã¦ã„ã¾ã›ã‚“ã€‚")

# ---------------------------
# --- PLãƒ‡ãƒ¼ã‚¿è§£æãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_pl_analysis():
    st.header("ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ")
    st.write("ã‚¹ãƒ†ãƒƒãƒ—1ï¼šæ³¢é•·æ ¡æ­£ï¼ˆ2ç‚¹ï¼‰ â†’ ã‚¹ãƒ†ãƒƒãƒ—2ï¼šæ¸¬å®šãƒ‡ãƒ¼ã‚¿è§£æ ã®é †ã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

    # --- ã‚¹ãƒ†ãƒƒãƒ—1: æ ¡æ­£ ---
    with st.expander("ã‚¹ãƒ†ãƒƒãƒ—1ï¼šæ³¢é•·æ ¡æ­£", expanded=True):
        st.write("2ã¤ã®åŸºæº–æ³¢é•·ã®åå°„å…‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€åˆ†å…‰å™¨ã®å‚¾ãï¼ˆnm/pixelï¼‰ã‚’æ ¡æ­£ã—ã¾ã™ã€‚")
        col1, col2 = st.columns(2)
        with col1:
            cal1_wavelength = st.number_input("åŸºæº–æ³¢é•·1 (nm)", value=1500)
            cal1_file = st.file_uploader(f"{cal1_wavelength} nm ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ« (.txt)", type=['txt'], key="pl_cal1")
        with col2:
            cal2_wavelength = st.number_input("åŸºæº–æ³¢é•·2 (nm)", value=1570)
            cal2_file = st.file_uploader(f"{cal2_wavelength} nm ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ« (.txt)", type=['txt'], key="pl_cal2")

        if st.button("æ ¡æ­£ã‚’å®Ÿè¡Œ", key="run_pl_cal"):
            if not (cal1_file and cal2_file):
                st.warning("ä¸¡æ–¹ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            else:
                df1 = load_pl_data(cal1_file)
                df2 = load_pl_data(cal2_file)
                if df1 is None or df2 is None:
                    st.error("æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãƒ»å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                else:
                    try:
                        peak_pixel1 = df1['pixel'].iloc[df1['intensity'].idxmax()]
                        peak_pixel2 = df2['pixel'].iloc[df2['intensity'].idxmax()]

                        st.write("---")
                        st.subheader("æ ¡æ­£çµæœ")
                        c1, c2, c3 = st.columns(3)
                        c1.metric(f"{cal1_wavelength} nm ã®ãƒ”ãƒ¼ã‚¯ä½ç½®", f"{int(peak_pixel1)} pixel")
                        c2.metric(f"{cal2_wavelength} nm ã®ãƒ”ãƒ¼ã‚¯ä½ç½®", f"{int(peak_pixel2)} pixel")

                        delta_wave = float(cal2_wavelength - cal1_wavelength)
                        delta_pixel = float(peak_pixel1 - peak_pixel2)
                        if delta_pixel == 0:
                            st.error("2ã¤ã®ãƒ”ãƒ¼ã‚¯ä½ç½®ãŒåŒã˜ã§ã™ã€‚ç•°ãªã‚‹æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚")
                        else:
                            slope = delta_wave / delta_pixel
                            c3.metric("æ ¡æ­£ä¿‚æ•° (nm/pixel)", f"{slope:.6f}")
                            st.session_state['pl_calibrated'] = True
                            st.session_state['pl_slope'] = slope
                            st.session_state['pl_center_wl_cal'] = cal1_wavelength
                            st.session_state['pl_center_pixel_cal'] = peak_pixel1
                            st.success("æ ¡æ­£ä¿‚æ•°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒƒãƒ—2ã«é€²ã‚“ã§ãã ã•ã„ã€‚")
                    except Exception as e:
                        st.error(f"æ ¡æ­£è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    st.write("---")
    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—2ï¼šæ¸¬å®šãƒ‡ãƒ¼ã‚¿è§£æ")

    if not st.session_state.get('pl_calibrated', False):
        st.info("ã¾ãšã‚¹ãƒ†ãƒƒãƒ—1ã®æ³¢é•·æ ¡æ­£ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
        return

    # --- ã‚¹ãƒ†ãƒƒãƒ—2: æ¸¬å®šãƒ‡ãƒ¼ã‚¿ã®è§£æ ---
    center_wavelength_input = st.number_input(
        "æ¸¬å®šæ™‚ã®ä¸­å¿ƒæ³¢é•· (nm)", min_value=0, value=1700, step=10,
        help="ã“ã®æ¸¬å®šã§è£…ç½®ã«è¨­å®šã—ãŸä¸­å¿ƒæ³¢é•·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆå‡¡ä¾‹æ•´å½¢ã«ã‚‚åˆ©ç”¨ï¼‰ã€‚"
    )
    uploaded_files = st.file_uploader("æ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['txt'], accept_multiple_files=True, key="pl_measure_files")

    if not uploaded_files:
        st.info("æ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    st.subheader("è§£æçµæœ")
    fig, ax = plt.subplots(figsize=(10, 6))
    all_dataframes = []
    slope = st.session_state['pl_slope']
    center_pixel = 256.5  # ã‚ãªãŸã®æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãã®ã¾ã¾ä½¿ç”¨

    for uploaded_file in uploaded_files:
        df = load_pl_data(uploaded_file)
        if df is None:
            st.warning(f"{uploaded_file.name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        # æ³¢é•·å¤‰æ›
        df['wavelength_nm'] = (df['pixel'] - center_pixel) * slope + center_wavelength_input

        base_name = os.path.splitext(uploaded_file.name)[0]
        cleaned_label = base_name.replace(str(int(center_wavelength_input)), "").strip(' _-')
        label = cleaned_label if cleaned_label else base_name

        ax.plot(df['wavelength_nm'], df['intensity'], label=label, linewidth=2.5)

        export_df = df[['wavelength_nm', 'intensity']].copy()
        export_df.rename(columns={'intensity': base_name}, inplace=True)
        all_dataframes.append(export_df)

    if not all_dataframes:
        st.warning("æœ‰åŠ¹ãªæ¸¬å®šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # çµåˆï¼ˆæ³¢é•·ã‚’ã‚­ãƒ¼ã«å¤–éƒ¨çµåˆï¼‰
    final_df = all_dataframes[0]
    for i in range(1, len(all_dataframes)):
        final_df = pd.merge(final_df, all_dataframes[i], on='wavelength_nm', how='outer')

    final_df = final_df.sort_values(by='wavelength_nm').reset_index(drop=True)

    # ã‚°ãƒ©ãƒ•æ•´å½¢
    ax.set_title(f"PL spectrum (Center: {center_wavelength_input} nm)")
    ax.set_xlabel("Wavelength [nm]")
    ax.set_ylabel("PL intensity [a.u.]")
    ax.legend(loc='upper left', frameon=False, fontsize=10)
    ax.grid(axis='y', linestyle='-', color='lightgray', zorder=0)
    ax.tick_params(direction='in', top=True, right=True, which='both')

    # x ç¯„å›²ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    min_wl = final_df['wavelength_nm'].min()
    max_wl = final_df['wavelength_nm'].max()
    if pd.notna(min_wl) and pd.notna(max_wl) and max_wl > min_wl:
        padding = (max_wl - min_wl) * 0.05
        ax.set_xlim(min_wl - padding, max_wl + padding)

    st.pyplot(fig, use_container_width=True)

    # Excel å‡ºåŠ›ï¼ˆopenpyxl ã‚’ä½¿ç”¨ï¼‰
    output = BytesIO()
    try:
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            final_df.to_excel(writer, index=False, sheet_name='Combined PL Data')
        processed_data = output.getvalue()
        st.download_button(
            label="ğŸ“ˆ Excelãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=processed_data,
            file_name=f"pl_analysis_combined_{center_wavelength_input}nm.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    except Exception as e:
        st.error(f"Excelå‡ºåŠ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# ---------------------------
# --- Google Calendar APIæ¥ç¶šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’è¿½åŠ  ---
# ---------------------------
@st.cache_resource(ttl=3600)
def get_calendar_service():
    """Google Calendar API ã‚µãƒ¼ãƒ“ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—ã™ã‚‹ (page_calendar()ã§ä½¿ç”¨)"""
    if "gcs_credentials" not in st.secrets:
        st.error("Google Calendar APIèªè¨¼æƒ…å ± (`gcs_credentials`) ãŒ Streamlit secrets ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        return None
    try:
        raw = st.secrets["gcs_credentials"]
        # ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
        cleaned = raw.strip().replace('\t', '').replace('\r', '').replace('\n', '')
        info = json.loads(cleaned)

        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼æƒ…å ±ã‚’ä½¿ç”¨ã—ã¦Credentialsã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
        creds = service_account.Credentials.from_service_account_info(info, scopes=SCOPES)
        # Calendar API ã‚µãƒ¼ãƒ“ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ§‹ç¯‰
        service = build('calendar', 'v3', credentials=creds)
        return service
    except json.JSONDecodeError:
        st.error("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼èªè¨¼æƒ…å ±JSONã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        return None
    except Exception as e:
        st.error(f"Google Calendar Serviceã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None
        
# --------------------------
# --- äºˆç´„ãƒ»ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸ï¼ˆæœ€çµ‚èª¿æ•´ç‰ˆï¼‰ ---
# --------------------------
def page_calendar():
# --- 0. ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜ã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º ---
    if 'calendar_success_message' in st.session_state:
        st.success(st.session_state['calendar_success_message'])
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸€åº¦è¡¨ç¤ºã—ãŸã‚‰æ¶ˆå»
        del st.session_state['calendar_success_message']
        
    st.header("ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„")
    
    # --- 1. å¤–éƒ¨äºˆç´„ã‚µã‚¤ãƒˆã¸ã®ãƒªãƒ³ã‚¯ ---
    st.subheader("å¤–éƒ¨äºˆç´„ã‚µã‚¤ãƒˆ")
    
    col_evers, col_rac = st.columns(2)
    
    # Evers äºˆç´„ã‚µã‚¤ãƒˆ
    evers_url = "https://www.eiiris.tut.ac.jp/evers/Web/dashboard.php"
    col_evers.markdown(
        f'<a href="{evers_url}" target="_blank">'
        f'<button style="width:100%; height:40px; background-color:#4CAF50; color:white; border:none; border-radius:5px; cursor:pointer;">'
        f'Evers äºˆç´„ã‚µã‚¤ãƒˆã¸ã‚¢ã‚¯ã‚»ã‚¹</button></a>',
        unsafe_allow_html=True
    )
    col_evers.caption("ï¼ˆå­¦å†…å…±ç”¨è£…ç½®äºˆç´„ã‚·ã‚¹ãƒ†ãƒ ï¼‰")

    # æ•™è‚²ç ”ç©¶åŸºç›¤ã‚»ãƒ³ã‚¿ãƒ¼ äºˆç´„ãƒãƒ¼ã‚¿ãƒ«
    rac_url = "https://tech.rac.tut.ac.jp/regist/potal_0.php"
    col_rac.markdown(
        f'<a href="{rac_url}" target="_blank">'
        f'<button style="width:100%; height:40px; background-color:#2196F3; color:white; border:none; border-radius:5px; cursor:pointer;">'
        f'æ•™è‚²ç ”ç©¶åŸºç›¤ã‚»ãƒ³ã‚¿ãƒ¼ ãƒãƒ¼ã‚¿ãƒ«ã¸</button></a>',
        unsafe_allow_html=True
    )
    col_rac.caption("ï¼ˆå…±ç”¨æ–½è¨­åˆ©ç”¨ç™»éŒ²ï¼‰")

    st.markdown("---")
    
    # --- 2. Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®åŸ‹ã‚è¾¼ã¿ ---
    st.subheader("äºˆç´„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ï¼ˆGoogleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ï¼‰")

    calendar_html = f"""
    <iframe src="https://calendar.google.com/calendar/embed?height=600&wkst=1&bgcolor=%23ffffff&ctz=Asia%2FTokyo&src={CALENDAR_ID}&color=%237986CB&showTitle=0&showPrint=0&showCalendars=0&showTz=0" style="border-width:0" width="100%" height="600" frameborder="0" scrolling="no"></iframe>
    """
    
    st.markdown(calendar_html, unsafe_allow_html=True)
    
    st.caption("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®äºˆç´„çŠ¶æ³ã‚’ç¢ºèªã—ã€ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰äºˆå®šã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")
    st.markdown("---") 
    
    # ------------------------------------------------------------------
    # --- 3. äºˆç´„ç™»éŒ²ã®åˆ¶å¾¡éƒ¨åˆ†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ å¤–: å³æ™‚å¿œç­”ãŒå¿…è¦ãªè¦ç´ ï¼‰ ---
    # ------------------------------------------------------------------
    st.subheader("ğŸ—“ï¸ æ–°è¦äºˆå®šã®ç™»éŒ²")
    
    initial_user_name = st.session_state.get('user_name', '')
    
    # 1. ç™»éŒ²è€…åã‚’ãƒ•ã‚©ãƒ¼ãƒ ã®å¤–ã«é…ç½® (å³æ™‚è¡¨ç¤ºã®ãŸã‚)
    user_name = st.text_input("ç™»éŒ²è€…å / ã‚°ãƒ«ãƒ¼ãƒ—å", value=initial_user_name, key="user_name_outside")
    
    # 2. ã‚«ãƒ†ã‚´ãƒªé¸æŠã¨ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›æ¬„ã‚’ãƒ•ã‚©ãƒ¼ãƒ ã®å¤–ã«é…ç½® (å³æ™‚è¡¨ç¤ºã®ãŸã‚)
    col_cat, col_other = st.columns([1, 2])
    
    with col_cat:
        category = st.selectbox("ä½œæ¥­/è£…ç½®ã‚«ãƒ†ã‚´ãƒª", CATEGORY_OPTIONS, key="category_select_outside")
        
    custom_category = ""
    with col_other:
        # ğŸ’¡ å³æ™‚è¡¨ç¤ºãŒåƒã
        if category == "ãã®ä»–å…¥åŠ›":
            custom_category = st.text_input(
                "ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ†ã‚´ãƒªã‚’ç›´æ¥å…¥åŠ›", 
                placeholder="ä¾‹: å­¦ä¼šç™ºè¡¨æº–å‚™", 
                key="custom_category_input_cal_outside"
            ) 
    
    # 3. æœ€çµ‚ã‚«ãƒ†ã‚´ãƒªåã‚’æ±ºå®š (submitãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã‚‹å‰ã«ç¢ºå®š)
    final_category = custom_category if category == "ãã®ä»–å…¥åŠ›" else category
    
    st.markdown("---") # ãƒ•ã‚©ãƒ¼ãƒ ã¨ã®åŒºåˆ‡ã‚Šç·š
    
    # -----------------------------------------------------
    # --- 4. ãƒ•ã‚©ãƒ¼ãƒ æœ¬ä½“ ---
    # -----------------------------------------------------
    with st.form(key='schedule_form'):
        
        # ğŸ’¡ ãƒ•ã‚©ãƒ¼ãƒ å¤–ã§æ±ºå®šã—ãŸæƒ…å ±ã‚’ã€ãƒ•ã‚©ãƒ¼ãƒ ã®æœ€åˆã§è¡¨ç¤º
        st.markdown(f"**ğŸ“š é¸æŠã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒª:** `{final_category}`") 
        
        # ğŸ’¡ äºˆå®šã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨ˆç®—ã—è¡¨ç¤º
        final_title_preview = f"{user_name} ({final_category})" if user_name and final_category else ""
        st.markdown(f"**ğŸ’¡ äºˆå®šã®ã‚¿ã‚¤ãƒˆãƒ«:** `{final_title_preview}`")

        st.markdown("---")
        
        # 5. é–‹å§‹æ—¥æ™‚ã¨çµ‚äº†æ—¥æ™‚
        st.markdown("##### äºˆå®šæ—¥æ™‚")
        
        cols_start_date, cols_start_time = st.columns(2)
        # st.date_input ã¯ãã®ã¾ã¾
        start_date = cols_start_date.date_input("é–‹å§‹æ—¥", value=date.today())
        
        # â° é–‹å§‹æ™‚åˆ»ã‚’ st.time_input ã«å¤‰æ›´ 
        # time_input ã¯ datetime.time ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™
        start_time_obj = cols_start_time.time_input("é–‹å§‹æ™‚åˆ»", value=datetime.strptime("09:00", '%H:%M').time())

        cols_end_date, cols_end_time = st.columns(2)
        # st.date_input ã¯ãã®ã¾ã¾
        end_date = cols_end_date.date_input("çµ‚äº†æ—¥", value=date.today())
        
        # â° çµ‚äº†æ™‚åˆ»ã‚’ st.time_input ã«å¤‰æ›´
        end_time_obj = cols_end_time.time_input("çµ‚äº†æ™‚åˆ»", value=datetime.strptime("11:00", '%H:%M').time())
        
        # ğŸ’¡ st.time_input ã‚’ä½¿ã£ãŸå ´åˆã€æ™‚åˆ»ã®ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ (time_obj) ã¯æ—¢ã«æ­£ã—ã„å½¢å¼ãªã®ã§ã€
        # å¾Œã® API å‡¦ç†ã§ strftime/strptime ã‚’ä½¿ã‚ãšã«ç›´æ¥ä½¿ãˆã¾ã™ã€‚
        
        # 6. è©³ç´°ï¼ˆãƒ¡ãƒ¢ï¼‰
        detail = st.text_area("è©³ç´°ï¼ˆäºˆå®šã®å†…å®¹ï¼‰", height=100)
        
        submit_button = st.form_submit_button(label='â¬†ï¸ Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«è‡ªå‹•ç™»éŒ²')

        if submit_button:
            # ãƒ•ã‚©ãƒ¼ãƒ å¤–ã® user_name ã¨ final_category ã‚’ä½¿ç”¨
            if not user_name or not final_category:
                st.error("ã€Œç™»éŒ²è€…åã€ã¨ã€Œä½œæ¥­ã‚«ãƒ†ã‚´ãƒªã€ã¯å¿…é ˆã§ã™ã€‚")
                return 
            
            # æœ€çµ‚ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç¢ºå®š
            final_title = f"{user_name} ({final_category})"

            # ----------------------------------------
            # APIçµŒç”±ã§ç›´æ¥ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«æ›¸ãè¾¼ã¿ 
            # ----------------------------------------
            service = get_calendar_service() 
            if service is None:
                return 

            try:
                # â° time_input ã§å–å¾—ã—ãŸ time_obj ã‚’ç›´æ¥ä½¿ç”¨ã™ã‚‹ãŸã‚ã€strptime ã¯ä¸è¦
                start_dt_obj = datetime.combine(start_date, start_time_obj) 
                end_dt_obj = datetime.combine(end_date, end_time_obj)
                
                if end_dt_obj <= start_dt_obj:
                    st.error("çµ‚äº†æ—¥æ™‚ã¯é–‹å§‹æ—¥æ™‚ã‚ˆã‚Šå¾Œã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                    return

                # äºˆå®šã®ãƒœãƒ‡ã‚£ã‚’ä½œæˆ
                event_body = {
                    'summary': final_title,
                    'description': detail,
                    'start': {
                        'dateTime': start_dt_obj.isoformat(),
                        'timeZone': 'Asia/Tokyo',
                    },
                    'end': {
                        'dateTime': end_dt_obj.isoformat(),
                        'timeZone': 'Asia/Tokyo',
                    },
                }

                # APIçµŒç”±ã§äºˆå®šã‚’æŒ¿å…¥
                event = service.events().insert(calendarId=CALENDAR_ID, body=event_body).execute()
                
                # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼åã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state['user_name'] = user_name 
                st.session_state['calendar_success_message'] = f"âœ… äºˆå®š `{final_title}` ãŒã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«è‡ªå‹•ç™»éŒ²ã•ã‚Œã¾ã—ãŸï¼"
                
                # ãƒšãƒ¼ã‚¸å…¨ä½“ã‚’å†å®Ÿè¡Œã—ã€ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼åŸ‹ã‚è¾¼ã¿ã‚’å†ãƒ­ãƒ¼ãƒ‰ã—ã¦æ›´æ–°
                # st.rerun() ã¯ st.success ã®å‰ã«å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒæ®‹ã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã™
                st.rerun()
                    
            except ValueError:
                st.error("æ™‚åˆ»ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒç„¡åŠ¹ã§ã™ã€‚ã€ŒHH:MMã€ã®å½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            except HttpError as e:
                st.error(f"ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ¨©é™ã¨ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼IDã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚è©³ç´°: {e.content.decode()}")
            except Exception as e:
                st.error(f"äºˆå®šã®ç™»éŒ²ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
# ---------------------------
# --- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° ---
# ---------------------------
def main():
    st.sidebar.title("å±±æ ¹ç ” ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ")
    menu_selection = st.sidebar.radio("æ©Ÿèƒ½é¸æŠ", [
        "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ",
        "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ",
        "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„",
        "IVãƒ‡ãƒ¼ã‚¿è§£æ",
        "PLãƒ‡ãƒ¼ã‚¿è§£æ",
        "è­°äº‹éŒ²",
        "çŸ¥æµè¢‹ãƒ»è³ªå•ç®±",
        "è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢",
        "ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š",
        "é€£çµ¡ãƒ»å•ã„åˆã‚ã›",
    ])

    if menu_selection == "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ":
        page_epi_note()
    elif menu_selection == "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ":
        page_mainte_note()
    elif menu_selection == "IVãƒ‡ãƒ¼ã‚¿è§£æ":
        page_iv_analysis()
    elif menu_selection == "PLãƒ‡ãƒ¼ã‚¿è§£æ":
        page_pl_analysis()
    elif menu_selection == "è­°äº‹éŒ²":
        page_meeting_note()
    elif menu_selection == "çŸ¥æµè¢‹ãƒ»è³ªå•ç®±":
        page_qa_box()
    elif menu_selection == "è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢":
        page_handover_note()
    elif menu_selection == "ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š":
        page_trouble_report()
    elif menu_selection == "é€£çµ¡ãƒ»å•ã„åˆã‚ã›":
        page_contact_form()
    elif menu_selection == "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„":
        page_calendar()
    else:
        st.info("é¸æŠã—ãŸæ©Ÿèƒ½ã¯æœªå®Ÿè£…ã§ã™ã€‚")

if __name__ == "__main__":
    main()













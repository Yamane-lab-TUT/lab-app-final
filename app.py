# --------------------------------------------------------------------------
# Yamane Lab Convenience Tool - Streamlit Application (app.py)
#
# v19.0.0 (ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ§‹é€ å®Œå…¨å¯¾å¿œ & IVé«˜é€ŸåŒ–ç‰ˆ)
# --------------------------------------------------------------------------

import streamlit as st
import gspread
import pandas as pd
import os
import io
import re
import json
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime, date, time, timedelta
from urllib.parse import quote as url_quote
from io import BytesIO
import calendar

# Google API client libraries
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from google.cloud import storage
from google.auth.exceptions import DefaultCredentialsError
from google.api_core import exceptions

# --- Global Configuration & Setup ---
st.set_page_config(page_title="å±±æ ¹ç ” ä¾¿åˆ©å±‹ã•ã‚“", layout="wide")

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# â†“â†“â†“â†“â†“â†“ ã€é‡è¦ã€‘ã”è‡ªèº«ã®ã€Œãƒã‚±ãƒƒãƒˆåã€ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ â†“â†“â†“â†“â†“â†“
CLOUD_STORAGE_BUCKET_NAME = "yamane-lab-app-files" # Streamlit Secretsã§è¨­å®šã•ã‚Œã¦ã„ã‚‹GCSãƒã‚±ãƒƒãƒˆå
# â†‘â†‘â†‘â†‘â†‘â†‘ ã€é‡è¦ã€‘ã”è‡ªèº«ã®ã€Œãƒã‚±ãƒƒãƒˆåã€ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ â†‘â†‘â†‘â†‘â†‘â†‘
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

SPREADSHEET_NAME = 'ã‚¨ãƒ”ãƒãƒ¼ãƒˆ' # Google Spreadsheetã®ãƒ•ã‚¡ã‚¤ãƒ«å
CALENDAR_ID = 'primary' # äºˆå®šè¡¨ID ('primary'ã§ãƒ¡ã‚¤ãƒ³äºˆå®šè¡¨)

# --- ã‚¨ãƒ”ãƒãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼å®šç¾©ï¼ˆâ˜…ã“ã“ãŒãŠå®¢æ§˜ã®ã‚·ãƒ¼ãƒˆæ§‹é€ ã«åˆã‚ã›ã¦ã‚ã‚Šã¾ã™â˜…ï¼‰
COLUMN_DATE = 'æ—¥ä»˜' # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ä»£ã‚ã‚Šã«æ—¥ä»˜
COLUMN_EPI_NO = 'ã‚¨ãƒ”ç•ªå·' 
COLUMN_TITLE = 'ã‚¿ã‚¤ãƒˆãƒ«' # ã‚«ãƒ†ã‚´ãƒªã®ä»£ã‚ã‚Šã«ã‚¿ã‚¤ãƒˆãƒ«
COLUMN_DETAIL_MEMO = 'è©³ç´°ãƒ¡ãƒ¢' # ãƒ¡ãƒ¢ã®ä»£ã‚ã‚Šã«è©³ç´°ãƒ¡ãƒ¢
COLUMN_FILENAME = 'ãƒ•ã‚¡ã‚¤ãƒ«å'
COLUMN_FILE_URL = 'ãƒ•ã‚¡ã‚¤ãƒ«URL' # å†™çœŸURLã®ä»£ã‚ã‚Šã«ãƒ•ã‚¡ã‚¤ãƒ«URL

# --- ãƒ¡ã‚¤ãƒ³ãƒ†ãƒãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼å®šç¾© (æ—§æ§‹é€ ã‚’ç¶­æŒ)
MAINT_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
MAINT_COL_TYPE = 'ãƒãƒ¼ãƒˆç¨®åˆ¥'
MAINT_COL_MEMO = 'ãƒ¡ãƒ¢'
MAINT_COL_FILENAME = 'ãƒ•ã‚¡ã‚¤ãƒ«å'
MAINT_COL_FILE_URL = 'å†™çœŸURL'

# --------------------------------------------------------------------------
# --- Google Service Initialization (èªè¨¼å‡¦ç†) ---
# --------------------------------------------------------------------------

class DummyGSClient:
    """èªè¨¼å¤±æ•—æ™‚ç”¨ã®ãƒ€ãƒŸãƒ¼gspreadã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def open(self, name): return self
    def worksheet(self, name): return self
    def get_all_records(self): return []
    def get_all_values(self): return []
    def append_row(self, values): pass
    def batch_update(self, requests): pass
    def update_cells(self, cells): pass

class DummyCalendarService:
    """èªè¨¼å¤±æ•—æ™‚ç”¨ã®ãƒ€ãƒŸãƒ¼ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã‚µãƒ¼ãƒ“ã‚¹"""
    def events(self): return self
    def list(self, **kwargs): return self
    def execute(self): return {'items': []}

class DummyStorageClient:
    """èªè¨¼å¤±æ•—æ™‚ç”¨ã®ãƒ€ãƒŸãƒ¼GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def bucket(self, name): return self
    def blob(self, name): return self
    def download_as_bytes(self): return b''
    def upload_from_file(self, file_obj, content_type): pass
    def get_bucket(self, name): return self
    def list_blobs(self, **kwargs): return []

@st.cache_resource(ttl=3600)
def initialize_google_services():
    """
    Streamlit Secretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã€Googleã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹
    """
    if "gcs_credentials" not in st.secrets:
        st.error("âŒ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: Streamlit Cloudã®Secretsã« `gcs_credentials` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return DummyGSClient(), DummyCalendarService(), DummyStorageClient()

    try:
        # gspread (Spreadsheet) ã®èªè¨¼
        info = json.loads(st.secrets["gcs_credentials"])
        gc = gspread.service_account_from_dict(info)

        # googleapiclient (Calendar) ã®èªè¨¼
        credentials = Credentials.from_service_account_info(info)
        calendar_service = build('calendar', 'v3', credentials=credentials)

        # google.cloud.storage (GCS) ã®èªè¨¼
        storage_client = storage.Client.from_service_account_info(info)

        return gc, calendar_service, storage_client

    except Exception as e:
        st.error(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚èªè¨¼æƒ…å ±ã‚’ã”ç¢ºèªãã ã•ã„ã€‚({e})")
        return DummyGSClient(), DummyCalendarService(), DummyStorageClient()

gc, calendar_service, storage_client = initialize_google_services()

# --------------------------------------------------------------------------
# --- Data Utilities (ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»è§£æ) ---
# --------------------------------------------------------------------------

@st.cache_data(ttl=600, show_spinner="ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
def get_sheet_as_df(gc, spreadsheet_name, sheet_name):
    """æŒ‡å®šã•ã‚ŒãŸã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã¨ã—ã¦å–å¾—ã™ã‚‹"""
    if isinstance(gc, DummyGSClient):
        return pd.DataFrame()
    
    try:
        worksheet = gc.open(spreadsheet_name).worksheet(sheet_name)
        # 1è¡Œç›®ã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿ã‚’è¡Œã®ãƒªã‚¹ãƒˆã¨ã—ã¦å–å¾—
        data = worksheet.get_all_values()
        if not data:
            return pd.DataFrame()
        
        # 1è¡Œç›®ã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã€2è¡Œç›®ä»¥é™ã‚’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦DataFrameã‚’ä½œæˆ
        df = pd.DataFrame(data[1:], columns=data[0])
        return df

    except gspread.exceptions.WorksheetNotFound:
        st.error(f"ã‚·ãƒ¼ãƒˆåã€Œ{sheet_name}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        return pd.DataFrame()
    except Exception as e:
        # ãƒ‡ãƒ¼ã‚¿ãŒç©ºã€ã¾ãŸã¯ãƒ˜ãƒƒãƒ€ãƒ¼åã¨ãƒ‡ãƒ¼ã‚¿ã®åˆ—æ•°ãŒåˆã‚ãªã„ãªã©ã®ã‚¨ãƒ©ãƒ¼
        st.warning(f"è­¦å‘Šï¼šã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ˜ãƒƒãƒ€ãƒ¼ã®ä¸ä¸€è‡´ã‚„ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚({e})")
        return pd.DataFrame()

# --- IVãƒ‡ãƒ¼ã‚¿è§£æç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã§é«˜é€ŸåŒ–) ---
@st.cache_data(show_spinner="IVãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­...", max_entries=50)
def load_iv_data(uploaded_file_bytes, uploaded_file_name):
    """ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸIVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€DataFrameã‚’è¿”ã™"""
    try:
        # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ¡ãƒ¢ãƒªã«èª­ã¿è¾¼ã¿ã€æ–‡å­—åˆ—ã¨ã—ã¦æ‰±ã†
        content = uploaded_file_bytes.decode('utf-8').splitlines()
        
        # æœ€åˆã®1è¡Œï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼: VF(V) IF(A)ãªã©ï¼‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
        data_lines = content[1:]

        # ç©ºè¡Œã‚„ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆ#ãªã©ã§å§‹ã¾ã‚‹ï¼‰è¡Œã‚’ã•ã‚‰ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        cleaned_data_lines = []
        for line in data_lines:
            line_stripped = line.strip()
            # è¡ŒãŒç©ºã§ãªãã€ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã§ãªã‘ã‚Œã°æ¡ç”¨
            if line_stripped and not line_stripped.startswith(('#', '!', '/')):
                cleaned_data_lines.append(line_stripped)

        if not cleaned_data_lines:
            return None

        data_string_io = io.StringIO("\n".join(cleaned_data_lines))
        
        # ãƒ­ãƒã‚¹ãƒˆãªèª­ã¿è¾¼ã¿å‡¦ç†: ã‚¿ãƒ–ã€ã‚¹ãƒšãƒ¼ã‚¹ã€ã¾ãŸã¯ã‚³ãƒ³ãƒåŒºåˆ‡ã‚Šã‚’è©¦ã™
        try:
            df = pd.read_csv(data_string_io, sep='\t', engine='c', header=None)
        except Exception:
            try:
                data_string_io.seek(0)
                df = pd.read_csv(data_string_io, sep=r'\s+', engine='python', header=None) # \s+ã§ã‚¹ãƒšãƒ¼ã‚¹ã¨ã‚¿ãƒ–ã®ä¸¡æ–¹ã«å¯¾å¿œ
            except Exception:
                data_string_io.seek(0)
                df = pd.read_csv(data_string_io, sep=',', engine='python', header=None)

        if df is None or len(df.columns) < 2:
            return None
        
        df = df.iloc[:, :2]
        df.columns = ['Voltage_V', uploaded_file_name] # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’åˆ—åã«ä½¿ç”¨

        # æ•°å€¤å‹ã«å¤‰æ›ã—ã€å¤‰æ›ã§ããªã„è¡Œã¯å‰Šé™¤ (np.float64ã¯äº’æ›æ€§å•é¡Œã‚’å›é¿ã™ã‚‹æ¨å¥¨å‹)
        df['Voltage_V'] = pd.to_numeric(df['Voltage_V'], errors='coerce', downcast='float')
        df[uploaded_file_name] = pd.to_numeric(df[uploaded_file_name], errors='coerce', downcast='float')
        df.dropna(inplace=True)
        
        return df

    except Exception:
        return None

@st.cache_data(show_spinner="ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆä¸­...")
def combine_iv_dataframes(dataframes, filenames):
    """è¤‡æ•°ã®IV DataFrameã‚’Voltage_Vã‚’ã‚­ãƒ¼ã«å¤–éƒ¨çµåˆã™ã‚‹"""
    if not dataframes:
        return None
    
    combined_df = dataframes[0]
    
    for i in range(1, len(dataframes)):
        df_to_merge = dataframes[i]
        combined_df = pd.merge(combined_df, df_to_merge, on='Voltage_V', how='outer')
        
    combined_df = combined_df.sort_values(by='Voltage_V', ascending=False).reset_index(drop=True)
    
    # é›»æµå€¤ã®ä¸¸ã‚è¾¼ã¿ (è¡¨ç¤ºã®æ•´ç†ã®ãŸã‚)
    for col in combined_df.columns:
        if col != 'Voltage_V':
            combined_df[col] = combined_df[col].round(4)
            
    return combined_df

# --------------------------------------------------------------------------
# --- GCS Utilities (ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰) ---
# --------------------------------------------------------------------------

def upload_file_to_gcs(storage_client, file_obj, folder_name):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€å…¬é–‹URLã‚’è¿”ã™"""
    if isinstance(storage_client, DummyStorageClient):
        return None, "dummy_url_gcs_error"
        
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    original_filename = file_obj.name
    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’æŠ½å‡º
    name_parts = os.path.splitext(original_filename)
    # GCSä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«åï¼š {ãƒ•ã‚©ãƒ«ãƒ€å}/{ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—}_{ãƒ•ã‚¡ã‚¤ãƒ«å}
    gcs_filename = f"{folder_name}/{timestamp}_{original_filename}"

    try:
        bucket = storage_client.bucket(CLOUD_STORAGE_BUCKET_NAME)
        blob = bucket.blob(gcs_filename)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ãã®ã¾ã¾ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        file_obj.seek(0)
        blob.upload_from_file(file_obj, content_type=file_obj.type)

        # å…¬é–‹ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½ãªURLã‚’è¿”ã™ï¼ˆé©åˆ‡ãªè¨­å®šãŒå¿…è¦ï¼‰
        public_url = f"https://storage.googleapis.com/{CLOUD_STORAGE_BUCKET_NAME}/{url_quote(gcs_filename)}"
        
        return original_filename, public_url

    except exceptions.NotFound:
        st.error(f"âŒ GCSã‚¨ãƒ©ãƒ¼: ãƒã‚±ãƒƒãƒˆå '{CLOUD_STORAGE_BUCKET_NAME}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None, None
    except Exception as e:
        st.error(f"âŒ GCSã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚({e})")
        return None, None

# --------------------------------------------------------------------------
# --- Page Definitions (å„æ©Ÿèƒ½ãƒšãƒ¼ã‚¸) ---
# --------------------------------------------------------------------------

def page_note_recording(sheet_name='ã‚¨ãƒ”ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿', is_mainte=False):
    """ã‚¨ãƒ”ãƒãƒ¼ãƒˆãƒ»ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆè¨˜éŒ²ãƒšãƒ¼ã‚¸"""
    
    if is_mainte:
        st.header("ğŸ› ï¸ ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆè¨˜éŒ²")
        sheet_name = 'ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿'
    else:
        st.header("ğŸ“ ã‚¨ãƒ”ãƒãƒ¼ãƒˆè¨˜éŒ²")
    
    st.markdown("---")
    
    # è¨˜éŒ²ãƒ•ã‚©ãƒ¼ãƒ 
    with st.form(key='note_form'):
        
        # ã‚¨ãƒ”ãƒãƒ¼ãƒˆå›ºæœ‰ã®é …ç›® (is_mainte=False ã®ã¨ãã®ã¿)
        if not is_mainte:
            col1, col2 = st.columns(2)
            with col1:
                ep_date = st.date_input(f"{COLUMN_DATE}", datetime.now().date())
                ep_no = st.text_input(f"{COLUMN_EPI_NO} (ä¾‹: 784-A)", key='ep_no_input')
            with col2:
                ep_title = st.text_input(f"{COLUMN_TITLE} (ä¾‹: PLæ¸¬å®š)", key='ep_title_input')

        # ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆå›ºæœ‰ã®é …ç›® (is_mainte=True ã®ã¨ãã®ã¿)
        if is_mainte:
            mainte_type = st.selectbox(f"{MAINT_COL_TYPE} (è£…ç½®/å†…å®¹)", [
                "ãƒ‰ãƒ©ã‚¤ãƒãƒ³ãƒ—äº¤æ›", "ãƒ‰ãƒ©ã‚¤ãƒãƒ³ãƒ—ãƒ¡ãƒ³ãƒ†", "ã‚ªã‚¤ãƒ«äº¤æ›", "ãƒ’ãƒ¼ã‚¿ãƒ¼äº¤æ›", "ãã®ä»–"
            ])

        # å…±é€šé …ç›®
        memo_content = st.text_area(f"{COLUMN_DETAIL_MEMO} / {MAINT_COL_MEMO}", height=150, key='memo_input')
        uploaded_files = st.file_uploader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« (ç”»åƒã€ã‚°ãƒ©ãƒ•ãªã©)", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], accept_multiple_files=True)
        
        st.markdown("---")
        submit_button = st.form_submit_button(label='è¨˜éŒ²ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜')

    if submit_button:
        if not memo_content and not uploaded_files:
            st.warning("ãƒ¡ãƒ¢å†…å®¹ã‚’å…¥åŠ›ã™ã‚‹ã‹ã€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            return
        
        # 1. GCSã¸ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨URLå–å¾—
        filenames_list = []
        urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                folder_name = "ep_notes" if not is_mainte else "mainte_notes"
                for file_obj in uploaded_files:
                    filename, url = upload_file_to_gcs(storage_client, file_obj, folder_name)
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)

        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y/%m/%d %H:%M:%S")

        # 2. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¡Œã‚’è¿½åŠ 
        if not is_mainte:
            # ã‚¨ãƒ”ãƒãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼é †: ['æ—¥ä»˜', 'ã‚¨ãƒ”ç•ªå·', 'ã‚¿ã‚¤ãƒˆãƒ«', 'è©³ç´°ãƒ¡ãƒ¢', 'ãƒ•ã‚¡ã‚¤ãƒ«å', 'ãƒ•ã‚¡ã‚¤ãƒ«URL']
            row_data = [
                ep_date.isoformat(), ep_no, ep_title, 
                memo_content, filenames_json, urls_json
            ]
        else:
            # ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆã®ãƒ˜ãƒƒãƒ€ãƒ¼é †: ['ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—', 'ãƒãƒ¼ãƒˆç¨®åˆ¥', 'ãƒ¡ãƒ¢', 'ãƒ•ã‚¡ã‚¤ãƒ«å', 'å†™çœŸURL']
            row_data = [
                timestamp, mainte_type, 
                memo_content, filenames_json, urls_json
            ]
        
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(sheet_name)
            worksheet.append_row(row_data)
            st.success("è¨˜éŒ²ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼"); st.cache_data.clear(); st.rerun() # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã¨å†å®Ÿè¡Œ
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ãƒ¼ãƒˆå '{sheet_name}' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.exception(e)

def page_note_list(sheet_name='ã‚¨ãƒ”ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿', is_mainte=False):
    """ã‚¨ãƒ”ãƒãƒ¼ãƒˆãƒ»ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆä¸€è¦§ãƒšãƒ¼ã‚¸"""
    
    if is_mainte:
        st.header("ğŸ› ï¸ ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆä¸€è¦§")
        sheet_name = 'ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿'
        COL_TIME = MAINT_COL_TIMESTAMP
        COL_FILTER = MAINT_COL_TYPE
        COL_MEMO = MAINT_COL_MEMO
        COL_URL = MAINT_COL_FILE_URL
    else:
        st.header("ğŸ“š ã‚¨ãƒ”ãƒãƒ¼ãƒˆä¸€è¦§")
        sheet_name = 'ã‚¨ãƒ”ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿'
        COL_TIME = COLUMN_DATE # æ—¥ä»˜ã‚’ãƒ™ãƒ¼ã‚¹ã«çµã‚Šè¾¼ã¿
        COL_FILTER = COLUMN_TITLE # ã‚¿ã‚¤ãƒˆãƒ«ã§çµã‚Šè¾¼ã¿
        COL_MEMO = COLUMN_DETAIL_MEMO # è©³ç´°ãƒ¡ãƒ¢ã‚’è¡¨ç¤º
        COL_URL = COLUMN_FILE_URL
    
    df = get_sheet_as_df(gc, SPREADSHEET_NAME, sheet_name)

    if df.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
        
    st.subheader("çµã‚Šè¾¼ã¿ã¨æ¤œç´¢")
    
    # çµã‚Šè¾¼ã¿ UI (â˜…ä¿®æ­£ç®‡æ‰€: COLUMN_TITLEã‚’ä½¿ç”¨â˜…)
    if COL_FILTER in df.columns:
        filter_options = ["ã™ã¹ã¦"] + list(df[COL_FILTER].unique())
        note_filter = st.selectbox(f"{COL_FILTER}ã§çµã‚Šè¾¼ã¿", filter_options)
        
        if note_filter != "ã™ã¹ã¦":
            df = df[df[COL_FILTER] == note_filter]

    # æ—¥ä»˜æ¤œç´¢
    col_date1, col_date2 = st.columns(2)
    with col_date1:
        start_date = st.date_input("é–‹å§‹æ—¥", value=datetime.now().date() - timedelta(days=30))
    with col_date2:
        end_date = st.date_input("çµ‚äº†æ—¥", value=datetime.now().date())
    
    try:
        df[COL_TIME] = pd.to_datetime(df[COL_TIME]).dt.date
        df = df[(df[COL_TIME] >= start_date) & (df[COL_TIME] <= end_date)]
    except:
        st.warning("æ—¥ä»˜ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼‰åˆ—ã®å½¢å¼ãŒä¸æ­£ãªè¡ŒãŒã‚ã‚Šã¾ã™ã€‚")

    if df.empty:
        st.info("çµã‚Šè¾¼ã¿æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # æœ€æ–°ã®ã‚‚ã®ã‚’ä¸Šã«è¡¨ç¤º
    df = df.sort_values(by=COL_TIME, ascending=False).reset_index(drop=True)
    
    st.markdown("---")
    st.subheader(f"æ¤œç´¢çµæœ ({len(df)}ä»¶)")

    # ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ãƒªã‚¹ãƒˆã®ä½œæˆ
    # â˜…ä¿®æ­£ç®‡æ‰€: COL_MEMOï¼ˆè©³ç´°ãƒ¡ãƒ¢ï¼‰ã‚’ä½¿ç”¨ã—ã¦è¡¨ç¤ºã‚’ç”Ÿæˆâ˜…
    if df.empty:
        st.info("è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æŒ¯ã£ã¦ã€ãã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¡¨ç¤ºã‚­ãƒ¼ã«ã™ã‚‹
    df['display_index'] = df.index
    format_func = lambda idx: f"[{df.loc[idx, COL_TIME]}] {df.loc[idx, COL_FILTER]} - {df.loc[idx, COL_MEMO][:30]}..."

    selected_index = st.selectbox(
        "è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹è¨˜éŒ²ã‚’é¸æŠ", 
        options=df['display_index'], 
        format_func=format_func
    )

    if selected_index is not None:
        row = df.loc[selected_index]
        
        st.markdown(f"#### é¸æŠã•ã‚ŒãŸè¨˜éŒ² (ID: {selected_index+1})")
        
        if not is_mainte:
            # ã‚¨ãƒ”ãƒãƒ¼ãƒˆã®è¡¨ç¤ºé …ç›®
            st.write(f"**{COLUMN_DATE}:** {row[COLUMN_DATE]}")
            st.write(f"**{COLUMN_EPI_NO}:** {row[COLUMN_EPI_NO]}")
            st.write(f"**{COLUMN_TITLE}:** {row[COLUMN_TITLE]}")
            st.markdown(f"**{COLUMN_DETAIL_MEMO}:**")
            st.text(row[COLUMN_DETAIL_MEMO])
        else:
            # ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆã®è¡¨ç¤ºé …ç›®
            st.write(f"**{MAINT_COL_TIMESTAMP}:** {row[MAINT_COL_TIMESTAMP]}")
            st.write(f"**{MAINT_COL_TYPE}:** {row[MAINT_COL_TYPE]}")
            st.markdown(f"**{MAINT_COL_MEMO}:**")
            st.text(row[MAINT_COL_MEMO])
            
        # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«
        st.markdown("##### æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«")
        try:
            urls = json.loads(row[COL_URL])
            filenames = json.loads(row[COLUMN_FILENAME])
            
            if urls:
                for filename, url in zip(filenames, urls):
                    st.markdown(f"- [{filename}]({url})")
            else:
                st.info("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        except:
            st.warning("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ãŒä¸æ­£ã§ã™ã€‚")
            

def page_mainte_recording():
    page_note_recording(is_mainte=True)
    
def page_mainte_list():
    page_note_list(is_mainte=True)
    
def page_pl_analysis():
    st.header("ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ")
    st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯æœªå®Ÿè£…ã§ã™ã€‚")
    # PLãƒ‡ãƒ¼ã‚¿è§£æã®ãƒ­ã‚¸ãƒƒã‚¯ã¯ã€IVãƒ‡ãƒ¼ã‚¿è§£æãƒ­ã‚¸ãƒƒã‚¯ã‚’ãƒ™ãƒ¼ã‚¹ã«ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã«å¿œã˜ã¦ä½œæˆã§ãã¾ã™ã€‚

def page_iv_analysis():
    """âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æãƒšãƒ¼ã‚¸ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥é©ç”¨æ¸ˆã¿ï¼‰"""
    st.header("âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ")
    
    # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_files = st.file_uploader(
        "IVæ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« (.txt) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=['txt'], 
        accept_multiple_files=True
    )

    if uploaded_files:
        valid_dataframes = []
        filenames = []
        
        st.subheader("ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¨è§£æ")
        
        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®æ´»ç”¨
        for uploaded_file in uploaded_files:
            # load_iv_dataã«bytesã¨nameã‚’æ¸¡ã™ã“ã¨ã§ã€ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æœ‰åŠ¹æ´»ç”¨ã™ã‚‹
            df = load_iv_data(uploaded_file.getvalue(), uploaded_file.name)
            
            if df is not None and not df.empty:
                valid_dataframes.append(df)
                filenames.append(uploaded_file.name)
        
        if valid_dataframes:
            
            # ãƒ‡ãƒ¼ã‚¿ã®çµåˆ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚ŒãŸé–¢æ•°ã‚’ä½¿ç”¨)
            combined_df = combine_iv_dataframes(valid_dataframes, filenames)
            
            st.success(f"{len(valid_dataframes)}å€‹ã®æœ‰åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€çµåˆã—ã¾ã—ãŸã€‚")
            
            st.subheader("ã‚¹ãƒ†ãƒƒãƒ—2: ã‚°ãƒ©ãƒ•è¡¨ç¤º")
            
            fig, ax = plt.subplots(figsize=(12, 7)) # ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºã‚’æ‹¡å¤§
            
            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®é›»æµå€¤ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
            for filename in filenames:
                ax.plot(combined_df['Voltage_V'], combined_df[filename], label=filename)
            
            ax.set_xlabel("Voltage (V)")
            ax.set_ylabel("Current (A)")
            ax.grid(True)
            ax.legend(title="ãƒ•ã‚¡ã‚¤ãƒ«å", loc='best')
            ax.set_title("IVç‰¹æ€§æ¯”è¼ƒ")
            
            # Streamlitã§ã‚°ãƒ©ãƒ•ã‚’è¡¨ç¤º
            st.pyplot(fig, use_container_width=True) # å¹…ã„ã£ã±ã„ã«è¡¨ç¤º
            
            st.subheader("ã‚¹ãƒ†ãƒƒãƒ—3: çµåˆãƒ‡ãƒ¼ã‚¿")
            st.dataframe(combined_df, use_container_width=True)
            
            # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            output = BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                combined_df.to_excel(writer, sheet_name='Combined IV Data', index=False)
            
            st.download_button(
                label="ğŸ“ˆ çµåˆExcelãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=output.getvalue(),
                file_name=f"iv_analysis_combined_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


# --------------------------------------------------------------------------
# --- Dummy Pages (æœªå®Ÿè£…ã®ãƒšãƒ¼ã‚¸) ---
# --------------------------------------------------------------------------

def page_calendar(): st.header("ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯æœªå®Ÿè£…ã§ã™ã€‚")
def page_meeting_minutes(): st.header("è­°äº‹éŒ²ãƒ»ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ãƒ¢"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯æœªå®Ÿè£…ã§ã™ã€‚")
def page_qa(): st.header("ğŸ’¡ çŸ¥æµè¢‹ãƒ»è³ªå•ç®±"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯æœªå®Ÿè£…ã§ã™ã€‚")
def page_handover(): st.header("ğŸ¤ è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯æœªå®Ÿè£…ã§ã™ã€‚")
def page_trouble_report(): st.header("ğŸš¨ ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯æœªå®Ÿè£…ã§ã™ã€‚")
def page_contact(): st.header("âœ‰ï¸ é€£çµ¡ãƒ»å•ã„åˆã‚ã›"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯æœªå®Ÿè£…ã§ã™ã€‚")

# --------------------------------------------------------------------------
# --- Main App Execution ---
# --------------------------------------------------------------------------
def main():
    st.sidebar.title("å±±æ ¹ç ” ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ")
    
    # ãƒ¡ãƒ‹ãƒ¥ãƒ¼å®šç¾© (æ©Ÿèƒ½ã®è¿½åŠ /å‰Šé™¤ã¯ã“ã“ã§è¡Œã†)
    menu_selection = st.sidebar.radio("æ©Ÿèƒ½é¸æŠ", [
        "ğŸ“ ã‚¨ãƒ”ãƒãƒ¼ãƒˆè¨˜éŒ²", "ğŸ“š ã‚¨ãƒ”ãƒãƒ¼ãƒˆä¸€è¦§", "ğŸ› ï¸ ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆè¨˜éŒ²", "ğŸ› ï¸ ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆä¸€è¦§",
        "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„", 
        "âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ", "ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ",
        "è­°äº‹éŒ²ãƒ»ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ãƒ¢", "ğŸ’¡ çŸ¥æµè¢‹ãƒ»è³ªå•ç®±", "ğŸ¤ è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢", 
        "ğŸš¨ ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š", "âœ‰ï¸ é€£çµ¡ãƒ»å•ã„åˆã‚ã›"
    ])
    
    # ãƒšãƒ¼ã‚¸ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    if menu_selection == "ğŸ“ ã‚¨ãƒ”ãƒãƒ¼ãƒˆè¨˜éŒ²": page_note_recording()
    elif menu_selection == "ğŸ“š ã‚¨ãƒ”ãƒãƒ¼ãƒˆä¸€è¦§": page_note_list()
    elif menu_selection == "ğŸ› ï¸ ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆè¨˜éŒ²": page_mainte_recording()
    elif menu_selection == "ğŸ› ï¸ ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆä¸€è¦§": page_mainte_list()
    elif menu_selection == "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„": page_calendar()
    elif menu_selection == "âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ": page_iv_analysis()
    elif menu_selection == "ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ": page_pl_analysis()
    elif menu_selection == "è­°äº‹éŒ²ãƒ»ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ãƒ¢": page_meeting_minutes()
    elif menu_selection == "ğŸ’¡ çŸ¥æµè¢‹ãƒ»è³ªå•ç®±": page_qa()
    elif menu_selection == "ğŸ¤ è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢": page_handover()
    elif menu_selection == "ğŸš¨ ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š": page_trouble_report()
    elif menu_selection == "âœ‰ï¸ é€£çµ¡ãƒ»å•ã„åˆã‚ã›": page_contact()

if __name__ == "__main__":
    main()

# --------------------------------------------------------------------------
# Yamane Lab Convenience Tool - Streamlit Application (app.py)
#
# v18.10.5 (æœ€çµ‚ä¿®æ­£ç‰ˆ: IVãƒ‡ãƒ¼ã‚¿çµåˆãƒ­ãƒã‚¹ãƒˆåŒ– & Excelå‡ºåŠ›å¯¾å¿œ)
# - FIX: IVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ (load_iv_data) ã§ Voltage_V ã‚’å°æ•°ç‚¹ä»¥ä¸‹3æ¡ã«ä¸¸ã‚ã€çµåˆæ™‚ã®è¡Œæ•°å¢—åŠ ã‚’é˜²æ­¢ã€‚
# - NEW: Excelå‡ºåŠ›ç”¨ to_excel é–¢æ•°ã‚’è¿½åŠ ã€‚
# - FIX: IVãƒ‡ãƒ¼ã‚¿è§£æ (page_iv_analysis) ã§çµåˆãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚»ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¯¾å¿œã€‚
# --------------------------------------------------------------------------

import streamlit as st
import gspread
import pandas as pd
import os
import io
import re
import json
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime, time, timedelta
from urllib.parse import quote as url_quote
from io import BytesIO

# Google API client libraries
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from google.cloud import storage
from google.auth.exceptions import DefaultCredentialsError
from google.api_core import exceptions

# --- Global Configuration & Setup ---
st.set_page_config(page_title="å±±æ ¹ç ” ä¾¿åˆ©å±‹ã•ã‚“", layout="wide")

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# â†“â†“â†“â†“â†“â†“ ã€é‡è¦ã€‘ã”è‡ªèº«ã®ã€Œãƒã‚±ãƒƒãƒˆåã€ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ â†“â†“â†“â†“â†“â†“
CLOUD_STORAGE_BUCKET_NAME = "yamane-lab-app-files" # ä¾‹: "yamane-lab-app-files"
# â†‘â†‘â†‘â†‘â†‘â†‘ ã€é‡è¦ã€‘ã”è‡ªèº«ã®ã€Œãƒã‚±ãƒƒãƒˆåã€ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ â†‘â†‘â†‘â†‘â†‘â†‘
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

SPREADSHEET_NAME = 'ã‚¨ãƒ”ãƒãƒ¼ãƒˆ'
DEFAULT_CALENDAR_ID = 'yamane.lab.6747@gmail.com' # ä¾‹: 'your-calendar-id@group.calendar.google.com'
INQUIRY_RECIPIENT_EMAIL = 'kyuno.yamato.ns@tut.ac.jp' # ä¾‹: 'lab-manager@example.com'

# --- Initialize Google Services ---
@st.cache_resource(show_spinner="Googleã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šä¸­...")
def initialize_google_services():
    """Googleã‚µãƒ¼ãƒ“ã‚¹ï¼ˆSpreadsheet, Calendar, Storageï¼‰ã‚’åˆæœŸåŒ–ã—ã€èªè¨¼æƒ…å ±ã‚’è¨­å®šã™ã‚‹ã€‚"""
    try:
        scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/calendar', 'https://www.googleapis.com/auth/devstorage.read_write']
        
        if "gcs_credentials" not in st.secrets:
            st.error("âŒ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: Streamlit Cloudã®Secretsã« `gcs_credentials` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            # ãƒ€ãƒŸãƒ¼ã®èªè¨¼æƒ…å ±ã§ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ (èªè¨¼æƒ…å ±ãŒãªã„å ´åˆã®å®Ÿè¡Œæ™‚ã‚¨ãƒ©ãƒ¼å›é¿ç”¨)
            class DummyWorksheet:
                def append_row(self, row): pass
                def get_all_values(self): return [[]]
            class DummySpreadsheet:
                def worksheet(self, name): return DummyWorksheet()
            class DummyGSClient:
                def open(self, name): return DummySpreadsheet()
            class DummyEvents:
                def list(self, **kwargs): return {"items": []}
                def insert(self, **kwargs): return {"summary": "ãƒ€ãƒŸãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ", "htmlLink": "#"}
            class DummyCalendarService:
                def events(self): return DummyEvents()
            class DummyBlob:
                def upload_from_file(self, file, content_type): pass
                def generate_signed_url(self, expiration): return "#"
            class DummyBucket:
                def blob(self, name): return DummyBlob()
            class DummyStorageClient:
                def bucket(self, name): return DummyBucket()

            return DummyGSClient(), DummyCalendarService(), DummyStorageClient()
        
        creds_string = st.secrets["gcs_credentials"]
        creds_string_cleaned = creds_string.replace('\u00A0', '')
        creds_dict = json.loads(creds_string_cleaned)
        
        creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)

        gc = gspread.authorize(creds)
        calendar_service = build('calendar', 'v3', credentials=creds)
        storage_client = storage.Client(credentials=creds)
        
        return gc, calendar_service, storage_client
    except Exception as e:
        st.error(f"âŒ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"); st.exception(e); st.stop()

gc, calendar_service, storage_client = initialize_google_services()

# --- Utility Functions ---

# â˜…â˜…â˜… NEW: Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã‚’è¿½åŠ  â˜…â˜…â˜…
def to_excel(df: pd.DataFrame) -> BytesIO:
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’Excelå½¢å¼ã®BytesIOã‚¹ãƒˆãƒªãƒ¼ãƒ ã«å¤‰æ›ã™ã‚‹"""
    output = BytesIO()
    # ExcelWriterã‚’ä½¿ç”¨ã—ã€ãƒ¡ãƒ¢ãƒªä¸Šã®BytesIOã«ç›´æ¥æ›¸ãè¾¼ã‚€ (engine='xlsxwriter'ã‚’æ˜ç¤ºçš„ã«æŒ‡å®š)
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, sheet_name='Combined_IV_Data', index=False)
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã®ä½ç½®ã‚’å…ˆé ­ã«æˆ»ã™
    output.seek(0)
    return output
# â˜…â˜…â˜… NEW: Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã“ã“ã¾ã§ â˜…â˜…â˜…

@st.cache_data(ttl=300, show_spinner="ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã‚’èª­ã¿è¾¼ã¿ä¸­...")
def get_sheet_as_df(_gc, spreadsheet_name, sheet_name):
    """Google Spreadsheetã®ã‚·ãƒ¼ãƒˆã‚’Pandas DataFrameã¨ã—ã¦å–å¾—ã™ã‚‹ã€‚"""
    try:
        worksheet = _gc.open(spreadsheet_name).worksheet(sheet_name)
        data = worksheet.get_all_values()
        if len(data) <= 1: return pd.DataFrame(columns=data[0] if data else [])
        return pd.DataFrame(data[1:], columns=data[0])
    except gspread.exceptions.WorksheetNotFound:
        st.error(f"ã‚·ãƒ¼ãƒˆåã€Œ{sheet_name}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"); return pd.DataFrame()
    except Exception:
        st.warning(f"ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã€‚ç©ºã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"); return pd.DataFrame()

def upload_file_to_gcs(storage_client, bucket_name, file_uploader_obj, memo_content=""):
    """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Google Cloud Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ç½²åä»˜ãURLã‚’ç”Ÿæˆã™ã‚‹ã€‚ï¼ˆã‚¨ãƒ”ãƒãƒ¼ãƒˆã€è­°äº‹éŒ²ã€çŸ¥æµè¢‹ç”¨ï¼‰"""
    if not file_uploader_obj: return "", ""
    try:
        bucket = storage_client.bucket(bucket_name)
        
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        file_extension = os.path.splitext(file_uploader_obj.name)[1]
        # ãƒ•ã‚¡ã‚¤ãƒ«åã®å®‰å…¨ãªéƒ¨åˆ†ã‚’æŠ½å‡º
        sanitized_memo = re.sub(r'[\\/:*?"<>|\r\n]+', '', memo_content)[:50] if memo_content else "ç„¡é¡Œ"
        destination_blob_name = f"{timestamp}_{sanitized_memo}{file_extension}"
        
        blob = bucket.blob(destination_blob_name)
        
        with st.spinner(f"'{file_uploader_obj.name}'ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
            file_uploader_obj.seek(0)
            blob.upload_from_file(file_uploader_obj, content_type=file_uploader_obj.type)
        
        expiration_time = timedelta(days=365 * 100)
        signed_url = blob.generate_signed_url(expiration=expiration_time)
        st.success(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ« '{destination_blob_name}' ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        return destination_blob_name, signed_url
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"); return "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—", ""

def upload_files_to_gcs(storage_client, bucket_name, file_uploader_obj_list, memo_content=""):
    """è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Google Cloud Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«åã¨URLã®ãƒªã‚¹ãƒˆã‚’JSONæ–‡å­—åˆ—ã¨ã—ã¦ç”Ÿæˆã™ã‚‹ã€‚ï¼ˆãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šç”¨ï¼‰"""
    if not file_uploader_obj_list: return "[]", "[]"
    uploaded_data = []
    bucket = storage_client.bucket(bucket_name)
    try:
        with st.spinner(f"{len(file_uploader_obj_list)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
            for uploaded_file in file_uploader_obj_list:
                timestamp = datetime.now().strftime("%Y%m%d-%H%M%S-%f")
                file_extension = os.path.splitext(uploaded_file.name)[1]
                # ãƒ•ã‚¡ã‚¤ãƒ«åã®å®‰å…¨ãªéƒ¨åˆ†ã‚’æŠ½å‡º (ä¸€æ„æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯æ®‹ã™)
                destination_blob_name = f"{timestamp}_{re.sub(r'[\\/:*?"<>|\r\n]+', '', uploaded_file.name)}"
                
                blob = bucket.blob(destination_blob_name)
                uploaded_file.seek(0)
                blob.upload_from_file(uploaded_file, content_type=uploaded_file.type)
                
                expiration_time = timedelta(days=365 * 100)
                signed_url = blob.generate_signed_url(expiration=expiration_time)
                
                uploaded_data.append({
                    "filename": uploaded_file.name,
                    "url": signed_url
                })

        st.success(f"ğŸ“„ {len(file_uploader_obj_list)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        filenames_json = json.dumps([d['filename'] for d in uploaded_data], ensure_ascii=False)
        urls_json = json.dumps([d['url'] for d in uploaded_data], ensure_ascii=False)
        return filenames_json, urls_json

    except Exception as e:
        st.error(f"è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"); return "[]", "[]"

def append_to_spreadsheet(gc, spreadsheet_name, sheet_name, row_data, success_message):
    """Google Spreadsheetã«è¡Œã‚’è¿½åŠ ã™ã‚‹æ±ç”¨é–¢æ•°"""
    try:
        gc.open(spreadsheet_name).worksheet(sheet_name).append_row(row_data)
        st.success(success_message); st.cache_data.clear(); st.rerun()
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ãƒ¼ãƒˆå '{sheet_name}' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.exception(e)

# --- Data Loading Functions ---

@st.cache_data
def load_pl_data(uploaded_file):
    """PLãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†ã‚’è¡Œã†"""
    try:
        file_buffer = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®ãƒ­ã‚¸ãƒƒã‚¯
        header_row = 0
        for i, line in enumerate(file_buffer):
            # 'VF(V)'ã‚„'IF(A)'ãªã©ã®IVãƒ‡ãƒ¼ã‚¿ç‰¹æœ‰ã®ãƒ˜ãƒƒãƒ€ãƒ¼ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ãƒã‚§ãƒƒã‚¯
            if not any(header_str in line for header_str in ['VF(V)', 'IF(A)', 'Current_A', 'Voltage_V', 'Pixel', 'Intensity', 'pixel', 'intensity']):
                # ãƒ‡ãƒ¼ã‚¿è¡ŒãŒå§‹ã¾ã‚‹å‰ã®è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—å¯¾è±¡ã¨ã—ã¦æ¤œå‡º (ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹æ€§ã«ã‚ˆã‚Šèª¿æ•´ãŒå¿…è¦)
                # ä»Šå›ã®PLãƒ‡ãƒ¼ã‚¿ã¯2è¡Œã‚¹ã‚­ãƒƒãƒ—ã‚’æƒ³å®š
                if i >= 1: 
                    header_row = i + 1 # skiprowsã§æŒ‡å®šã™ã‚‹è¡Œæ•°
                    break
            
            # ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®è¡Œã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦ä½¿ç”¨
            if i > 1:
                break
        file_buffer.seek(0) # ãƒãƒƒãƒ•ã‚¡ã‚’æœ€åˆã«æˆ»ã™
        
        # å®Ÿéš›ã«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’èª­ã¿è¾¼ã‚€
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡ŒãŒæ¤œå‡ºã•ã‚Œãªã„å ´åˆã¯ã€æœ€åˆã®è¡Œã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦ä½¿ç”¨ (header=0, skiprows=0)
        skip_rows = header_row - 1 if header_row > 0 else 0
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã€ãƒ˜ãƒƒãƒ€ãƒ¼ãŒã†ã¾ãèª­ã¿è¾¼ã‚ãªã„ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€å…ˆã«ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã§èª­ã¿è¾¼ã¿ã€å¾Œã§ã‚«ãƒ©ãƒ åã‚’ä»˜ã‘ã‚‹
        df = pd.read_csv(file_buffer, skiprows=skip_rows, header=None, encoding='utf-8', sep=r'[,\t\s]+', engine='python', on_bad_lines='skip')
        
        # ã‚«ãƒ©ãƒ æ•°ã‚’2ã¤ã«çµã‚‹ (å·¦ç«¯ã®2ã‚«ãƒ©ãƒ ãŒPixelã¨Intensityã¨ä»®å®š)
        if df.shape[1] >= 2:
            df = df.iloc[:, :2]
            df.columns = ['pixel', 'intensity']
        else:
            st.error("PLãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€å°‘ãªãã¨ã‚‚2ã¤ã®ãƒ‡ãƒ¼ã‚¿åˆ—ï¼ˆPixel, Intensityï¼‰ãŒå¿…è¦ã§ã™ã€‚")
            return None

        # ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›
        df['pixel'] = pd.to_numeric(df['pixel'], errors='coerce')
        df['intensity'] = pd.to_numeric(df['intensity'], errors='coerce')
        
        # ç„¡åŠ¹ãªè¡Œã‚’å‰Šé™¤
        df.dropna(inplace=True)
        
        return df

    except Exception as e:
        st.error(f"PLãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

@st.cache_data
def load_iv_data(uploaded_file, filename):
    """IVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†ã‚’è¡Œã†"""
    try:
        file_buffer = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ç‰¹å®šã™ã‚‹ãŸã‚ã®ãƒ­ã‚¸ãƒƒã‚¯
        # æ¸¬å®šå™¨ãŒå‡ºåŠ›ã™ã‚‹å…¸å‹çš„ãªãƒ˜ãƒƒãƒ€ãƒ¼å½¢å¼ 'VF(V), IF(A)'
        skip_rows = 0
        for i, line in enumerate(file_buffer):
            # ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®è¡Œã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦ä½¿ç”¨ (2è¡Œç›®ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿é–‹å§‹ã‚’æƒ³å®š)
            if i >= 1: 
                skip_rows = i + 1 # skiprowsã§æŒ‡å®šã™ã‚‹è¡Œæ•°
                break
        file_buffer.seek(0) # ãƒãƒƒãƒ•ã‚¡ã‚’æœ€åˆã«æˆ»ã™
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã€‚ãƒ˜ãƒƒãƒ€ãƒ¼ãªã—ã§èª­ã¿è¾¼ã¿ã€ã‚«ãƒ©ãƒ åã‚’å¾Œã§è¨­å®š
        df = pd.read_csv(file_buffer, skiprows=skip_rows, header=None, encoding='utf-8', sep=r'[,\t\s]+', engine='python', on_bad_lines='skip')

        # ã‚«ãƒ©ãƒ æ•°ã‚’2ã¤ã«çµã‚‹ (å·¦ç«¯ã®2ã‚«ãƒ©ãƒ ãŒVoltageã¨Currentã¨ä»®å®š)
        if df.shape[1] >= 2:
            df = df.iloc[:, :2]
        else:
            st.error(f"IVãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã¯ã€å°‘ãªãã¨ã‚‚2ã¤ã®ãƒ‡ãƒ¼ã‚¿åˆ—ï¼ˆVoltage, Currentï¼‰ãŒå¿…è¦ã§ã™ã€‚")
            return None

        # ã‚«ãƒ©ãƒ åã®æ•´ç†
        df.columns = ['Voltage_V', 'Current_A']

        # IVãƒ‡ãƒ¼ã‚¿ã®åˆ†æã§ã¯é›»åœ§å€¤ãŒå¾®å°ã«ç•°ãªã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ã€
        # çµåˆã‚’ãƒ­ãƒã‚¹ãƒˆã«ã™ã‚‹ãŸã‚ã«Voltage_Vã‚’ä¸¸ã‚ã‚‹
        # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€: Voltage_Vã‚’å°æ•°ç‚¹ä»¥ä¸‹3æ¡ã«ä¸¸ã‚ã‚‹ â˜…â˜…â˜…
        df['Voltage_V'] = df['Voltage_V'].round(3) 

        # ãƒ‡ãƒ¼ã‚¿å‹ã®å¤‰æ›
        df['Voltage_V'] = pd.to_numeric(df['Voltage_V'], errors='coerce')
        df['Current_A'] = pd.to_numeric(df['Current_A'], errors='coerce')
        
        # ç„¡åŠ¹ãªè¡Œã‚’å‰Šé™¤
        df.dropna(inplace=True)
        
        # é›»åœ§ãŒæ˜‡é †ã§ãªã„å ´åˆã«ã‚½ãƒ¼ãƒˆ
        if not df['Voltage_V'].is_monotonic_increasing:
            df = df.sort_values(by='Voltage_V').reset_index(drop=True)

        return df

    except Exception as e:
        st.error(f"IVãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

# --- Page Definitions ---

# (ä»–ã®ãƒšãƒ¼ã‚¸ã®å®šç¾©ã¯çœç•¥ã—ã€é–¢é€£ã™ã‚‹IVè§£æãƒšãƒ¼ã‚¸ã®ã¿æ²è¼‰ã—ã¾ã™)

def page_iv_analysis():
    st.header("âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ")
    st.markdown("è¤‡æ•°ã®IVãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€é›»åœ§ã‚’ã‚­ãƒ¼ã«é›»æµå€¤ã‚’æ¨ªä¸¦ã³ã§çµåˆãƒ»æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã§ãã¾ã™ã€‚")

    uploaded_files = st.file_uploader(
        "IVæ¸¬å®šãƒ‡ãƒ¼ã‚¿ (CSV/TXTå½¢å¼) ã‚’é¸æŠã—ã¦ãã ã•ã„ (è¤‡æ•°é¸æŠå¯)", 
        type=['csv', 'txt'], 
        accept_multiple_files=True
    )

    if uploaded_files:
        valid_dfs = {}
        with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            for uploaded_file in uploaded_files:
                filename = os.path.basename(uploaded_file.name)
                df = load_iv_data(uploaded_file, filename)
                if df is not None:
                    # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ‹¡å¼µå­ã‚’é™¤ã„ãŸã‚‚ã®ã‚’ã‚­ãƒ¼ã¨ã™ã‚‹
                    key = os.path.splitext(filename)[0]
                    valid_dfs[key] = df

        if valid_dfs:
            # çµåˆãƒ­ã‚¸ãƒƒã‚¯ã‚’æœ€é©åŒ–ï¼ˆVoltage_Vã‚’ã‚­ãƒ¼ã«çµåˆï¼‰
            processed_data = None
            
            for df_key, df in valid_dfs.items():
                # ã‚«ãƒ©ãƒ åã‚’ 'Current_A_ãƒ•ã‚¡ã‚¤ãƒ«å' ã«ãƒªãƒãƒ¼ãƒ 
                new_col_name = f'Current_A_{df_key}'
                df_renamed = df.rename(columns={'Current_A': new_col_name})
                
                if processed_data is None:
                    # æœ€åˆã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒ™ãƒ¼ã‚¹ã«ã™ã‚‹
                    processed_data = df_renamed
                else:
                    # æ¬¡ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã¨ Voltage_V ã‚’ã‚­ãƒ¼ã«å¤–éƒ¨çµåˆ (outer merge) ã™ã‚‹
                    # load_iv_dataã§Voltage_Vã‚’ä¸¸ã‚ã¦ã„ã‚‹ãŸã‚ã€è¡Œã®é‡è¤‡ã¯ç™ºç”Ÿã—ãªã„ã¯ãš
                    processed_data = pd.merge(
                        processed_data, 
                        df_renamed,
                        on='Voltage_V', 
                        how='outer'
                    )

            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ãŒçµåˆã•ã‚ŒãŸã‚‰ãƒ—ãƒ­ãƒƒãƒˆ
            if processed_data is not None:
                st.subheader("ğŸ“ˆ IVç‰¹æ€§æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ")
                
                # Plotting
                fig, ax = plt.subplots(figsize=(12, 7))
                
                current_cols = [col for col in processed_data.columns if col.startswith('Current_A_')]
                
                for col in current_cols:
                    label = col.replace('Current_A_', '')
                    ax.plot(processed_data['Voltage_V'], processed_data[col], marker='.', linestyle='-', label=label, alpha=0.7)
                
                ax.set_title("IVç‰¹æ€§æ¯”è¼ƒ")
                ax.set_xlabel("Voltage (V)")
                ax.set_ylabel("Current (A)")
                ax.grid(True, linestyle='--', alpha=0.6)
                ax.legend(loc='best')
                
                # Yè»¸ã‚’å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«ã«ã™ã‚‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³
                if st.checkbox("Yè»¸ã‚’å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ« (Log Scale) ã§è¡¨ç¤º"):
                    # è² ã®é›»æµå€¤ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€çµ¶å¯¾å€¤ã®å¯¾æ•°ã‚’ã¨ã‚Šã€ç¬¦å·ã‚’å…ƒã«æˆ»ã™å‡¦ç†ã‚’è¡Œã†
                    log_current_data = processed_data.copy()
                    for col in current_cols:
                        log_current_data[col] = log_current_data[col].apply(lambda x: np.log10(np.abs(x)) * np.sign(x) if np.abs(x) > 0 else np.nan)
                    
                    fig_log, ax_log = plt.subplots(figsize=(12, 7))
                    
                    for col in current_cols:
                        label = col.replace('Current_A_', '')
                        ax_log.plot(processed_data['Voltage_V'], np.abs(processed_data[col]), marker='.', linestyle='-', label=label, alpha=0.7)
                    
                    ax_log.set_yscale('log')
                    ax_log.set_title("IVç‰¹æ€§æ¯”è¼ƒ (Yè»¸ å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«)")
                    ax_log.set_xlabel("Voltage (V)")
                    ax_log.set_ylabel("|Current| (A) [Log Scale]")
                    ax_log.grid(True, linestyle='--', alpha=0.6)
                    ax_log.legend(loc='best')
                    st.pyplot(fig_log, use_container_width=True)
                else:
                    st.pyplot(fig, use_container_width=True)
                
                # çµåˆæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                st.subheader("ğŸ“Š çµåˆæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿")
                # çµåˆå¾Œã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
                st.dataframe(processed_data, use_container_width=True)
                
                # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€: Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒ­ã‚¸ãƒƒã‚¯ã‚’BytesIOã‚’ä½¿ç”¨ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´ â˜…â˜…â˜…
                excel_data = to_excel(processed_data)

                st.download_button(
                    label="ğŸ“ˆ çµåˆExcelãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (å˜ä¸€ã‚·ãƒ¼ãƒˆ)",
                    # BytesIOã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’dataå¼•æ•°ã«æ¸¡ã™
                    data=excel_data,
                    file_name=f"iv_analysis_combined_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.warning("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ‰åŠ¹ãªIVãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.info("æ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")


# (ä»–ã®ãƒšãƒ¼ã‚¸ã®å®šç¾©ã¯çœç•¥ã—ã¾ã™: page_pl_analysis, page_note_recording, page_note_list, page_calendar, etc.)
# --- Dummy Pages (æœªå®Ÿè£…ã®ãƒšãƒ¼ã‚¸) ---
def page_calendar(): st.header("ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯æœªå®Ÿè£…ã§ã™ã€‚")
def page_pl_analysis(): st.header("ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯æœªå®Ÿè£…ã§ã™ã€‚") # å®Ÿéš›ã«ã¯PLè§£æãƒšãƒ¼ã‚¸ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ãŒã€IVè§£æã®ä¿®æ­£ã«é›†ä¸­ã™ã‚‹ãŸã‚ãƒ€ãƒŸãƒ¼ã¨ã—ã¦æ®‹ã—ã¾ã™

# --------------------------------------------------------------------------
# --- Main App Execution ---\
# --------------------------------------------------------------------------
def main():
    st.sidebar.title("å±±æ ¹ç ” ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ")
    
    menu_selection = st.sidebar.radio("æ©Ÿèƒ½é¸æŠ", [
        "ğŸ“ ã‚¨ãƒ”ãƒãƒ¼ãƒˆè¨˜éŒ²", "ğŸ“š ã‚¨ãƒ”ãƒãƒ¼ãƒˆä¸€è¦§", "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„", 
        "âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ", "ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ",
        "è­°äº‹éŒ²ãƒ»ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ãƒ¢", "ğŸ’¡ çŸ¥æµè¢‹ãƒ»è³ªå•ç®±", "ğŸ¤ è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢", 
        "ğŸš¨ ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š", "âœ‰ï¸ é€£çµ¡ãƒ»å•ã„åˆã‚ã›"
    ])
    
    # ãƒšãƒ¼ã‚¸ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° (IVè§£æã¨PLè§£æã¯ãƒ€ãƒŸãƒ¼ã‚’å‰Šé™¤ã—ã€å®Ÿéš›ã®é–¢æ•°ã‚’å‘¼ã³å‡ºã™ã‚ˆã†ã«ã—ã¦ãã ã•ã„)
    if menu_selection == "âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ": page_iv_analysis()
    elif menu_selection == "ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ": page_pl_analysis()
    elif menu_selection == "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„": page_calendar()
    # elif menu_selection == "ğŸ“ ã‚¨ãƒ”ãƒãƒ¼ãƒˆè¨˜éŒ²": page_note_recording() # ä»–ã®ãƒšãƒ¼ã‚¸ã¸ã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚‚å¿˜ã‚Œãšã«
    # ... (ãã®ä»–ã®ãƒšãƒ¼ã‚¸ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°) ...
    
    # ä¾‹: ä»–ã®æ©Ÿèƒ½ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹å ´åˆ
    # if menu_selection == "ğŸ“ ã‚¨ãƒ”ãƒãƒ¼ãƒˆè¨˜éŒ²": page_note_recording()
    # elif menu_selection == "ğŸ“š ã‚¨ãƒ”ãƒãƒ¼ãƒˆä¸€è¦§": page_note_list()
    # ...

if __name__ == "__main__":
    main()

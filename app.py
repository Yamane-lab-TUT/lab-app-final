# -*- coding: utf-8 -*-
"""
bennriyasann3_fixed_v2_part1.py
Yamane Lab Convenience Tool - ä¿®æ­£ç‰ˆãƒ‘ãƒ¼ãƒˆ1ï¼ˆå…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ãƒ»èªè¨¼ãƒ»ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ç­‰ï¼‰

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚¢ãƒ—ãƒªæœ¬ä½“ã‚’äºŒåˆ†å‰²ã—ã¦æä¾›ã™ã‚‹ãŸã‚ã®ã€Œå‰åŠã€ã§ã™ã€‚
å¾ŒåŠï¼ˆãƒšãƒ¼ã‚¸å®šç¾©ãƒ»ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ï¼‰ã¯ç¶šã‘ã¦å‡ºåŠ›ã—ã¾ã™ã€‚
"""

import streamlit as st
import gspread
import pandas as pd
import os
import io
import re
import json
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime, date, timedelta
from urllib.parse import quote as url_quote
from io import BytesIO
import calendar
import matplotlib.font_manager as fm

# Google Calendar APIã®ãŸã‚ã®æ–°ã—ã„ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

# Optional: google cloud client import
try:
    from google.cloud import storage
except Exception:
    storage = None  # GCS ãŒç„¡ã„ç’°å¢ƒã§ã‚‚èµ·å‹•å¯èƒ½

# --- Matplotlib æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆ (å®‰å…¨ã«è¨­å®š) ---
try:
    plt.rcParams['font.family'] = 'sans-serif'
    plt.rcParams['font.sans-serif'] = [
        'Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meiryo',
        'TakaoGothic', 'IPAexGothic', 'Noto Sans CJK JP'
    ]
    plt.rcParams['axes.unicode_minus'] = False
except Exception:
    pass

# --- Streamlit ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="å±±æ ¹ç ” ä¾¿åˆ©å±‹ã•ã‚“", layout="wide")

# ---------------------------
# --- Global constants ------
# ---------------------------
CLOUD_STORAGE_BUCKET_NAME = "yamane-lab-app-files"  # å¿…è¦ã«å¿œã˜ã¦ç½®ãæ›ãˆã¦ãã ã•ã„
SPREADSHEET_NAME = "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ"

# --- ã‚·ãƒ¼ãƒˆå & ã‚«ãƒ©ãƒ åï¼ˆæ—¢å­˜ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ§‹æˆã«åˆã‚ã›ã¦ã„ã¾ã™ï¼‰ ---
SHEET_EPI_DATA = 'ã‚¨ãƒ”ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿'
EPI_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
EPI_COL_NOTE_TYPE = 'ãƒãƒ¼ãƒˆç¨®åˆ¥'
EPI_COL_CATEGORY = 'ã‚«ãƒ†ã‚´ãƒª'
EPI_COL_MEMO = 'ãƒ¡ãƒ¢'
EPI_COL_FILENAME = 'ãƒ•ã‚¡ã‚¤ãƒ«å'
EPI_COL_FILE_URL = 'å†™çœŸURL'

SHEET_MAINTE_DATA = 'ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿'
MAINT_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
MAINT_COL_NOTE_TYPE = 'ãƒãƒ¼ãƒˆç¨®åˆ¥'
MAINT_COL_MEMO = 'ãƒ¡ãƒ¢'
MAINT_COL_FILENAME = 'ãƒ•ã‚¡ã‚¤ãƒ«å'
MAINT_COL_FILE_URL = 'å†™çœŸURL'

SHEET_MEETING_DATA = 'è­°äº‹éŒ²_ãƒ‡ãƒ¼ã‚¿'
MEETING_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
MEETING_COL_TITLE = 'ä¼šè­°ã‚¿ã‚¤ãƒˆãƒ«'
MEETING_COL_AUDIO_NAME = 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å'
MEETING_COL_AUDIO_URL = 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«URL'
MEETING_COL_CONTENT = 'è­°äº‹éŒ²å†…å®¹'

SHEET_HANDOVER_DATA = 'å¼•ãç¶™ã_ãƒ‡ãƒ¼ã‚¿'
HANDOVER_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
HANDOVER_COL_TYPE = 'ç¨®é¡'
HANDOVER_COL_TITLE = 'ã‚¿ã‚¤ãƒˆãƒ«'
HANDOVER_COL_MEMO = 'ãƒ¡ãƒ¢'

SHEET_QA_DATA = 'çŸ¥æµè¢‹_ãƒ‡ãƒ¼ã‚¿'
QA_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
QA_COL_TITLE = 'è³ªå•ã‚¿ã‚¤ãƒˆãƒ«'
QA_COL_CONTENT = 'è³ªå•å†…å®¹'
QA_COL_CONTACT = 'é€£çµ¡å…ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'
QA_COL_FILENAME = 'æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å'
QA_COL_FILE_URL = 'æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«URL'
QA_COL_STATUS = 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'
SHEET_QA_ANSWER = 'çŸ¥æµè¢‹_è§£ç­”'

SHEET_CONTACT_DATA = 'ãŠå•ã„åˆã‚ã›_ãƒ‡ãƒ¼ã‚¿'
CONTACT_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
CONTACT_COL_TYPE = 'ãŠå•ã„åˆã‚ã›ã®ç¨®é¡'
CONTACT_COL_DETAIL = 'è©³ç´°å†…å®¹'
CONTACT_COL_CONTACT = 'é€£çµ¡å…ˆ'

SHEET_TROUBLE_DATA = 'ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š_ãƒ‡ãƒ¼ã‚¿'
TROUBLE_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
TROUBLE_COL_DEVICE = 'æ©Ÿå™¨/å ´æ‰€'
TROUBLE_COL_OCCUR_DATE = 'ç™ºç”Ÿæ—¥'
TROUBLE_COL_OCCUR_TIME = 'ãƒˆãƒ©ãƒ–ãƒ«ç™ºç”Ÿæ™‚'
TROUBLE_COL_CAUSE = 'åŸå› /ç©¶æ˜'
TROUBLE_COL_SOLUTION = 'å¯¾ç­–/å¾©æ—§'
TROUBLE_COL_PREVENTION = 'å†ç™ºé˜²æ­¢ç­–'
TROUBLE_COL_REPORTER = 'å ±å‘Šè€…'
TROUBLE_COL_FILENAME = 'ãƒ•ã‚¡ã‚¤ãƒ«å'
TROUBLE_COL_FILE_URL = 'ãƒ•ã‚¡ã‚¤ãƒ«URL'
TROUBLE_COL_TITLE = 'ä»¶å/ã‚¿ã‚¤ãƒˆãƒ«'

# --- ç ”ç©¶å®¤ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæ–°ã—ã„ã‚·ãƒ¼ãƒˆãŒå¿…è¦ï¼‰ ---
SHEET_SCHEDULE_DATA = "Schedule"
SCH_COL_TIMESTAMP = "ç™»éŒ²æ—¥æ™‚"
SCH_COL_TITLE = "ã‚¿ã‚¤ãƒˆãƒ«"
SCH_COL_DETAIL = "è©³ç´°"
SCH_COL_START_DATETIME = "é–‹å§‹æ—¥æ™‚"
SCH_COL_END_DATETIME = "çµ‚äº†æ—¥æ™‚"
SCH_COL_USER = "ç™»éŒ²è€…"

# --- äºˆç´„/ä½œæ¥­ã®ã‚«ãƒ†ã‚´ãƒªï¼ˆã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆç”¨ï¼‰ ---
CATEGORY_OPTIONS = [
    "D1ã‚¨ãƒ”", "D2ã‚¨ãƒ”", "MBEãƒ¡ãƒ³ãƒ†", "XRD", "PL", "AFM", "ãƒ•ã‚©ãƒˆãƒªã‚½", "ã‚¢ãƒ‹ãƒ¼ãƒ«", "è’¸ç€", "ãã®ä»–å…¥åŠ›"
]

# --- Google Calendar APIé€£æºç”¨å®šæ•° ---
# éµãƒ•ã‚¡ã‚¤ãƒ«ã¯ st.secrets ã‹ã‚‰èª­ã¿è¾¼ã‚€ãŸã‚ã€ãƒ•ã‚¡ã‚¤ãƒ«åã¯ä¸è¦ã§ã™
SCOPES = ['https://www.googleapis.com/auth/calendar']
CALENDAR_ID = "yamane.lab.6747@gmail.com" # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ID

# ---------------------------
# --- Google Service Stubs ---
# ---------------------------
class DummyGSClient:
    """èªè¨¼å¤±æ•—æ™‚ç”¨ãƒ€ãƒŸãƒ¼ gspread ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def open(self, name): return self
    def worksheet(self, name): return self
    def get_all_records(self): return []
    def get_all_values(self): return []
    def append_row(self, values): pass

class DummyStorageClient:
    """èªè¨¼å¤±æ•—æ™‚ç”¨ãƒ€ãƒŸãƒ¼ GCS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def bucket(self, name): return self
    def blob(self, name): return self
    def upload_from_file(self, file_obj, content_type): pass
    def list_blobs(self, **kwargs): return []

# ã‚°ãƒ­ãƒ¼ãƒãƒ«åˆæœŸå€¤ï¼ˆèªè¨¼ã•ã‚Œã¦ã„ãªã„çŠ¶æ…‹ã§ã‚‚UIã¯èµ·å‹•ã™ã‚‹ï¼‰
gc = DummyGSClient()
storage_client = DummyStorageClient()

# ---------------------------
# --- Google èªè¨¼åˆæœŸåŒ– ---
# ---------------------------
@st.cache_resource(ttl=3600)
def initialize_google_services():
    """Streamlit secrets ã‹ã‚‰ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆJSONã‚’èª­ã¿è¾¼ã¿ã€gspread ã¨ GCS ã‚’åˆæœŸåŒ–"""
    global storage
    if storage is None:
        # google.cloud.storage ãŒ import ã§ããªã„ç’°å¢ƒ
        st.sidebar.warning("âš ï¸ `google-cloud-storage` ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ã¯åˆ¶é™ã•ã‚Œã¾ã™ã€‚")
        return DummyGSClient(), DummyStorageClient()

    if "gcs_credentials" not in st.secrets:
        st.sidebar.info("Streamlit secrets ã« `gcs_credentials` ã‚’è¨­å®šã—ã¦ãã ã•ã„ï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§ã‚‚ä¸€éƒ¨æ©Ÿèƒ½ã¯å‹•ãã¾ã™ï¼‰ã€‚")
        return DummyGSClient(), DummyStorageClient()

    try:
        raw = st.secrets["gcs_credentials"]
        # ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
        cleaned = raw.strip().replace('\t', '').replace('\r', '').replace('\n', '')
        info = json.loads(cleaned)
        gc_real = gspread.service_account_from_dict(info)
        storage_real = storage.Client.from_service_account_info(info)
        st.sidebar.success("âœ… Googleã‚µãƒ¼ãƒ“ã‚¹èªè¨¼ æˆåŠŸ")
        return gc_real, storage_real
    except json.JSONDecodeError as e:
        st.sidebar.error(f"èªè¨¼æƒ…å ±ã®JSONãŒä¸æ­£ã§ã™: {e}")
        return DummyGSClient(), DummyStorageClient()
    except Exception as e:
        st.sidebar.error(f"Googleã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return DummyGSClient(), DummyStorageClient()

# å®Ÿéš›ã«åˆæœŸåŒ–ã—ã¦ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚’æ›¸ãæ›ãˆ
gc, storage_client = initialize_google_services()

# ---------------------------
# --- Spreadsheet é–¢é€£ ---
# ---------------------------
@st.cache_data(ttl=600, show_spinner="ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
def get_sheet_as_df(spreadsheet_name, sheet_name):
    """æŒ‡å®šã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚·ãƒ¼ãƒˆã‚’ DataFrame ã§è¿”ã™ã€‚å¤±æ•—æ™‚ã¯ç©ºã®DFã‚’è¿”ã™"""
    global gc
    try:
        if isinstance(gc, DummyGSClient):
            # èªè¨¼ã•ã‚Œã¦ã„ãªã„å ´åˆã¯ç©ºDFã‚’è¿”ã™ï¼ˆUIãƒ†ã‚¹ãƒˆç”¨ï¼‰
            return pd.DataFrame()
        ws = gc.open(spreadsheet_name).worksheet(sheet_name)
        data = ws.get_all_values()
        if not data or len(data) <= 1:
            return pd.DataFrame(columns=data[0] if data else [])
        df = pd.DataFrame(data[1:], columns=data[0])
        return df
    except Exception:
        return pd.DataFrame()

# ---------------------------
# --- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚³ã‚¢ ---
# ---------------------------
def _load_two_column_data_core(uploaded_bytes, column_names):
    """
    ãƒã‚¤ãƒˆåˆ—ã‹ã‚‰ 2åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦ DataFrame ã‚’è¿”ã™ã€‚
    - uploaded_bytes: bytes
    - column_names: list[str] ä¾‹ ['Axis_X', 'Current']
    """
    try:
        text = uploaded_bytes.decode('utf-8', errors='ignore').splitlines()
        # ã‚³ãƒ¡ãƒ³ãƒˆ/ç©ºè¡Œã‚’é™¤ã
        data_lines = []
        for line in text:
            s = line.strip()
            if not s:
                continue
            if s.startswith(('#', '!', '/')):  # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œ
                continue
            data_lines.append(line)
        if not data_lines:
            return None
        # pandas ã«æ¸¡ã™
        df = pd.read_csv(io.StringIO("\n".join(data_lines)),
                         sep=r'\s+|,|\t', engine='python', header=None)
        if df.shape[1] < 2:
            return None
        df = df.iloc[:, :2]
        df.columns = column_names
        # æ•°å€¤å¤‰æ›
        df[column_names[0]] = pd.to_numeric(df[column_names[0]], errors='coerce')
        df[column_names[1]] = pd.to_numeric(df[column_names[1]], errors='coerce')
        df = df.dropna().sort_values(column_names[0]).reset_index(drop=True)
        if df.empty:
            return None
        return df
    except Exception:
        return None

# ---------------------------
# --- IV / PL å°‚ç”¨èª­ã¿è¾¼ã¿ ---
# ---------------------------
@st.cache_data(show_spinner="IVãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­...", max_entries=128)
def load_data_file(uploaded_bytes, uploaded_filename):
    """IVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ Axis_X ã¨ filename åˆ—ã‚’è¿”ã™ï¼ˆuploaded_bytes: bytesï¼‰"""
    return _load_two_column_data_core(uploaded_bytes, ['Axis_X', uploaded_filename])

@st.cache_data(show_spinner="PLãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­...", max_entries=128)
def load_pl_data(uploaded_file):
    """
    PLãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°ï¼ˆæœ€çµ‚å®‰å®šç‰ˆï¼‰ã€‚
    ã‚³ãƒ¡ãƒ³ãƒˆè¡Œ(#,!,/)ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã€ã‚«ãƒ³ãƒãƒ»ã‚¹ãƒšãƒ¼ã‚¹ãƒ»ã‚¿ãƒ–åŒºåˆ‡ã‚Šã™ã¹ã¦ã«å¯¾å¿œã€‚
    ä¾‹: '1, 303' / '1 303' / '1\t303'
    """
    try:
        # èª­ã¿è¾¼ã¿
        content = uploaded_file.getvalue().decode('utf-8', errors='ignore').splitlines()

        # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œãƒ»ç©ºè¡Œã‚¹ã‚­ãƒƒãƒ—
        data_lines = []
        for line in content:
            s = line.strip()
            if not s or s.startswith(('#', '!', '/')):
                continue
            data_lines.append(s)

        if not data_lines:
            st.warning(f"'{uploaded_file.name}' ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return None

        # --- ãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€å½¢å¼ã«æ•´å½¢ ---
        # ã€Œ, ã€ã‚„ã€Œ ,ã€ãªã©ã‚’çµ±ä¸€ã—ã¦ã‚«ãƒ³ãƒã¾ãŸã¯ç©ºç™½ã«å¤‰æ›
        normalized = []
        for line in data_lines:
            # ã‚«ãƒ³ãƒâ†’ã‚¹ãƒšãƒ¼ã‚¹ã«çµ±ä¸€
            line = line.replace(',', ' ')
            # ã‚¿ãƒ–ã‚’ã‚¹ãƒšãƒ¼ã‚¹ã«å¤‰æ›
            line = line.replace('\t', ' ')
            # ä½™åˆ†ãªã‚¹ãƒšãƒ¼ã‚¹ã‚’1ã¤ã«
            line = re.sub(r'\s+', ' ', line.strip())
            normalized.append(line)

        df = pd.read_csv(io.StringIO("\n".join(normalized)),
                         sep=' ', header=None, names=['pixel', 'intensity'])

        # æ•°å€¤å¤‰æ›
        df['pixel'] = pd.to_numeric(df['pixel'], errors='coerce')
        df['intensity'] = pd.to_numeric(df['intensity'], errors='coerce')
        df.dropna(inplace=True)

        if df.empty:
            st.warning(f"'{uploaded_file.name}' ã«æœ‰åŠ¹ãªæ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            return None

        return df

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ï¼š'{uploaded_file.name}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚({e})")
        return None


# ---------------------------
# --- IV ãƒ‡ãƒ¼ã‚¿çµåˆï¼ˆè£œé–“ï¼‰ ---
# ---------------------------
@st.cache_data(show_spinner="IVãƒ‡ãƒ¼ã‚¿ã‚’çµåˆä¸­...", max_entries=64)
def combine_dataframes(dataframes, filenames, num_points=500):
    """
    è¤‡æ•°ã®IVãƒ‡ãƒ¼ã‚¿ã‚’å…±é€šé›»åœ§è»¸ã§ç·šå½¢è£œé–“ã—ã¦çµåˆï¼ˆæ¬ æã‚’ä½œã‚‰ãªã„ï¼‰ã€‚
    - dataframes: list of DataFrame (each has 'Axis_X' and a second column)
    - filenames: list of str (åˆ—åã«ä½¿ç”¨)
    """
    if not dataframes:
        return None

    # å„DFã® Axis_X ã‚’é›†ã‚ã‚‹
    try:
        all_x = np.concatenate([df['Axis_X'].values for df in dataframes if 'Axis_X' in df.columns])
    except Exception:
        return None

    if all_x.size == 0:
        return None

    x_common = np.linspace(all_x.min(), all_x.max(), num_points)
    combined_df = pd.DataFrame({'X_Axis': x_common})

    for df, name in zip(dataframes, filenames):
        # df ã¯ Axis_X, <value> ã®2åˆ—æ§‹æˆã‚’ä»®å®š
        df_sorted = df.sort_values('Axis_X')
        y_vals = df_sorted.iloc[:, 1].values
        x_vals = df_sorted['Axis_X'].values
        # ç·šå½¢è£œé–“ï¼ˆå¢ƒç•Œå¤–ã¯æœ€å¤–ç«¯ã®å€¤ã‚’ä½¿ç”¨ï¼‰
        y_interp = np.interp(x_common, x_vals, y_vals, left=y_vals[0], right=y_vals[-1])
        combined_df[name] = y_interp

    return combined_df

# ---------------------------
# --- GCS ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---
# ---------------------------
def upload_file_to_gcs(storage_client_obj, file_obj, folder_name):
    """
    file_obj: streamlit uploaded file (has .name, .type, .getvalue()/read())
    Returns: (original_filename, public_url) or (None, None) on error
    """
    if isinstance(storage_client_obj, DummyStorageClient) or storage is None:
        # ãƒ€ãƒŸãƒ¼å‹•ä½œï¼šæœªèªè¨¼ç’°å¢ƒã§ã¯ None ã‚’è¿”ã™
        return None, None

    try:
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        original_filename = file_obj.name
        safe_filename = original_filename.replace(' ', '_').replace('/', '_')
        gcs_filename = f"{folder_name}/{timestamp}_{safe_filename}"

        bucket = storage_client_obj.bucket(CLOUD_STORAGE_BUCKET_NAME)
        blob = bucket.blob(gcs_filename)

        # file_objã¯Streamlit UploadedFile ãªã®ã§ getvalue() ã‚’ä½¿ã†
        file_bytes = file_obj.getvalue()
        blob.upload_from_string(file_bytes, content_type=file_obj.type if hasattr(file_obj, 'type') else 'application/octet-stream')

        public_url = f"https://storage.googleapis.com/{CLOUD_STORAGE_BUCKET_NAME}/{url_quote(gcs_filename)}"
        return original_filename, public_url
    except Exception as e:
        st.error(f"GCS ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}")
        return None, None

# ---------------------------
# --- æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤ºãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆè‡ªå‹•ãƒªã‚µã‚¤ã‚ºï¼‰ ---
# ---------------------------

def display_attached_files(row_dict, col_url_key, col_filename_key=None):
    """
    row_dict: pandas Series / dict representing a row
    col_url_key: key name of the URL field (ä¿å­˜æ™‚ã¯ JSON array ã‚’æœŸå¾…)
    col_filename_key: key name of filenames (optional, JSON array)
    """
    try:
        if col_url_key not in row_dict or not row_dict[col_url_key]:
            st.info("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            return

        urls = []; filenames = []
        try:
            urls = json.loads(row_dict[col_url_key])
            if not isinstance(urls, list): urls = [urls]
        except Exception:
            # GCSã®ç½²åä»˜ãURLãŒå˜ä¸€ã®æ–‡å­—åˆ—ã¨ã—ã¦å…¥ã£ã¦ã„ã‚‹å ´åˆã¸ã®å¯¾å¿œ
            urls = [s.strip().strip('"') for s in str(row_dict[col_url_key]).split(',') if s.strip()]

        if col_filename_key and col_filename_key in row_dict and row_dict[col_filename_key]:
            try:
                filenames = json.loads(row_dict[col_filename_key])
                if not isinstance(filenames, list): filenames = [filenames]
            except Exception:
                filenames = []
        
        # è¡¨ç¤º
        for idx, url in enumerate(urls):
            if not url:
                continue
            
            label = filenames[idx] if idx < len(filenames) else os.path.basename(url)
            
            # URLã‹ã‚‰ã‚¯ã‚¨ãƒªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆ?ä»¥é™ï¼‰ã‚’å‰Šé™¤ã—ã¦æ‹¡å¼µå­ã‚’åˆ¤å®š
            url_no_query = url.split('?')[0] 
            lower = url_no_query.lower()
            
            is_image = lower.endswith(('.png', '.jpg', '.jpeg', '.gif', '.webp')) 
            is_pdf = lower.endswith('.pdf')
            
            st.markdown("---") # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®åŒºåˆ‡ã‚Š

            if is_image:
                st.markdown("**å†™çœŸãƒ»ç”»åƒ:**")
                try:
                    # âš ï¸ ä¿®æ­£ç‚¹: width=800 ã§æ¨ªå¹…ã‚’800ãƒ”ã‚¯ã‚»ãƒ«ã«åˆ¶é™
                    st.image(
                        url, 
                        caption="", 
                        width=800 # æ¨ªå¹…ã‚’800ãƒ”ã‚¯ã‚»ãƒ«ã«å›ºå®šã—ã€é«˜ã•ã¯ç¸¦æ¨ªæ¯”ã«åˆã‚ã›ã¦è‡ªå‹•èª¿æ•´
                    )
                except Exception:
                    # ç”»åƒè¡¨ç¤ºå¤±æ•—æ™‚ã¯è­¦å‘Šã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º
                    st.warning("âš ï¸ ç”»åƒã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                    
                # æˆåŠŸãƒ»å¤±æ•—ã«é–¢ã‚ã‚‰ãšã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã¯è¡¨ç¤º
                st.markdown(f"ğŸ”— [ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã/ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰]({url})")
            
            elif is_pdf:
                # PDFã¯ãƒªãƒ³ã‚¯ã®ã¿
                st.info(f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ç›´æ¥è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚")
                st.markdown(f"ğŸ”— [ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã/ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰]({url})")

            else:
                # ãã®ä»–ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ãƒªãƒ³ã‚¯ã¨ã—ã¦æä¾›
                st.markdown(f"ğŸ”— [ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã/ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰]({url})")

    except Exception as e:
        st.error(f"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

def page_epi_note_list():
    detail_cols = [EPI_COL_TIMESTAMP, EPI_COL_CATEGORY, EPI_COL_NOTE_TYPE, EPI_COL_MEMO, EPI_COL_FILENAME]
    page_data_list(
        sheet_name=SHEET_EPI_DATA,
        title="ã‚¨ãƒ”ãƒãƒ¼ãƒˆ",
        col_time=EPI_COL_TIMESTAMP,
        col_filter=EPI_COL_CATEGORY,
        col_memo=EPI_COL_MEMO,
        col_url=EPI_COL_FILE_URL,
        detail_cols=detail_cols,
        col_filename=EPI_COL_FILENAME
    )
# ... (å¾Œç•¥: page_mainte_list ãªã©ã€ä»–ã®ãƒªã‚¹ãƒˆè¡¨ç¤ºé–¢æ•°ã‚‚ã™ã¹ã¦ page_data_list ã‚’å‘¼ã³å‡ºã—ã¦ãŠã‚Šã€page_data_list ãŒ display_attached_files ã‚’å‘¼ã³å‡ºã—ã¦ã„ã‚‹ãŸã‚ã€è‡ªå‹•çš„ã«æ–°ã—ã„è¡¨ç¤ºæ–¹æ³•ãŒé©ç”¨ã•ã‚Œã¾ã™ã€‚) ...

# ---------------------------
# --- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£å‚ç…§ ---
# ---------------------------
# å‰åŠéƒ¨ã‚’åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¾ã¨ã‚ãªã„å ´åˆã¯ import ã§å‘¼ã¶ï¼ˆä¾‹: from bennriyasann3_fixed_v2_part1 import *ï¼‰
# ã“ã“ã§ã¯ã€ŒåŒä¸€å®Ÿè¡Œç’°å¢ƒã«part1ãŒãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ã€ã¨ä»®å®šã—ã¾ã™ã€‚

# ---------------------------
# --- æ±ç”¨çš„ãªä¸€è¦§è¡¨ç¤ºé–¢æ•° ---
# ---------------------------
def page_data_list(sheet_name, title, col_time, col_filter=None, col_memo=None, col_url=None, detail_cols=None, col_filename=None):
    """æ±ç”¨çš„ãªãƒ‡ãƒ¼ã‚¿ä¸€è¦§ãƒšãƒ¼ã‚¸"""
    st.header(f"ğŸ“š {title} ä¸€è¦§")
    df = get_sheet_as_df(SPREADSHEET_NAME, sheet_name)

    if df.empty:
        st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    st.subheader("çµã‚Šè¾¼ã¿ã¨æ¤œç´¢")

    # ãƒ•ã‚£ãƒ«ã‚¿åˆ—ãŒã‚ã‚Œã°é¸æŠè‚¢ã‚’è¡¨ç¤º
    if col_filter and col_filter in df.columns:
        df[col_filter] = df[col_filter].fillna('ãªã—')
        options = ["ã™ã¹ã¦"] + sorted(list(df[col_filter].unique()))
        sel = st.selectbox(f"ã€Œ{col_filter}ã€ã§çµã‚Šè¾¼ã¿", options)
        if sel != "ã™ã¹ã¦":
            df = df[df[col_filter] == sel]

    # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åˆ—ãŒã‚ã‚‹å ´åˆï¼‰
    if col_time and col_time in df.columns:
        try:
            df['date_only'] = pd.to_datetime(
                df[col_time].astype(str).str.replace(r'[^0-9]', '', regex=True).str[:8],
                errors='coerce', format='%Y%m%d'
            ).dt.date
        except Exception:
            df['date_only'] = pd.NaT

        df_valid = df.dropna(subset=['date_only'])
        if not df_valid.empty:
            min_date = df_valid['date_only'].min()
            max_date = df_valid['date_only'].max()
            # å­˜åœ¨ã—ãªã„æ—¥ä»˜ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«ã™ã‚‹ã¨ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ãŸã‚ã€é©åˆ‡ãªãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’è¨­å®š
            default_start = min(date(2025, 4, 1), max_date) if isinstance(max_date, date) else date(2025, 4, 1)
            start_date = st.date_input("é–‹å§‹æ—¥", value=max(min_date, default_start) if isinstance(min_date, date) else default_start)
            end_date = st.date_input("çµ‚äº†æ—¥", value=max_date)
            df = df_valid[(df_valid['date_only'] >= start_date) & (df_valid['date_only'] <= end_date)].drop(columns=['date_only'])

    if df.empty:
        st.info("çµã‚Šè¾¼ã¿æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    df = df.sort_values(by=col_time, ascending=False).reset_index(drop=True)

    st.markdown("---")
    st.subheader(f"æ¤œç´¢çµæœ ({len(df)} ä»¶)")

    # è¡¨ç¤ºç”¨ã®é¸æŠãƒœãƒƒã‚¯ã‚¹ï¼ˆè¡Œã‚’é¸ã¶ã¨è©³ç´°è¡¨ç¤ºï¼‰
    df['display_index'] = df.index
    def fmt(i):
        row = df.loc[i]
        t = str(row[col_time]) if col_time in row and pd.notna(row[col_time]) else ""
        filt = row[col_filter] if col_filter and col_filter in row and pd.notna(row[col_filter]) else ""
        memo_preview = row[col_memo].split('\n')[0] if col_memo and col_memo in row and pd.notna(row[col_memo]) else ""
        return f"[{t.split('_')[0]}] {filt} - {memo_preview[:50]}"

    sel_idx = st.selectbox("è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹è¨˜éŒ²ã‚’é¸æŠ", options=df['display_index'], format_func=fmt)

    if sel_idx is not None:
        row = df.loc[sel_idx]
        st.markdown(f"#### é¸æŠã•ã‚ŒãŸè¨˜éŒ² (ID: {sel_idx+1})")
        
        # ğŸ‘‡ NameErrorã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã€ã“ã“ã§å®šç¾©ã—ã¾ã™
        cols_to_skip = [col_url, col_filename] 
        
        if detail_cols:
            for c in detail_cols:
                # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ—ã§ã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—
                if c in cols_to_skip:
                    continue
                    
                if c in row and pd.notna(row[c]):
                    # ãƒ¡ãƒ¢ã‚„é•·æ–‡ã¯ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
                    if col_memo == c or 'å†…å®¹' in c or len(str(row[c])) > 200:
                        st.markdown(f"**{c}:**")
                        st.text(row[c])
                    else:
                        st.write(f"**{c}:** {row[c]}")

        # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡¨ç¤º
        if col_url and col_url in row:
            st.markdown("##### æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«")
            display_attached_files(row, col_url, col_filename)
# ---------------------------
# --- ã‚¨ãƒ”ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_epi_note_recording():
    st.markdown("#### ğŸ“ æ–°ã—ã„ã‚¨ãƒ”ãƒãƒ¼ãƒˆã‚’è¨˜éŒ²")
    with st.form(key='epi_note_form'):
        col1, col2 = st.columns(2)
        with col1:
            ep_category = st.selectbox(f"{EPI_COL_CATEGORY} (è£…ç½®ç¨®åˆ¥)", ["D1", "D2", "ãã®ä»–"], key='ep_category_input')
        with col2:
            ep_title = st.text_input("ç•ªå· (ä¾‹: 791) (å¿…é ˆ)", key='ep_title_input')
        ep_memo = st.text_area("æ§‹é€  (ä¾‹: 10nm GaAs/AlGaAs/GaAs) (ç©ºç™½ã§ã‚‚å¯)", height=100, key='ep_memo_input')
        uploaded_files = st.file_uploader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« (ç”»åƒã€ã‚°ãƒ©ãƒ•ãªã©)", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], accept_multiple_files=True)
        st.markdown("---")
        submit_button = st.form_submit_button(label='è¨˜éŒ²ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜')

    if submit_button:
        if not ep_title:
            st.warning("ç•ªå· (ä¾‹: 791) ã¯å¿…é ˆé …ç›®ã§ã™ã€‚")
            return
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    filename, url = upload_file_to_gcs(storage_client, file_obj, "ep_notes")
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)
        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        memo_content = f"{ep_title}\n{ep_memo}"
        row_data = [timestamp, EPI_COL_NOTE_TYPE, ep_category, memo_content, filenames_json, urls_json]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_EPI_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ã‚¨ãƒ”ãƒãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_epi_note_list():
    detail_cols = [EPI_COL_TIMESTAMP, EPI_COL_CATEGORY, EPI_COL_NOTE_TYPE, EPI_COL_MEMO, EPI_COL_FILENAME]
    page_data_list(
        sheet_name=SHEET_EPI_DATA,
        title="ã‚¨ãƒ”ãƒãƒ¼ãƒˆ",
        col_time=EPI_COL_TIMESTAMP,
        col_filter=EPI_COL_CATEGORY,
        col_memo=EPI_COL_MEMO,
        col_url=EPI_COL_FILE_URL,
        detail_cols=detail_cols,
        col_filename=EPI_COL_FILENAME
    )

def page_epi_note():
    st.header("ã‚¨ãƒ”ãƒãƒ¼ãƒˆæ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="epi_tab", horizontal=True)
    if tab == "ğŸ“ è¨˜éŒ²":
        page_epi_note_recording()
    else:
        page_epi_note_list()

# ---------------------------
# --- ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_mainte_recording():
    st.markdown("#### ğŸ› ï¸ æ–°ã—ã„ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆã‚’è¨˜éŒ²")
    with st.form(key='mainte_note_form'):
        mainte_title = st.text_input("ãƒ¡ãƒ³ãƒ†ã‚¿ã‚¤ãƒˆãƒ« (ä¾‹: D1 ãƒ‰ãƒ©ã‚¤ãƒãƒ³ãƒ—äº¤æ›) (å¿…é ˆ)", key='mainte_title_input')
        memo_content = st.text_area("è©³ç´°ãƒ¡ãƒ¢", height=150, key='mainte_memo_input')
        uploaded_files = st.file_uploader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« (ç”»åƒã€ã‚°ãƒ©ãƒ•ãªã©)", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], accept_multiple_files=True)
        st.markdown("---")
        submit_button = st.form_submit_button(label='è¨˜éŒ²ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜')
    if submit_button:
        if not mainte_title:
            st.warning("ãƒ¡ãƒ³ãƒ†ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    filename, url = upload_file_to_gcs(storage_client, file_obj, "mainte_notes")
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)
        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        memo_to_save = f"[{mainte_title}]\n{memo_content}"
        row_data = [timestamp, MAINT_COL_NOTE_TYPE, memo_to_save, filenames_json, urls_json]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_MAINTE_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_mainte_list():
    detail_cols = [MAINT_COL_TIMESTAMP, MAINT_COL_NOTE_TYPE, MAINT_COL_MEMO, MAINT_COL_FILENAME]
    page_data_list(
        sheet_name=SHEET_MAINTE_DATA,
        title="ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ",
        col_time=MAINT_COL_TIMESTAMP,
        col_filter=MAINT_COL_NOTE_TYPE,
        col_memo=MAINT_COL_MEMO,
        col_url=MAINT_COL_FILE_URL,
        detail_cols=detail_cols,
        col_filename=MAINT_COL_FILENAME
    )

def page_mainte_note():
    st.header("ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆæ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="mainte_tab", horizontal=True)
    if tab == "ğŸ“ è¨˜éŒ²":
        page_mainte_recording()
    else:
        page_mainte_list()

# ---------------------------
# --- è­°äº‹éŒ²ãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_meeting_recording():
    st.markdown("#### ğŸ“ æ–°ã—ã„è­°äº‹éŒ²ã‚’è¨˜éŒ²")
    with st.form(key='meeting_form'):
        meeting_title = st.text_input(f"{MEETING_COL_TITLE} (ä¾‹: 2025-10-28 å®šä¾‹ä¼šè­°)", key='meeting_title_input')
        meeting_content = st.text_area(f"{MEETING_COL_CONTENT}", height=300, key='meeting_content_input')
        col1, col2 = st.columns(2)
        with col1:
            audio_name = st.text_input(f"{MEETING_COL_AUDIO_NAME} (ä¾‹: audio.m4a)", key='audio_name_input')
        with col2:
            audio_url = st.text_input(f"{MEETING_COL_AUDIO_URL} (Google Drive URLãªã©)", key='audio_url_input')
        submit_button = st.form_submit_button(label='è¨˜éŒ²ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜')
    if submit_button:
        if not meeting_title or not meeting_content:
            st.warning("ä¼šè­°ã‚¿ã‚¤ãƒˆãƒ«ã¨è­°äº‹éŒ²å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        row_data = [timestamp, meeting_title, audio_name, audio_url, meeting_content]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_MEETING_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… è­°äº‹éŒ²ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_meeting_list():
    detail_cols = [MEETING_COL_TIMESTAMP, MEETING_COL_TITLE, MEETING_COL_CONTENT, MEETING_COL_AUDIO_NAME, MEETING_COL_AUDIO_URL]
    page_data_list(
        sheet_name=SHEET_MEETING_DATA,
        title="è­°äº‹éŒ²",
        col_time=MEETING_COL_TIMESTAMP,
        col_filter=MEETING_COL_TITLE,
        col_memo=MEETING_COL_CONTENT,
        col_url=MEETING_COL_AUDIO_URL,
        detail_cols=detail_cols,
        col_filename=MEETING_COL_AUDIO_NAME
    )

def page_meeting_note():
    st.header("è­°äº‹éŒ²ãƒ»ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ãƒ¢æ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="meeting_tab", horizontal=True)
    if tab == "ğŸ“ è¨˜éŒ²":
        page_meeting_recording()
    else:
        page_meeting_list()

# ---------------------------
# --- çŸ¥æµè¢‹ãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_qa_recording():
    st.markdown("#### ğŸ’¡ æ–°ã—ã„è³ªå•ã‚’æŠ•ç¨¿")
    with st.form(key='qa_form'):
        qa_title = st.text_input(f"{QA_COL_TITLE} (ä¾‹: XRDã®æ¸¬å®šæ‰‹é †ã«ã¤ã„ã¦)", key='qa_title_input')
        qa_content = st.text_area(f"{QA_COL_CONTENT}", height=200, key='qa_content_input')
        col1, col2 = st.columns(2)
        with col1:
            qa_contact = st.text_input(f"{QA_COL_CONTACT} (ä»»æ„)", key='qa_contact_input')
        with col2:
            uploaded_files = st.file_uploader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], accept_multiple_files=True)
        st.markdown("---")
        submit_button = st.form_submit_button(label='è³ªå•ã‚’æŠ•ç¨¿')
    if submit_button:
        if not qa_title or not qa_content:
            st.warning("è³ªå•ã‚¿ã‚¤ãƒˆãƒ«ã¨è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    filename, url = upload_file_to_gcs(storage_client, file_obj, "qa_files")
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)
        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        row_data = [timestamp, qa_title, qa_content, qa_contact, filenames_json, urls_json, "æœªè§£æ±º"]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_QA_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… è³ªå•ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_qa_list():
    detail_cols = [QA_COL_TIMESTAMP, QA_COL_TITLE, QA_COL_CONTENT, QA_COL_CONTACT, QA_COL_STATUS, QA_COL_FILENAME]
    page_data_list(
        sheet_name=SHEET_QA_DATA,
        title="çŸ¥æµè¢‹ãƒ»è³ªå•ç®±",
        col_time=QA_COL_TIMESTAMP,
        col_filter=QA_COL_STATUS,
        col_memo=QA_COL_CONTENT,
        col_url=QA_COL_FILE_URL,
        detail_cols=detail_cols,
        col_filename=QA_COL_FILENAME
    )

def page_qa_box():
    st.header("çŸ¥æµè¢‹ãƒ»è³ªå•ç®±æ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ’¡ è³ªå•æŠ•ç¨¿", "ğŸ“š è³ªå•ä¸€è¦§"], key="qa_tab", horizontal=True)
    if tab == "ğŸ’¡ è³ªå•æŠ•ç¨¿":
        page_qa_recording()
    else:
        page_qa_list()

# ---------------------------
# --- å¼•ãç¶™ããƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_handover_recording():
    st.markdown("#### ğŸ¤ æ–°ã—ã„å¼•ãç¶™ããƒ¡ãƒ¢ã‚’è¨˜éŒ²")
    with st.form(key='handover_form'):
        handover_type = st.selectbox(f"{HANDOVER_COL_TYPE} (ã‚«ãƒ†ã‚´ãƒª)", ["ãƒãƒ‹ãƒ¥ã‚¢ãƒ«", "è£…ç½®è¨­å®š", "ãã®ä»–ãƒ¡ãƒ¢"])
        handover_title = st.text_input(f"{HANDOVER_COL_TITLE} (ä¾‹: D1 MBEèµ·å‹•æ‰‹é †)", key='handover_title_input')
        handover_memo = st.text_area(f"{HANDOVER_COL_MEMO}", height=150, key='handover_memo_input')
        st.markdown("---")
        submit_button = st.form_submit_button(label='è¨˜éŒ²ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜')
    if submit_button:
        if not handover_title:
            st.warning("ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        row_data = [timestamp, handover_type, handover_title, handover_memo, "", "", ""]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_HANDOVER_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… å¼•ãç¶™ããƒ¡ãƒ¢ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_handover_list():
    detail_cols = [HANDOVER_COL_TIMESTAMP, HANDOVER_COL_TYPE, HANDOVER_COL_TITLE, 'å†…å®¹1', 'å†…å®¹2', 'å†…å®¹3', HANDOVER_COL_MEMO]
    page_data_list(
        sheet_name=SHEET_HANDOVER_DATA,
        title="è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢",
        col_time=HANDOVER_COL_TIMESTAMP,
        col_filter=HANDOVER_COL_TYPE,
        col_memo=HANDOVER_COL_TITLE,
        col_url='å†…å®¹1',
        detail_cols=detail_cols,
        col_filename=None
    )

def page_handover_note():
    st.header("è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢æ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="handover_tab", horizontal=True)
    if tab == "ğŸ“ è¨˜éŒ²":
        page_handover_recording()
    else:
        page_handover_list()

# ---------------------------
# --- ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_trouble_recording():
    st.markdown("#### ğŸš¨ æ–°ã—ã„ãƒˆãƒ©ãƒ–ãƒ«ã‚’å ±å‘Š")
    DEVICE_OPTIONS = ["MBE", "XRD", "PL", "IV", "TEMãƒ»SEM", "æŠµæŠ—åŠ ç†±è’¸ç€", "RTA", "ãƒ•ã‚©ãƒˆãƒªã‚½", "ãƒ‰ãƒ©ãƒ•ã‚¿ãƒ¼", "ãã®ä»–"]
    with st.form(key='trouble_form'):
        st.subheader("åŸºæœ¬æƒ…å ±")
        col1, col2 = st.columns(2)
        with col1:
            report_date = st.date_input(f"{TROUBLE_COL_OCCUR_DATE} (ç™ºç”Ÿæ—¥)", datetime.now().date())
        with col2:
            device_to_save = st.selectbox(f"{TROUBLE_COL_DEVICE} (æ©Ÿå™¨/å ´æ‰€)", DEVICE_OPTIONS, key='device_input')
        report_title = st.text_input(f"{TROUBLE_COL_TITLE} (ä»¶å/ã‚¿ã‚¤ãƒˆãƒ«) (å¿…é ˆ)", key='trouble_title_input')
        occur_time = st.text_area(f"{TROUBLE_COL_OCCUR_TIME} (çŠ¶æ³è©³ç´°)", height=100)
        st.subheader("å¯¾å¿œã¨è€ƒå¯Ÿ")
        cause = st.text_area(f"{TROUBLE_COL_CAUSE} (åŸå› /ç©¶æ˜)", height=100)
        solution = st.text_area(f"{TROUBLE_COL_SOLUTION} (å¯¾ç­–/å¾©æ—§)", height=100)
        prevention = st.text_area(f"{TROUBLE_COL_PREVENTION} (å†ç™ºé˜²æ­¢ç­–)", height=100)
        col3, col4 = st.columns(2)
        with col3:
            reporter_name = st.text_input(f"{TROUBLE_COL_REPORTER} (å ±å‘Šè€…) (å¿…é ˆ)", key='reporter_input')
        with col4:
            uploaded_files = st.file_uploader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], accept_multiple_files=True)
        st.markdown("---")
        submit_button = st.form_submit_button(label='ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šã‚’ä¿å­˜')
    if submit_button:
        if not report_title or not reporter_name:
            st.warning("ã‚¿ã‚¤ãƒˆãƒ«ã¨å ±å‘Šè€…åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    filename, url = upload_file_to_gcs(storage_client, file_obj, "trouble_reports")
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)
        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        row_data = [timestamp, device_to_save, report_date.isoformat(), occur_time, cause, solution, prevention, reporter_name, filenames_json, urls_json, report_title]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_TROUBLE_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_trouble_list():
    detail_cols = [
        TROUBLE_COL_TIMESTAMP, TROUBLE_COL_TITLE, TROUBLE_COL_DEVICE, TROUBLE_COL_OCCUR_DATE,
        TROUBLE_COL_OCCUR_TIME, TROUBLE_COL_CAUSE, TROUBLE_COL_SOLUTION, TROUBLE_COL_PREVENTION,
        TROUBLE_COL_REPORTER, TROUBLE_COL_FILENAME
    ]
    page_data_list(
        sheet_name=SHEET_TROUBLE_DATA,
        title="ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š",
        col_time=TROUBLE_COL_TIMESTAMP,
        col_filter=TROUBLE_COL_DEVICE,
        col_memo=TROUBLE_COL_TITLE,
        col_url=TROUBLE_COL_FILE_URL,
        detail_cols=detail_cols,
        col_filename=TROUBLE_COL_FILENAME
    )

def page_trouble_report():
    st.header("ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šæ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="trouble_tab", horizontal=True)
    if tab == "ğŸ“ è¨˜éŒ²":
        page_trouble_recording()
    else:
        page_trouble_list()

# ---------------------------
# --- é€£çµ¡ãƒ»å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_contact_recording():
    st.markdown("#### âœ‰ï¸ æ–°ã—ã„å•ã„åˆã‚ã›ã‚’è¨˜éŒ²")
    with st.form(key='contact_form'):
        contact_type = st.selectbox(f"{CONTACT_COL_TYPE}", ["ãƒã‚°å ±å‘Š", "æ©Ÿèƒ½è¦æœ›", "ãƒ‡ãƒ¼ã‚¿ä¿®æ­£ä¾é ¼", "ãã®ä»–"])
        contact_detail = st.text_area(f"{CONTACT_COL_DETAIL}", height=150, key='contact_detail_input')
        contact_info = st.text_input(f"{CONTACT_COL_CONTACT} (ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã©ã€ä»»æ„)", key='contact_info_input')
        st.markdown("---")
        submit_button = st.form_submit_button(label='é€ä¿¡')
    if submit_button:
        if not contact_detail:
            st.warning("è©³ç´°å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        row_data = [timestamp, contact_type, contact_detail, contact_info]
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_CONTACT_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ãŠå•ã„åˆã‚ã›ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚")
            st.cache_data.clear()
            st.rerun()
        except Exception as e:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿æ›¸ãè¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def page_contact_list():
    detail_cols = [CONTACT_COL_TIMESTAMP, CONTACT_COL_TYPE, CONTACT_COL_DETAIL, CONTACT_COL_CONTACT]
    page_data_list(
        sheet_name=SHEET_CONTACT_DATA,
        title="é€£çµ¡ãƒ»å•ã„åˆã‚ã›",
        col_time=CONTACT_COL_TIMESTAMP,
        col_filter=CONTACT_COL_TYPE,
        col_memo=CONTACT_COL_DETAIL,
        detail_cols=detail_cols
    )

def page_contact_form():
    st.header("é€£çµ¡ãƒ»å•ã„åˆã‚ã›æ©Ÿèƒ½")
    st.markdown("---")
    tab = st.radio("è¡¨ç¤ºåˆ‡æ›¿", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="contact_tab", horizontal=True)
    if tab == "ğŸ“ è¨˜éŒ²":
        page_contact_recording()
    else:
        page_contact_list()

# ---------------------------
# --- IVãƒ‡ãƒ¼ã‚¿è§£æãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_iv_analysis():
    st.header("âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ")
    uploaded_files = st.file_uploader("IVæ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« (.txt) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['txt'], accept_multiple_files=True)
    if not uploaded_files:
        st.info("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    valid_dataframes = []
    filenames = []
    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¨è§£æ")
    for uploaded_file in uploaded_files:
        # load_data_file ã¯ bytes ã‚’å—ã‘å–ã‚‹ (part1 ã§å®šç¾©)
        df = load_data_file(uploaded_file.getvalue(), uploaded_file.name)
        if df is not None and not df.empty:
            valid_dataframes.append(df)
            filenames.append(uploaded_file.name)

    if not valid_dataframes:
        st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return

    st.success(f"{len(valid_dataframes)} å€‹ã®æœ‰åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")

    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—2: çµåˆ (è£œé–“)")
    combined_df = combine_dataframes(valid_dataframes, filenames)
    if combined_df is None:
        st.error("çµåˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—3: ã‚°ãƒ©ãƒ•è¡¨ç¤º")
    fig, ax = plt.subplots(figsize=(12, 7))
    for filename in filenames:
        ax.plot(combined_df['X_Axis'], combined_df[filename], label=filename)
    ax.set_xlabel("é›»åœ§ (V)")
    ax.set_ylabel("é›»æµ (A)")
    ax.grid(True)
    ax.legend(title="ãƒ•ã‚¡ã‚¤ãƒ«å", loc='best')
    ax.set_title("IVç‰¹æ€§æ¯”è¼ƒ")
    st.pyplot(fig, use_container_width=True)

    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—4: çµåˆãƒ‡ãƒ¼ã‚¿")
    combined_df_display = combined_df.rename(columns={'X_Axis': 'Voltage_V'})
    st.dataframe(combined_df_display.head(50), use_container_width=True)

    # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        combined_df_display.to_excel(writer, sheet_name='Combined IV Data', index=False)
    st.download_button(
        label="ğŸ“ˆ çµåˆExcelãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
        data=output.getvalue(),
        file_name=f"iv_analysis_combined_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    )

# ---------------------------
# --- PLãƒ‡ãƒ¼ã‚¿è§£æãƒšãƒ¼ã‚¸ ---
# ---------------------------
def page_pl_analysis():
    st.header("ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ")
    st.write("ã‚¹ãƒ†ãƒƒãƒ—1ï¼šæ³¢é•·æ ¡æ­£ï¼ˆ2ç‚¹ï¼‰ â†’ ã‚¹ãƒ†ãƒƒãƒ—2ï¼šæ¸¬å®šãƒ‡ãƒ¼ã‚¿è§£æ ã®é †ã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

    # --- ã‚¹ãƒ†ãƒƒãƒ—1: æ ¡æ­£ ---
    with st.expander("ã‚¹ãƒ†ãƒƒãƒ—1ï¼šæ³¢é•·æ ¡æ­£", expanded=True):
        st.write("2ã¤ã®åŸºæº–æ³¢é•·ã®åå°„å…‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€åˆ†å…‰å™¨ã®å‚¾ãï¼ˆnm/pixelï¼‰ã‚’æ ¡æ­£ã—ã¾ã™ã€‚")
        col1, col2 = st.columns(2)
        with col1:
            cal1_wavelength = st.number_input("åŸºæº–æ³¢é•·1 (nm)", value=1500)
            cal1_file = st.file_uploader(f"{cal1_wavelength} nm ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ« (.txt)", type=['txt'], key="pl_cal1")
        with col2:
            cal2_wavelength = st.number_input("åŸºæº–æ³¢é•·2 (nm)", value=1570)
            cal2_file = st.file_uploader(f"{cal2_wavelength} nm ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ« (.txt)", type=['txt'], key="pl_cal2")

        if st.button("æ ¡æ­£ã‚’å®Ÿè¡Œ", key="run_pl_cal"):
            if not (cal1_file and cal2_file):
                st.warning("ä¸¡æ–¹ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
            else:
                df1 = load_pl_data(cal1_file)
                df2 = load_pl_data(cal2_file)
                if df1 is None or df2 is None:
                    st.error("æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ãƒ»å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                else:
                    try:
                        peak_pixel1 = df1['pixel'].iloc[df1['intensity'].idxmax()]
                        peak_pixel2 = df2['pixel'].iloc[df2['intensity'].idxmax()]

                        st.write("---")
                        st.subheader("æ ¡æ­£çµæœ")
                        c1, c2, c3 = st.columns(3)
                        c1.metric(f"{cal1_wavelength} nm ã®ãƒ”ãƒ¼ã‚¯ä½ç½®", f"{int(peak_pixel1)} pixel")
                        c2.metric(f"{cal2_wavelength} nm ã®ãƒ”ãƒ¼ã‚¯ä½ç½®", f"{int(peak_pixel2)} pixel")

                        delta_wave = float(cal2_wavelength - cal1_wavelength)
                        delta_pixel = float(peak_pixel1 - peak_pixel2)
                        if delta_pixel == 0:
                            st.error("2ã¤ã®ãƒ”ãƒ¼ã‚¯ä½ç½®ãŒåŒã˜ã§ã™ã€‚ç•°ãªã‚‹æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚")
                        else:
                            slope = delta_wave / delta_pixel
                            c3.metric("æ ¡æ­£ä¿‚æ•° (nm/pixel)", f"{slope:.6f}")
                            st.session_state['pl_calibrated'] = True
                            st.session_state['pl_slope'] = slope
                            st.session_state['pl_center_wl_cal'] = cal1_wavelength
                            st.session_state['pl_center_pixel_cal'] = peak_pixel1
                            st.success("æ ¡æ­£ä¿‚æ•°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒƒãƒ—2ã«é€²ã‚“ã§ãã ã•ã„ã€‚")
                    except Exception as e:
                        st.error(f"æ ¡æ­£è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    st.write("---")
    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—2ï¼šæ¸¬å®šãƒ‡ãƒ¼ã‚¿è§£æ")

    if not st.session_state.get('pl_calibrated', False):
        st.info("ã¾ãšã‚¹ãƒ†ãƒƒãƒ—1ã®æ³¢é•·æ ¡æ­£ã‚’å®Œäº†ã—ã¦ãã ã•ã„ã€‚")
        return

    # --- ã‚¹ãƒ†ãƒƒãƒ—2: æ¸¬å®šãƒ‡ãƒ¼ã‚¿ã®è§£æ ---
    center_wavelength_input = st.number_input(
        "æ¸¬å®šæ™‚ã®ä¸­å¿ƒæ³¢é•· (nm)", min_value=0, value=1700, step=10,
        help="ã“ã®æ¸¬å®šã§è£…ç½®ã«è¨­å®šã—ãŸä¸­å¿ƒæ³¢é•·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆå‡¡ä¾‹æ•´å½¢ã«ã‚‚åˆ©ç”¨ï¼‰ã€‚"
    )
    uploaded_files = st.file_uploader("æ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['txt'], accept_multiple_files=True, key="pl_measure_files")

    if not uploaded_files:
        st.info("æ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        return

    st.subheader("è§£æçµæœ")
    fig, ax = plt.subplots(figsize=(10, 6))
    all_dataframes = []
    slope = st.session_state['pl_slope']
    center_pixel = 256.5  # ã‚ãªãŸã®æ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã‚’ãã®ã¾ã¾ä½¿ç”¨

    for uploaded_file in uploaded_files:
        df = load_pl_data(uploaded_file)
        if df is None:
            st.warning(f"{uploaded_file.name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            continue

        # æ³¢é•·å¤‰æ›
        df['wavelength_nm'] = (df['pixel'] - center_pixel) * slope + center_wavelength_input

        base_name = os.path.splitext(uploaded_file.name)[0]
        cleaned_label = base_name.replace(str(int(center_wavelength_input)), "").strip(' _-')
        label = cleaned_label if cleaned_label else base_name

        ax.plot(df['wavelength_nm'], df['intensity'], label=label, linewidth=2.5)

        export_df = df[['wavelength_nm', 'intensity']].copy()
        export_df.rename(columns={'intensity': base_name}, inplace=True)
        all_dataframes.append(export_df)

    if not all_dataframes:
        st.warning("æœ‰åŠ¹ãªæ¸¬å®šãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # çµåˆï¼ˆæ³¢é•·ã‚’ã‚­ãƒ¼ã«å¤–éƒ¨çµåˆï¼‰
    final_df = all_dataframes[0]
    for i in range(1, len(all_dataframes)):
        final_df = pd.merge(final_df, all_dataframes[i], on='wavelength_nm', how='outer')

    final_df = final_df.sort_values(by='wavelength_nm').reset_index(drop=True)

    # ã‚°ãƒ©ãƒ•æ•´å½¢
    ax.set_title(f"PL spectrum (Center: {center_wavelength_input} nm)")
    ax.set_xlabel("Wavelength [nm]")
    ax.set_ylabel("PL intensity [a.u.]")
    ax.legend(loc='upper left', frameon=False, fontsize=10)
    ax.grid(axis='y', linestyle='-', color='lightgray', zorder=0)
    ax.tick_params(direction='in', top=True, right=True, which='both')

    # x ç¯„å›²ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
    min_wl = final_df['wavelength_nm'].min()
    max_wl = final_df['wavelength_nm'].max()
    if pd.notna(min_wl) and pd.notna(max_wl) and max_wl > min_wl:
        padding = (max_wl - min_wl) * 0.05
        ax.set_xlim(min_wl - padding, max_wl + padding)

    st.pyplot(fig, use_container_width=True)

    # Excel å‡ºåŠ›ï¼ˆopenpyxl ã‚’ä½¿ç”¨ï¼‰
    output = BytesIO()
    try:
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            final_df.to_excel(writer, index=False, sheet_name='Combined PL Data')
        processed_data = output.getvalue()
        st.download_button(
            label="ğŸ“ˆ Excelãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=processed_data,
            file_name=f"pl_analysis_combined_{center_wavelength_input}nm.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    except Exception as e:
        st.error(f"Excelå‡ºåŠ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# --------------------------
# --- äºˆç´„ãƒ»ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸ï¼ˆæ¡ä»¶ä»˜ãå…¥åŠ›æ¬„è¡¨ç¤ºä¿®æ­£ç‰ˆï¼‰ ---
# --------------------------
# Google Calendar APIæ¥ç¶šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
def get_calendar_service():
    """Streamlit Secretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’å–å¾—ã—ã€Google Calendar APIã®ã‚µãƒ¼ãƒ“ã‚¹ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ§‹ç¯‰ã™ã‚‹"""
    
    # âš ï¸ ã“ã“ã‚’ gcs_credentials ã«å¤‰æ›´ã—ã¾ã™ âš ï¸
    SECRETS_KEY_NAME = "gcs_credentials"
    
    try:
        # 1. Secrets ã‹ã‚‰éµæƒ…å ±ã‚’å–å¾—
        secret_content = st.secrets[SECRETS_KEY_NAME] 

        # 2. å–å¾—ã—ãŸå†…å®¹ã‚’ã€JSONã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹
        if isinstance(secret_content, str):
            # SecretsãŒJSONæ–‡å­—åˆ—ã¨ã—ã¦ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹å ´åˆ
            json_info = json.loads(secret_content)
        elif isinstance(secret_content, dict):
            # SecretsãŒTOMLå½¢å¼ï¼ˆè¾æ›¸å‹ï¼‰ã¨ã—ã¦æ­£ã—ãç™»éŒ²ã•ã‚Œã¦ã„ã‚‹å ´åˆ
            json_info = secret_content
        else:
            st.error(f"ã‚¨ãƒ©ãƒ¼: Secretsã®ã‚­ãƒ¼ '{SECRETS_KEY_NAME}' ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ãŒä¸æ­£ã§ã™ã€‚")
            return None

        # ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼æƒ…å ±ã‚’ä½œæˆ
        creds = service_account.Credentials.from_service_account_info(
            json_info, scopes=SCOPES
        )
        
        # Calendar APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’ä½œæˆ
        service = build('calendar', 'v3', credentials=creds)
        return service

    except KeyError:
        # éµãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚‚ã‚­ãƒ¼åã«åˆã‚ã›ã¦ä¿®æ­£
        st.error(f"é‡å¤§ã‚¨ãƒ©ãƒ¼: Streamlit Secretsã«ã‚­ãƒ¼ '{SECRETS_KEY_NAME}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        st.caption(f"Secretsè¨­å®šç”»é¢ã§ã€ã‚­ãƒ¼åãŒ [{SECRETS_KEY_NAME}] ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„ã€‚")
        return None
    except json.JSONDecodeError:
        st.error(f"ã‚¨ãƒ©ãƒ¼: Secretsã®ã‚­ãƒ¼ '{SECRETS_KEY_NAME}' ã«ç™»éŒ²ã•ã‚ŒãŸéµæƒ…å ±ãŒä¸æ­£ãªJSONå½¢å¼ã§ã™ã€‚")
        st.caption("ç™»éŒ²å†…å®¹ã«ä½™è¨ˆãªæ–‡å­—ã‚„å¼•ç”¨ç¬¦ãŒå«ã¾ã‚Œã¦ã„ãªã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return None
    except Exception as e:
        # ... (ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼å‡¦ç†)
        if isinstance(e, HttpError):
            st.error(f"ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼APIã‚¨ãƒ©ãƒ¼: æ¨©é™ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚è©³ç´°: {e.content.decode()}")
        else:
            st.error(f"Google Calendar APIã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None
# --------------------------
# --- äºˆç´„ãƒ»ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒšãƒ¼ã‚¸ï¼ˆGoogleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼è‡ªå‹•ç™»éŒ²ç‰ˆï¼‰ ---
# --------------------------
def page_calendar():
    st.header("ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„")
    
    # ã‚«ãƒ†ã‚´ãƒªã®å®šç¾©ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ä¸Šéƒ¨ã®å®šæ•°ã¨ã—ã¦å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã—ã¾ã™ï¼‰
    try:
        CATEGORY_OPTIONS
    except NameError:
        # æš«å®šçš„ãªå®šç¾©
        CATEGORY_OPTIONS = ["D1ã‚¨ãƒ”", "D2ã‚¨ãƒ”", "MBEãƒ¡ãƒ³ãƒ†", "XRD", "PL", "AFM", "ãƒ•ã‚©ãƒˆãƒªã‚½", "ã‚¢ãƒ‹ãƒ¼ãƒ«", "è’¸ç€", "ãã®ä»–å…¥åŠ›"]

    # --- 1. å¤–éƒ¨äºˆç´„ã‚µã‚¤ãƒˆã¸ã®ãƒªãƒ³ã‚¯ï¼ˆçœç•¥ï¼‰ ---
    st.subheader("å¤–éƒ¨äºˆç´„ã‚µã‚¤ãƒˆ")
    col_evers, col_rac = st.columns(2)
    evers_url = "https://www.eiiris.tut.ac.jp/evers/Web/dashboard.php"
    col_evers.markdown(
        f'<a href="{evers_url}" target="_blank">'
        f'<button style="width:100%; height:40px; background-color:#4CAF50; color:white; border:none; border-radius:5px; cursor:pointer;">'
        f'Evers äºˆç´„ã‚µã‚¤ãƒˆã¸ã‚¢ã‚¯ã‚»ã‚¹</button></a>',
        unsafe_allow_html=True
    )
    col_evers.caption("ï¼ˆå­¦å†…å…±ç”¨è£…ç½®äºˆç´„ã‚·ã‚¹ãƒ†ãƒ ï¼‰")
    rac_url = "https://tech.rac.tut.ac.jp/regist/potal_0.php"
    col_rac.markdown(
        f'<a href="{rac_url}" target="_blank">'
        f'<button style="width:100%; height:40px; background-color:#2196F3; color:white; border:none; border-radius:5px; cursor:pointer;">'
        f'æ•™è‚²ç ”ç©¶åŸºç›¤ã‚»ãƒ³ã‚¿ãƒ¼ ãƒãƒ¼ã‚¿ãƒ«ã¸</button></a>',
        unsafe_allow_html=True
    )
    col_rac.caption("ï¼ˆå…±ç”¨æ–½è¨­åˆ©ç”¨ç™»éŒ²ï¼‰")
    st.markdown("---")
    
    # --- 2. Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®åŸ‹ã‚è¾¼ã¿ï¼ˆçœç•¥ï¼‰ ---
    st.subheader("äºˆç´„ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ï¼ˆGoogleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ï¼‰")
    # CALENDAR_ID ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹å‰æ
    try:
        CALENDAR_ID
    except NameError:
        # æš«å®šçš„ãªå®šç¾©ï¼ˆã‚¨ãƒ©ãƒ¼é˜²æ­¢ï¼‰
        CALENDAR_ID = "yamane.lab.6747@gmail.com"

    calendar_html = f"""
    <iframe src="https://calendar.google.com/calendar/embed?height=600&wkst=1&bgcolor=%23ffffff&ctz=Asia%2FTokyo&src={CALENDAR_ID}&color=%237986CB&showTitle=0&showPrint=0&showCalendars=0&showTz=0" style="border-width:0" width="100%" height="600" frameborder="0" scrolling="no"></iframe>
    """
    st.markdown(calendar_html, unsafe_allow_html=True)
    st.caption("ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®äºˆç´„çŠ¶æ³ã‚’ç¢ºèªã—ã€ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒ ã‹ã‚‰äºˆå®šã‚’ç™»éŒ²ã—ã¦ãã ã•ã„ã€‚")
    st.markdown("---") 

    # -----------------------------------------------------
    # --- 3. äºˆç´„ç™»éŒ²ã®åˆ¶å¾¡éƒ¨åˆ†ï¼ˆãƒ•ã‚©ãƒ¼ãƒ å¤–ã§å³æ™‚å¿œç­”ã‚’å®Ÿç¾ï¼‰ ---
    # -----------------------------------------------------
    st.subheader("ğŸ—“ï¸ æ–°è¦äºˆå®šã®ç™»éŒ²")
    
    initial_user_name = st.session_state.get('user_name', '')
    
    # --- ãƒ•ã‚©ãƒ¼ãƒ ã®å¤–ã«é…ç½®ã™ã‚‹è¦ç´ : ã‚«ãƒ†ã‚´ãƒªé¸æŠã¨ã‚«ã‚¹ã‚¿ãƒ å…¥åŠ›æ¬„ ---
    col_cat, col_other = st.columns([1, 2])
    
    with col_cat:
        category = st.selectbox("ä½œæ¥­/è£…ç½®ã‚«ãƒ†ã‚´ãƒª", CATEGORY_OPTIONS, key="category_select_outside")
        
    custom_category = ""
    with col_other:
        if category == "ãã®ä»–å…¥åŠ›":
            custom_category = st.text_input(
                "ã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ†ã‚´ãƒªã‚’ç›´æ¥å…¥åŠ›", 
                placeholder="ä¾‹: å­¦ä¼šç™ºè¡¨æº–å‚™", 
                key="custom_category_input_cal_outside"
            ) 
    
    # æœ€çµ‚ã‚«ãƒ†ã‚´ãƒªåã‚’æ±ºå®š (submitãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚Œã‚‹å‰ã«ç¢ºå®š)
    final_category = custom_category if category == "ãã®ä»–å…¥åŠ›" else category
    
    # ğŸ’¡ ãƒ•ã‚©ãƒ¼ãƒ ã®å¤–ã§ã¯ã€ã‚¿ã‚¤ãƒˆãƒ«ã¯ä»®è¡¨ç¤ºã«ç•™ã‚ã‚‹ï¼ˆãƒ‡ã‚¶ã‚¤ãƒ³èª¿æ•´ã®ãŸã‚ã“ã®è¡Œã‚’å‰Šé™¤ã¾ãŸã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
    # st.markdown(f"**ğŸ’¡ äºˆå®šã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆç™»éŒ²è€…åå…¥åŠ›å¾Œç¢ºå®šï¼‰:** `{initial_user_name} ({final_category})`")
    st.markdown("---") 

    # -----------------------------------------------------
    # --- 4. ãƒ•ã‚©ãƒ¼ãƒ æœ¬ä½“ ---
    # -----------------------------------------------------
    with st.form(key='schedule_form'):
        
        # 1. ç™»éŒ²è€…å
        user_name = st.text_input("ç™»éŒ²è€…å / ã‚°ãƒ«ãƒ¼ãƒ—å", value=initial_user_name)
        
        # 2. é¸æŠã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒªã®è¡¨ç¤ºã‚’ãƒ•ã‚©ãƒ¼ãƒ å†…ã«ç§»å‹•
        # ğŸ’¡ ã“ã‚ŒãŒã€Œæ ã‹ã‚‰ã¯ã¿å‡ºã•ãªã„ã€ãŸã‚ã®ä¿®æ­£ã§ã™ã€‚
        st.markdown(f"**ğŸ“š é¸æŠã•ã‚ŒãŸã‚«ãƒ†ã‚´ãƒª:** `{final_category}`") 
        
        # 3. äºˆå®šã‚¿ã‚¤ãƒˆãƒ«ã‚’è¨ˆç®—ã—è¡¨ç¤º
        final_title_preview = f"{user_name} ({final_category})" if user_name and final_category else ""
        st.markdown(f"**ğŸ’¡ äºˆå®šã®ã‚¿ã‚¤ãƒˆãƒ«:** `{final_title_preview}`")

        st.markdown("---")
        
        # 4. é–‹å§‹æ—¥æ™‚ã¨çµ‚äº†æ—¥æ™‚
        st.markdown("##### äºˆå®šæ—¥æ™‚")
        
        cols_start_date, cols_start_time = st.columns(2)
        start_date = cols_start_date.date_input("é–‹å§‹æ—¥", value=date.today())
        start_time_str = cols_start_time.text_input("é–‹å§‹æ™‚åˆ» (ä¾‹: 09:00)", value="09:00")

        cols_end_date, cols_end_time = st.columns(2)
        end_date = cols_end_date.date_input("çµ‚äº†æ—¥", value=date.today())
        end_time_str = cols_end_time.text_input("çµ‚äº†æ™‚åˆ» (ä¾‹: 11:00)", value="11:00")
        
        # 5. è©³ç´°ï¼ˆãƒ¡ãƒ¢ï¼‰
        detail = st.text_area("è©³ç´°ï¼ˆäºˆå®šã®å†…å®¹ï¼‰", height=100)
        
        submit_button = st.form_submit_button(label='â¬†ï¸ Googleã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«è‡ªå‹•ç™»éŒ²')

        if submit_button:
            # ãƒ•ã‚©ãƒ¼ãƒ å†…ã® user_name ã¨ã€ãƒ•ã‚©ãƒ¼ãƒ å¤–ã® final_category ã‚’ä½¿ç”¨
            if not user_name or not final_category:
                st.error("ã€Œç™»éŒ²è€…åã€ã¨ã€Œä½œæ¥­ã‚«ãƒ†ã‚´ãƒªã€ã¯å¿…é ˆã§ã™ã€‚")
                return 
            
            # æœ€çµ‚ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç¢ºå®š
            final_title = f"{user_name} ({final_category})"

            # ----------------------------------------
            # APIçµŒç”±ã§ç›´æ¥ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«æ›¸ãè¾¼ã¿ 
            # ----------------------------------------
            service = get_calendar_service()
            if service is None:
                return 

            try:
                # æ—¥æ™‚ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç”Ÿæˆ
                # (æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã‚’çœç•¥ã€‚ã“ã“ã§å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚„é–¢æ•°ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’å‰æã¨ã™ã‚‹)
                # datetime.combine, datetime.strptime, HttpError, service_account.Credentials, build, SCOPES...
                
                # ãƒ€ãƒŸãƒ¼ã‚³ãƒ¼ãƒ‰ã‚’å‰Šé™¤ã—ã€å®Ÿéš›ã®å‡¦ç†ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„
                from datetime import datetime
                from googleapiclient.discovery import build
                from googleapiclient.errors import HttpError
                # get_calendar_service ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹å‰æ
                
                start_dt_obj = datetime.combine(start_date, datetime.strptime(start_time_str, '%H:%M').time())
                end_dt_obj = datetime.combine(end_date, datetime.strptime(end_time_str, '%H:%M').time())
                
                if end_dt_obj <= start_dt_obj:
                    st.error("çµ‚äº†æ—¥æ™‚ã¯é–‹å§‹æ—¥æ™‚ã‚ˆã‚Šå¾Œã«è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                    return

                # äºˆå®šã®ãƒœãƒ‡ã‚£ã‚’ä½œæˆ
                event_body = {
                    'summary': final_title,
                    'description': detail,
                    'start': {
                        'dateTime': start_dt_obj.isoformat(),
                        'timeZone': 'Asia/Tokyo',
                    },
                    'end': {
                        'dateTime': end_dt_obj.isoformat(),
                        'timeZone': 'Asia/Tokyo',
                    },
                }

                # APIçµŒç”±ã§äºˆå®šã‚’æŒ¿å…¥
                event = service.events().insert(calendarId=CALENDAR_ID, body=event_body).execute()
                
                st.session_state['user_name'] = user_name 
                st.success(f"äºˆå®š `{final_title}` ãŒã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã«è‡ªå‹•ç™»éŒ²ã•ã‚Œã¾ã—ãŸï¼")
                
                st.rerun() 
                    
            except ValueError:
                st.error("æ™‚åˆ»ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒç„¡åŠ¹ã§ã™ã€‚ã€ŒHH:MMã€ã®å½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            except HttpError as e:
                st.error(f"ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ¨©é™ã¨ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼IDã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚è©³ç´°: {e.content.decode()}")
            except Exception as e:
                st.error(f"äºˆå®šã®ç™»éŒ²ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
# ---------------------------
# --- ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚° ---
# ---------------------------
def main():
    st.sidebar.title("å±±æ ¹ç ” ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ")
    menu_selection = st.sidebar.radio("æ©Ÿèƒ½é¸æŠ", [
        "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ",
        "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ",
        "IVãƒ‡ãƒ¼ã‚¿è§£æ",
        "PLãƒ‡ãƒ¼ã‚¿è§£æ",
        "è­°äº‹éŒ²",
        "çŸ¥æµè¢‹ãƒ»è³ªå•ç®±",
        "è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢",
        "ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š",
        "é€£çµ¡ãƒ»å•ã„åˆã‚ã›",
        "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„"
    ])

    if menu_selection == "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ":
        page_epi_note()
    elif menu_selection == "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ":
        page_mainte_note()
    elif menu_selection == "âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ":
        page_iv_analysis()
    elif menu_selection == "ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ":
        page_pl_analysis()
    elif menu_selection == "è­°äº‹éŒ²":
        page_meeting_note()
    elif menu_selection == "çŸ¥æµè¢‹ãƒ»è³ªå•ç®±":
        page_qa_box()
    elif menu_selection == "è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢":
        page_handover_note()
    elif menu_selection == "ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š":
        page_trouble_report()
    elif menu_selection == "é€£çµ¡ãƒ»å•ã„åˆã‚ã›":
        page_contact_form()
    elif menu_selection == "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„":
        page_calendar()
    else:
        st.info("é¸æŠã—ãŸæ©Ÿèƒ½ã¯æœªå®Ÿè£…ã§ã™ã€‚")

if __name__ == "__main__":
    main()






































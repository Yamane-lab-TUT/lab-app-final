# --------------------------------------------------------------------------
# Yamane Lab Convenience Tool - Streamlit Application (app.py)
#
# v20.6.1 + IVè§£æä¿®æ­£ç‰ˆ (ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹)
# - ãƒ™ãƒ¼ã‚¹: ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ã®v20.6.1 (PLæ³¢é•·æ ¡æ­£å¯¾å¿œç‰ˆ)
# - FIX: IVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ (load_iv_data) ã‚’ãƒ­ãƒã‚¹ãƒˆãªå‡¦ç† (Voltage_Vã®ä¸¸ã‚ã‚’å«ã‚€) ã«ç½®ãæ›ãˆã€
#        è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«çµåˆæ™‚ã®ã‚­ãƒ¼ã®ä¸ä¸€è‡´ã‚¨ãƒ©ãƒ¼ã‚’è§£æ¶ˆã€‚
# - FIX: IVãƒ‡ãƒ¼ã‚¿è§£æ (page_iv_analysis) ã‚’ã€è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«çµåˆãƒ»æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆãƒ»Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¯¾å¿œã—ãŸ
#        æœ€æ–°ã®ãƒ­ã‚¸ãƒƒã‚¯ã«ç½®ãæ›ãˆã€‚
# - CHG: to_excel ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°ã‚’è¿½åŠ ã€‚
# - CHG: ã‚¨ãƒ”ãƒãƒ¼ãƒˆ/ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆã®æ©Ÿèƒ½ã‚’ã€ãƒ‡ãƒ¼ã‚¿é€£æºãƒ­ã‚¸ãƒƒã‚¯ã‚’ä»®å®šã—ã¦å®Œå…¨ãªå½¢ã«è£œå®Œã€‚
# --------------------------------------------------------------------------

import streamlit as st
import gspread
import pandas as pd
import os
import io
import re
import json
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime, date, timedelta
from urllib.parse import quote as url_quote
from io import BytesIO
import calendar
import matplotlib.font_manager as fm

# Google API client libraries (èªè¨¼æƒ…å ±å–å¾—ã®ãŸã‚ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’è£œå®Œ)
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
try:
    from google.cloud import storage
except ImportError:
    st.error("âŒ è­¦å‘Š: `google-cloud-storage` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    pass
from google.auth.exceptions import DefaultCredentialsError
from google.api_core import exceptions
    
# --- Matplotlib æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š ---
try:
    plt.rcParams['font.family'] = 'sans-serif'
    plt.rcParams['font.sans-serif'] = ['Hiragino Maru Gothic Pro', 'Yu Gothic', 'Meiryo', 'TakaoGothic', 'IPAexGothic', 'IPAfont', 'Noto Sans CJK JP'] 
    plt.rcParams['axes.unicode_minus'] = False
except Exception:
    pass
    
# --- Global Configuration & Setup ---
st.set_page_config(page_title="å±±æ ¹ç ” ä¾¿åˆ©å±‹ã•ã‚“", layout="wide")

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# â†“â†“â†“â†“â†“â†“ ã€é‡è¦ã€‘ã”è‡ªèº«ã®ã€Œãƒã‚±ãƒƒãƒˆåã€ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ â†“â†“â†“â†“â†“â†“
CLOUD_STORAGE_BUCKET_NAME = "yamane-lab-app-files" # ä¾‹: "yamane-lab-app-files"
# â†‘â†‘â†‘â†‘â†‘â†‘ ã€é‡è¦ã€‘ã”è‡ªèº«ã®ã€Œãƒã‚±ãƒƒãƒˆåã€ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ â†‘â†‘â†‘â†‘â†‘â†‘
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

SPREADSHEET_NAME = 'ã‚¨ãƒ”ãƒãƒ¼ãƒˆ'
DEFAULT_CALENDAR_ID = 'yamane.lab.6747@gmail.com' # ä¾‹: 'your-calendar-id@group.calendar.google.com'
INQUIRY_RECIPIENT_EMAIL = 'kyuno.yamato.ns@tut.ac.jp' # ä¾‹: 'lab-manager@example.com'


# --- Initialize Google Services ---
@st.cache_resource(show_spinner="Googleã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šä¸­...")
def initialize_google_services():
    """Googleã‚µãƒ¼ãƒ“ã‚¹ï¼ˆSpreadsheet, Calendar, Storageï¼‰ã‚’åˆæœŸåŒ–ã—ã€èªè¨¼æƒ…å ±ã‚’è¨­å®šã™ã‚‹ã€‚"""
    try:
        scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/calendar', 'https://www.googleapis.com/auth/devstorage.read_write']
        
        if "gcs_credentials" not in st.secrets:
            st.error("âŒ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: Streamlit Cloudã®Secretsã« `gcs_credentials` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            class DummyWorksheet:
                def append_row(self, row): pass
                def get_all_values(self): return [[]]
            class DummySpreadsheet:
                def worksheet(self, name): return DummyWorksheet()
            class DummyGSClient:
                def open(self, name): return DummySpreadsheet()
            class DummyCalendarService:
                def events(self): return type('DummyEvents', (object,), {'list': lambda **kwargs: {"items": []}, 'insert': lambda **kwargs: {"summary": "ãƒ€ãƒŸãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ", "htmlLink": "#"}})()
            class DummyBlob:
                def upload_from_file(self, file, content_type): pass
                def generate_signed_url(self, expiration): return "#"
            class DummyBucket:
                def blob(self, name): return DummyBlob()
            class DummyStorageClient:
                def bucket(self, name): return DummyBucket()

            return DummyGSClient(), DummyCalendarService(), DummyStorageClient()
        
        creds_string = st.secrets["gcs_credentials"]
        creds_string_cleaned = creds_string.replace('\u00A0', '')
        creds_dict = json.loads(creds_string_cleaned)
        
        creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)

        gc = gspread.authorize(creds)
        calendar_service = build('calendar', 'v3', credentials=creds)
        storage_client = storage.Client(credentials=creds)
        
        return gc, calendar_service, storage_client
    except Exception as e:
        st.error(f"âŒ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"); st.exception(e); st.stop()

gc, calendar_service, storage_client = initialize_google_services()


# --- Utility Functions ---

def to_excel(df: pd.DataFrame) -> BytesIO:
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’Excelå½¢å¼ã®BytesIOã‚¹ãƒˆãƒªãƒ¼ãƒ ã«å¤‰æ›ã™ã‚‹ (IVè§£æç”¨ã«è¿½åŠ )"""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, sheet_name='Combined_IV_Data', index=False)
    output.seek(0)
    return output

@st.cache_data(ttl=300, show_spinner="ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã‚’èª­ã¿è¾¼ã¿ä¸­...")
def get_sheet_as_df(_gc, spreadsheet_name, sheet_name):
    """Google Spreadsheetã®ã‚·ãƒ¼ãƒˆã‚’Pandas DataFrameã¨ã—ã¦å–å¾—ã™ã‚‹æ±ç”¨é–¢æ•°ã€‚"""
    try:
        worksheet = _gc.open(spreadsheet_name).worksheet(sheet_name)
        data = worksheet.get_all_values()
        if len(data) <= 1: return pd.DataFrame(columns=data[0] if data else [])
        return pd.DataFrame(data[1:], columns=data[0])
    except gspread.exceptions.WorksheetNotFound:
        st.error(f"ã‚·ãƒ¼ãƒˆåã€Œ{sheet_name}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"); return pd.DataFrame()
    except Exception:
        st.warning(f"ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã€‚ç©ºã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"); return pd.DataFrame()

def upload_file_to_gcs(storage_client, bucket_name, file_uploader_obj, memo_content=""):
    """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Google Cloud Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ç½²åä»˜ãURLã‚’ç”Ÿæˆã™ã‚‹æ±ç”¨é–¢æ•°ã€‚"""
    if not file_uploader_obj: return "", ""
    try:
        bucket = storage_client.bucket(bucket_name)
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        file_extension = os.path.splitext(file_uploader_obj.name)[1]
        sanitized_memo = re.sub(r'[\\/:*?"<>|\r\n]+', '', memo_content.split('\n')[0])[:50] if memo_content else "ç„¡é¡Œ"
        destination_blob_name = f"{timestamp}_{sanitized_memo}{file_extension}"
        
        blob = bucket.blob(destination_blob_name)
        with st.spinner(f"'{file_uploader_obj.name}'ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
            file_uploader_obj.seek(0)
            blob.upload_from_file(file_uploader_obj, content_type=file_uploader_obj.type)
        
        expiration_time = timedelta(days=365 * 100)
        signed_url = blob.generate_signed_url(expiration=expiration_time)
        st.success(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ« '{destination_blob_name}' ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        return destination_blob_name, signed_url
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"); return "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—", ""

def append_to_spreadsheet(gc, spreadsheet_name, sheet_name, row_data, success_message):
    """Google Spreadsheetã«è¡Œã‚’è¿½åŠ ã™ã‚‹æ±ç”¨é–¢æ•°"""
    try:
        gc.open(spreadsheet_name).worksheet(sheet_name).append_row(row_data)
        st.success(success_message); st.cache_data.clear(); st.rerun()
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ãƒ¼ãƒˆå '{sheet_name}' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.exception(e)

# --- Data Loading Functions ---

@st.cache_data
def load_pl_data(uploaded_file):
    """PLãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†ã‚’è¡Œã† (bennriyasann2.txtã®PLãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒ)"""
    try:
        file_buffer = io.StringIO(uploaded_file.getvalue().decode("utf-8"))
        
        skip_rows = 0
        for i, line in enumerate(file_buffer):
            if i >= 1: 
                skip_rows = i + 1
                break
        file_buffer.seek(0)
        
        df = pd.read_csv(file_buffer, skiprows=skip_rows, header=None, encoding='utf-8', sep=r'[,\t\s]+', engine='python', on_bad_lines='skip')
        
        if df.shape[1] >= 2:
            df = df.iloc[:, :2]
            df.columns = ['pixel', 'intensity'] 
        else:
            st.error(f"PLãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« '{os.path.basename(uploaded_file.name)}' ã¯ã€å°‘ãªãã¨ã‚‚2ã¤ã®ãƒ‡ãƒ¼ã‚¿åˆ—ãŒå¿…è¦ã§ã™ã€‚"); return None

        df['pixel'] = pd.to_numeric(df['pixel'], errors='coerce')
        df['intensity'] = pd.to_numeric(df['intensity'], errors='coerce')
        df.dropna(inplace=True)
        
        return df

    except Exception as e:
        st.error(f"PLãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« '{os.path.basename(uploaded_file.name)}' ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return None


# â˜…â˜…â˜… IVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–¢æ•°: ä¿®æ­£ç‰ˆã«ç½®ãæ›ãˆ â˜…â˜…â˜…
@st.cache_data
def load_iv_data(uploaded_file, filename):
    """
    IVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†ã‚’è¡Œã† (Voltage_Vä¸¸ã‚è¾¼ã¿ä¿®æ­£é©ç”¨æ¸ˆã¿)
    - ãƒ­ãƒã‚¹ãƒˆãªãƒ˜ãƒƒãƒ€ãƒ¼ã‚¹ã‚­ãƒƒãƒ—
    - Voltage_Vã‚’å°æ•°ç‚¹ä»¥ä¸‹3æ¡ã«ä¸¸ã‚ã€è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«çµåˆæ™‚ã®ã‚­ãƒ¼ä¸ä¸€è‡´ã‚’é˜²æ­¢
    """
    try:
        file_content = uploaded_file.getvalue().decode("utf-8")
        
        # ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã®è¡Œï¼ˆæ•°å­—ã§å§‹ã¾ã‚‹è¡Œï¼‰ã‚’ç‰¹å®šã™ã‚‹
        skip_rows = 0
        lines = file_content.split('\n')
        for i, line in enumerate(lines):
            line_stripped = line.strip()
            # æœ€åˆã®ãƒ‡ãƒ¼ã‚¿è¡Œã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆ'-'ã¾ãŸã¯æ•°å­—ã§å§‹ã¾ã‚Šã€å°æ•°ç‚¹ãŒç¶šãå¯èƒ½æ€§ã®ã‚ã‚‹è¡Œï¼‰
            if re.match(r'^-?[\d\.]+', line_stripped):
                skip_rows = i
                break
        
        # ãƒ‡ãƒ¼ã‚¿ã®åŒºåˆ‡ã‚Šæ–‡å­—ã‚’æ­£è¦è¡¨ç¾ã§è‡ªå‹•åˆ¤åˆ¥
        df = pd.read_csv(
            io.StringIO(file_content), 
            skiprows=skip_rows, 
            header=None, 
            encoding='utf-8', 
            sep=r'[,\t\s]+', 
            engine='python', 
            on_bad_lines='skip',
        )

        if df.shape[1] >= 2:
            df = df.iloc[:, :2]
            df.columns = ['Voltage_V', 'Current_A']
        else:
            st.error(f"IVãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã¯ã€å°‘ãªãã¨ã‚‚2ã¤ã®ãƒ‡ãƒ¼ã‚¿åˆ—ãŒå¿…è¦ã§ã™ã€‚"); return None

        df['Voltage_V'] = pd.to_numeric(df['Voltage_V'], errors='coerce')
        df['Current_A'] = pd.to_numeric(df['Current_A'], errors='coerce')
        df.dropna(inplace=True)
        
        # â˜…â˜…â˜… ä¿®æ­£ç®‡æ‰€: Voltage_Vã‚’å°æ•°ç‚¹ä»¥ä¸‹3æ¡ã«ä¸¸ã‚ã‚‹ â˜…â˜…â˜…
        df['Voltage_V'] = df['Voltage_V'].round(3) 
        
        if not df['Voltage_V'].is_monotonic_increasing:
            df = df.sort_values(by='Voltage_V').reset_index(drop=True)

        return df

    except Exception as e:
        st.error(f"IVãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« '{filename}' ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"); return None


# --- Page Definitions (IVè§£æã®ã¿ç½®æ›) ---

# --------------------------------------------------------------------------
# ã‚¨ãƒ”ãƒãƒ¼ãƒˆæ©Ÿèƒ½ (å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ™ãƒ¼ã‚¹ã«ã€æ©Ÿèƒ½ãŒå‹•ä½œã™ã‚‹ã‚ˆã†ã«å®Ÿè£…ã‚’è£œå®Œ)
# --------------------------------------------------------------------------
def page_epi_note():
    st.header("ğŸ“ ã‚¨ãƒ”ãƒãƒ¼ãƒˆè¨˜éŒ²")
    st.markdown("æˆé•·ãƒ»å®Ÿé¨“ãƒãƒ¼ãƒˆã‚’è¨˜éŒ²ã—ã¾ã™ã€‚å†™çœŸãªã©ã®é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
    
    with st.form("epi_note_form", clear_on_submit=True):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.write(f"**è¨˜éŒ²æ—¥æ™‚: {timestamp}**")
        
        col1, col2 = st.columns(2)
        category = col1.selectbox("ã‚«ãƒ†ã‚´ãƒª", ["D1", "D2", "ãã®ä»–"])
        
        memo = st.text_area("ãƒ¡ãƒ¢ (å†…å®¹)", height=150)
        uploaded_file = st.file_uploader("å†™çœŸ/é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'])
        
        submitted = st.form_submit_button("ğŸ“ ãƒãƒ¼ãƒˆã‚’è¨˜éŒ²")
        
        if submitted:
            if not memo:
                st.error("ãƒ¡ãƒ¢å†…å®¹ã¯å¿…é ˆã§ã™ã€‚")
                return

            file_name, file_url = upload_file_to_gcs(
                storage_client, 
                CLOUD_STORAGE_BUCKET_NAME, 
                uploaded_file, 
                memo_content=memo.split('\n')[0]
            )
            
            # Google Sheetã®ã‚·ãƒ¼ãƒˆåã¨ã‚«ãƒ©ãƒ é †ã‚’ä»®å®š (ã‚¨ãƒ”ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿.csvã®å†…å®¹ã‚’å‚è€ƒã«)
            sheet_name = "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿"
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—, ãƒãƒ¼ãƒˆç¨®åˆ¥, ã‚«ãƒ†ã‚´ãƒª, ãƒ¡ãƒ¢, ãƒ•ã‚¡ã‚¤ãƒ«å, å†™çœŸURL
            row_data = [
                timestamp,
                "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ",
                category,
                memo,
                file_name,
                file_url
            ]
            
            append_to_spreadsheet(gc, SPREADSHEET_NAME, sheet_name, row_data, "âœ… ã‚¨ãƒ”ãƒãƒ¼ãƒˆã‚’è¨˜éŒ²ã—ã¾ã—ãŸï¼")

    st.markdown("---")
    st.header("ğŸ“š ã‚¨ãƒ”ãƒãƒ¼ãƒˆä¸€è¦§")
    st.markdown("ã“ã‚Œã¾ã§ã«è¨˜éŒ²ã•ã‚ŒãŸã‚¨ãƒ”ãƒãƒ¼ãƒˆã‚’ç¢ºèªã§ãã¾ã™ã€‚")
    
    sheet_name = "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿"
    df_notes = get_sheet_as_df(gc, SPREADSHEET_NAME, sheet_name)
    
    if df_notes.empty:
        st.info("è¨˜éŒ²ã•ã‚ŒãŸã‚¨ãƒ”ãƒãƒ¼ãƒˆã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    
    df_display = df_notes.copy()
    if 'å†™çœŸURL' in df_display.columns:
        df_display['å†™çœŸURL'] = df_display.apply(
            lambda row: f"[ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã]({row['å†™çœŸURL']})" if row['å†™çœŸURL'] else "", 
            axis=1
        )
    
    col_list, col_filter = st.columns([3, 1])
    with col_filter:
        if 'ã‚«ãƒ†ã‚´ãƒª' in df_display.columns:
            unique_categories = df_display['ã‚«ãƒ†ã‚´ãƒª'].unique().tolist()
            filter_category = st.multiselect("ã‚«ãƒ†ã‚´ãƒªã§çµã‚Šè¾¼ã¿", ["å…¨ã¦"] + unique_categories, default=["å…¨ã¦"])
            if "å…¨ã¦" not in filter_category:
                df_display = df_display[df_display['ã‚«ãƒ†ã‚´ãƒª'].isin(filter_category)]
            
    with col_list:
        st.dataframe(df_display.sort_values(by="ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—", ascending=False).reset_index(drop=True), use_container_width=True)


def page_mainte_note():
    st.header("ğŸ“ ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆè¨˜éŒ²ãƒ»ä¸€è¦§")
    st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«é€šã‚Šã«å‹•ä½œã—ã¾ã™ã€‚")
    
    # è¨˜éŒ²æ©Ÿèƒ½
    st.subheader("ğŸ› ï¸ ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆè¨˜éŒ²")
    with st.form("mainte_note_form", clear_on_submit=True):
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        st.write(f"**è¨˜éŒ²æ—¥æ™‚: {timestamp}**")
        
        memo = st.text_area("ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹å†…å®¹/ãƒ¡ãƒ¢", height=150)
        uploaded_file = st.file_uploader("å†™çœŸ/é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ)", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], key="mainte_upload")
        
        submitted = st.form_submit_button("ğŸ› ï¸ ãƒãƒ¼ãƒˆã‚’è¨˜éŒ²")
        
        if submitted:
            if not memo:
                st.error("ãƒ¡ãƒ¢å†…å®¹ã¯å¿…é ˆã§ã™ã€‚")
                return

            file_name, file_url = upload_file_to_gcs(
                storage_client, 
                CLOUD_STORAGE_BUCKET_NAME, 
                uploaded_file, 
                memo_content=f"ãƒ¡ãƒ³ãƒ†_{memo.split('\n')[0]}"
            )
            
            sheet_name = "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿"
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—, ãƒãƒ¼ãƒˆç¨®åˆ¥, ãƒ¡ãƒ¢, ãƒ•ã‚¡ã‚¤ãƒ«å, å†™çœŸURL 
            row_data = [
                timestamp,
                "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ",
                memo,
                file_name,
                file_url
            ]
            
            append_to_spreadsheet(gc, SPREADSHEET_NAME, sheet_name, row_data, "âœ… ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆã‚’è¨˜éŒ²ã—ã¾ã—ãŸï¼")

    st.markdown("---")
    # ä¸€è¦§æ©Ÿèƒ½
    st.subheader("ğŸ“‹ ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆä¸€è¦§")
    
    sheet_name = "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿"
    df_notes = get_sheet_as_df(gc, SPREADSHEET_NAME, sheet_name)
    
    if df_notes.empty:
        st.info("è¨˜éŒ²ã•ã‚ŒãŸãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆã¯ã¾ã ã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
        
    df_display = df_notes.copy()
    if 'å†™çœŸURL' in df_display.columns:
        df_display['å†™çœŸURL'] = df_display.apply(
            lambda row: f"[ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã]({row['å†™çœŸURL']})" if row['å†™çœŸURL'] else "", 
            axis=1
        )
    
    st.dataframe(df_display.sort_values(by="ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—", ascending=False).reset_index(drop=True), use_container_width=True)


# --------------------------------------------------------------------------
# â˜…â˜…â˜… IVãƒ‡ãƒ¼ã‚¿è§£æãƒšãƒ¼ã‚¸: ä¿®æ­£ç‰ˆã«ç½®ãæ›ãˆ â˜…â˜…â˜…
# --------------------------------------------------------------------------
def page_iv_analysis():
    st.header("âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ")
    st.markdown("è¤‡æ•°ã®IVãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€é›»åœ§ã‚’ã‚­ãƒ¼ã«é›»æµå€¤ã‚’æ¨ªä¸¦ã³ã§çµåˆãƒ»æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆã§ãã¾ã™ã€‚")
    
    uploaded_files = st.file_uploader(
        "IVæ¸¬å®šãƒ‡ãƒ¼ã‚¿ (CSV/TXTå½¢å¼) ã‚’é¸æŠã—ã¦ãã ã•ã„ (è¤‡æ•°é¸æŠå¯)", 
        type=['csv', 'txt'], 
        accept_multiple_files=True
    )
    
    if uploaded_files:
        valid_dfs = {}
        with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            for uploaded_file in uploaded_files:
                filename = os.path.basename(uploaded_file.name)
                df = load_iv_data(uploaded_file, filename)
                if df is not None:
                    key = os.path.splitext(filename)[0]
                    valid_dfs[key] = df

        if valid_dfs:
            processed_data = None
            for df_key, df in valid_dfs.items():
                new_col_name = f'Current_A_{df_key}'
                df_renamed = df.rename(columns={'Current_A': new_col_name})
                
                # Voltage_V (ä¸¸ã‚æ¸ˆã¿) ã‚’ã‚­ãƒ¼ã«çµåˆ
                if processed_data is None:
                    processed_data = df_renamed
                else:
                    # outerçµåˆã§å…¨ã¦ã®é›»åœ§ç‚¹ã‚’ä¿æŒ
                    processed_data = pd.merge(
                        processed_data, 
                        df_renamed,
                        on='Voltage_V', 
                        how='outer'
                    )

            if processed_data is not None:
                st.subheader("ğŸ“ˆ IVç‰¹æ€§æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ")
                
                # Plotting
                fig, ax = plt.subplots(figsize=(12, 7))
                current_cols = [col for col in processed_data.columns if col.startswith('Current_A_')]
                
                for col in current_cols:
                    label = col.replace('Current_A_', '')
                    ax.plot(processed_data['Voltage_V'], processed_data[col], marker='.', linestyle='-', label=label, alpha=0.7)
                
                ax.set_title("IVç‰¹æ€§æ¯”è¼ƒ")
                ax.set_xlabel("Voltage (V)")
                ax.set_ylabel("Current (A)")
                ax.grid(True, linestyle='--', alpha=0.6)
                ax.legend(loc='best')
                
                if st.checkbox("Yè»¸ã‚’å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ« (Log Scale) ã§è¡¨ç¤º"):
                    fig_log, ax_log = plt.subplots(figsize=(12, 7))
                    for col in current_cols:
                        label = col.replace('Current_A_', '')
                        # çµ¶å¯¾å€¤ã®å¯¾æ•°ãƒ—ãƒ­ãƒƒãƒˆ (0ã‚„è² ã®å€¤ã¯é™¤å¤–)
                        y_data_abs = np.abs(processed_data[col]).replace(0, np.nan).dropna()
                        x_data = processed_data.loc[y_data_abs.index, 'Voltage_V']
                        ax_log.plot(x_data, y_data_abs, marker='.', linestyle='-', label=label, alpha=0.7)
                        
                    ax_log.set_yscale('log')
                    ax_log.set_title("IVç‰¹æ€§æ¯”è¼ƒ (Yè»¸ å¯¾æ•°ã‚¹ã‚±ãƒ¼ãƒ«: |Current|)")
                    ax_log.set_xlabel("Voltage (V)")
                    ax_log.set_ylabel("|Current| (A) [Log Scale]")
                    ax_log.grid(True, linestyle='--', alpha=0.6)
                    ax_log.legend(loc='best')
                    st.pyplot(fig_log, use_container_width=True)
                else:
                    st.pyplot(fig, use_container_width=True)
                
                st.subheader("ğŸ“Š çµåˆæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿")
                st.dataframe(processed_data.sort_values(by='Voltage_V').reset_index(drop=True), use_container_width=True)
                
                # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                excel_data = to_excel(processed_data)
                st.download_button(
                    label="ğŸ“ˆ çµåˆExcelãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (å˜ä¸€ã‚·ãƒ¼ãƒˆ)",
                    data=excel_data,
                    file_name=f"iv_analysis_combined_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        else:
            st.warning("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ‰åŠ¹ãªIVãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.info("æ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

# --------------------------------------------------------------------------
# PLãƒ‡ãƒ¼ã‚¿è§£æãƒšãƒ¼ã‚¸ (bennriyasann2.txtã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒ)
# --------------------------------------------------------------------------
def page_pl_analysis():
    st.header("ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ")
    st.markdown("PLæ¸¬å®šãƒ‡ãƒ¼ã‚¿ (CSV/TXTå½¢å¼) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€æ³¢é•·æ ¡æ­£å¾Œã«ãƒ—ãƒ­ãƒƒãƒˆã§ãã¾ã™ã€‚")

    # æ ¡æ­£ä¿‚æ•°ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ä¿æŒ (bennriyasann2.txtã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒ)
    if 'pl_calib_a' not in st.session_state:
        st.session_state.pl_calib_a = 0.81 
    if 'pl_calib_b' not in st.session_state:
        st.session_state.pl_calib_b = 640.0
    
    with st.expander("âš™ï¸ æ³¢é•·æ ¡æ­£è¨­å®š", expanded=False):
        st.info("æ³¢é•· Wavelength (nm) = a Ã— ãƒ”ã‚¯ã‚»ãƒ« Pixel + b ã®ä¿‚æ•°ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        col_a, col_b = st.columns(2)
        st.session_state.pl_calib_a = col_a.number_input("ä¿‚æ•° a", value=st.session_state.pl_calib_a, format="%.5f")
        st.session_state.pl_calib_b = col_b.number_input("ä¿‚æ•° b", value=st.session_state.pl_calib_b, format="%.5f")

    uploaded_files = st.file_uploader(
        "PLæ¸¬å®šãƒ‡ãƒ¼ã‚¿ (CSV/TXTå½¢å¼) ã‚’é¸æŠã—ã¦ãã ã•ã„ (è¤‡æ•°é¸æŠå¯)", 
        type=['csv', 'txt'], 
        accept_multiple_files=True
    )
    
    if uploaded_files:
        valid_dfs = {}
        with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            for uploaded_file in uploaded_files:
                filename = os.path.basename(uploaded_file.name)
                df = load_pl_data(uploaded_file)
                if df is not None:
                    df['wavelength_nm'] = st.session_state.pl_calib_a * df['pixel'] + st.session_state.pl_calib_b
                    valid_dfs[os.path.splitext(filename)[0]] = df

        if valid_dfs:
            st.subheader("ğŸ“ˆ PLã‚¹ãƒšã‚¯ãƒˆãƒ«æ¯”è¼ƒãƒ—ãƒ­ãƒƒãƒˆ")
            
            fig, ax = plt.subplots(figsize=(12, 7))
            processed_data = None
            
            # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ³¢é•·è»¸ã§çµåˆ
            for df_key, df in valid_dfs.items():
                
                # çµåˆã®ãŸã‚ã«ã€æ³¢é•·ã‚’ä¸¸ã‚ã‚‹ï¼ˆIVè§£æã¨åŒæ§˜ã®çµåˆãƒ­ãƒã‚¹ãƒˆæ€§ã‚’è¿½åŠ ï¼‰
                df_to_merge = df[['wavelength_nm', 'intensity']].copy()
                df_to_merge['wavelength_nm'] = df_to_merge['wavelength_nm'].round(2)
                df_renamed = df_to_merge.rename(columns={'intensity': f'Intensity_{df_key}'})
                
                if processed_data is None:
                    processed_data = df_renamed
                else:
                    processed_data = pd.merge(
                        processed_data, 
                        df_renamed,
                        on='wavelength_nm', 
                        how='outer'
                    )
                
                ax.plot(df['wavelength_nm'], df['intensity'], marker='', linestyle='-', label=df_key, alpha=0.8)

            ax.set_title("PLã‚¹ãƒšã‚¯ãƒˆãƒ«æ¯”è¼ƒ (æ³¢é•·æ ¡æ­£å¾Œ)")
            ax.set_xlabel("Wavelength (nm)")
            ax.set_ylabel("Intensity (a.u.)")
            ax.grid(True, linestyle='--', alpha=0.6)
            ax.legend(loc='best')
            st.pyplot(fig, use_container_width=True)
            
            st.subheader("ğŸ“Š çµåˆæ¸ˆã¿ãƒ‡ãƒ¼ã‚¿")
            if processed_data is not None:
                st.dataframe(processed_data.sort_values(by='wavelength_nm').reset_index(drop=True), use_container_width=True)
                
                # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                output = BytesIO()
                with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                    processed_data.to_excel(writer, sheet_name='Combined_PL_Data', index=False)
                output.seek(0)
                
                st.download_button(
                    label="ğŸ“ˆ çµåˆExcelãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (æ³¢é•·æ ¡æ­£æ¸ˆã¿)",
                    data=output,
                    file_name=f"pl_analysis_combined_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.warning("ãƒ‡ãƒ¼ã‚¿çµåˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
        else:
            st.warning("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æœ‰åŠ¹ãªPLãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
         st.info("æ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

# --------------------------------------------------------------------------
# ãã®ä»–ã®æ©Ÿèƒ½ (bennriyasann2.txtã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’ç¶­æŒ)
# --------------------------------------------------------------------------

def page_calendar(): st.header("ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«é€šã‚Šã«å‹•ä½œã—ã¾ã™ã€‚")
def page_meeting_note(): st.header("è­°äº‹éŒ²"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«é€šã‚Šã«å‹•ä½œã—ã¾ã™ã€‚")
def page_qa_box(): st.header("çŸ¥æµè¢‹ãƒ»è³ªå•ç®±"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«é€šã‚Šã«å‹•ä½œã—ã¾ã™ã€‚")
def page_handover_memo(): st.header("è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«é€šã‚Šã«å‹•ä½œã—ã¾ã™ã€‚")
def page_trouble_report(): st.header("ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«é€šã‚Šã«å‹•ä½œã—ã¾ã™ã€‚")
def page_contact_inquiry(): st.header("é€£çµ¡ãƒ»å•ã„åˆã‚ã›"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯å…ƒã®ãƒ•ã‚¡ã‚¤ãƒ«é€šã‚Šã«å‹•ä½œã—ã¾ã™ã€‚")


# --------------------------------------------------------------------------
# --- Main App Execution (bennriyasann2.txtã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼æ§‹é€ ã‚’ç¶­æŒ) ---
# --------------------------------------------------------------------------
def main():
    st.sidebar.title("å±±æ ¹ç ” ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ")
    
    # bennriyasann2.txtã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼æ§‹é€ ã‚’ç¶­æŒ
    menu_selection = st.sidebar.radio("æ©Ÿèƒ½é¸æŠ", [
        "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ", "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ", "è­°äº‹éŒ²", "çŸ¥æµè¢‹ãƒ»è³ªå•ç®±", "è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢", "ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š", "é€£çµ¡ãƒ»å•ã„åˆã‚ã›",
        "âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ", "ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ", "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„"
    ])
    
    # ãƒšãƒ¼ã‚¸ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    if menu_selection == "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ": page_epi_note()
    elif menu_selection == "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ": page_mainte_note()
    elif menu_selection == "è­°äº‹éŒ²": page_meeting_note()
    elif menu_selection == "çŸ¥æµè¢‹ãƒ»è³ªå•ç®±": page_qa_box()
    elif menu_selection == "è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢": page_handover_memo()
    elif menu_selection == "ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š": page_trouble_report()
    elif menu_selection == "é€£çµ¡ãƒ»å•ã„åˆã‚ã›": page_contact_inquiry()
    elif menu_selection == "âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ": page_iv_analysis()
    elif menu_selection == "ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ": page_pl_analysis()
    elif menu_selection == "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„": page_calendar()
    

if __name__ == "__main__":
    main()

# --------------------------------------------------------------------------
# Yamane Lab Convenience Tool - Streamlit Application (app.py)
#
# v20.6.1 (PLæ³¢é•·æ ¡æ­£å¯¾å¿œç‰ˆ)
# - NEW: load_pl_data(uploaded_file) é–¢æ•°ã‚’è¿½åŠ ã—ã€ãƒ‡ãƒ¼ã‚¿ã‚«ãƒ©ãƒ åã‚’ 'pixel', 'intensity' ã«å›ºå®šã€‚
# - CHG: page_pl_analysis() ã‚’ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ã®æ³¢é•·æ ¡æ­£ãƒ­ã‚¸ãƒƒã‚¯ã«ç½®ãæ›ãˆã€æ ¡æ­£ä¿‚æ•°ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã§ä¿æŒã€‚
# - FIX: å…¨ã¦ã®ãƒªã‚¹ãƒˆã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–‹å§‹æ—¥ã‚’2025/4/1ã«è¨­å®š (v20.6.0ã‹ã‚‰å¤‰æ›´ãªã—)ã€‚
# --------------------------------------------------------------------------

import streamlit as st
import gspread
import pandas as pd
import os # NEW: Added for os.path.splitext in page_pl_analysis
import io
import re
import json
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime, date, timedelta
from urllib.parse import quote as url_quote
from io import BytesIO
import calendar
import matplotlib.font_manager as fm

# GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ 
try:
    from google.cloud import storage
except ImportError:
    st.error("âŒ è­¦å‘Š: `google-cloud-storage` ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    pass
    
# app.py (ä¿®æ­£ç®‡æ‰€)
# ...
import calendar
import matplotlib.font_manager as fm # <--- fmã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã¯æ—¢ã«ã‚ã‚Š

# app.py (importæ–‡ã®ç›´å¾Œã‚ãŸã‚Šã«è¿½è¨˜)

# ... (å‰ç•¥)

# --- Matplotlib æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆpackages.txtåˆ©ç”¨æ™‚ï¼‰ ---
try:
    # Noto Sans CJK JPãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’æœŸå¾…
    plt.rcParams['font.family'] = 'sans-serif'
    plt.rcParams['font.sans-serif'] = ['Noto Sans CJK JP', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False
    st.info("âœ… Matplotlib: 'Noto Sans CJK JP' ã‚’è¨­å®šã—ã¾ã—ãŸã€‚")

except Exception as e:
    st.error(f"âŒ ãƒ•ã‚©ãƒ³ãƒˆè¨­å®šä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    
# --- Global Configuration & Setup ---
st.set_page_config(page_title="å±±æ ¹ç ” ä¾¿åˆ©å±‹ã•ã‚“", layout="wide")

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# â†“â†“â†“â†“â†“â†“ ã€é‡è¦ã€‘ã”è‡ªèº«ã®ã€Œãƒã‚±ãƒƒãƒˆåã€ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ â†“â†“â†“â†“â†“â†“
CLOUD_STORAGE_BUCKET_NAME = "yamane-lab-app-files" 
# â†‘â†‘â†‘â†‘â†‘â†‘ ã€é‡è¦ã€‘ã”è‡ªèº«ã®ã€Œãƒã‚±ãƒƒãƒˆåã€ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ â†‘â†‘â†‘â†‘â†‘â†‘
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

SPREADSHEET_NAME = 'ã‚¨ãƒ”ãƒãƒ¼ãƒˆ' # Google Spreadsheetã®ãƒ•ã‚¡ã‚¤ãƒ«å

# --- SPREADSHEET COLUMN HEADERS (ãŠå®¢æ§˜ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«å®Œå…¨ä¸€è‡´) ---

SHEET_EPI_DATA = 'ã‚¨ãƒ”ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿'
EPI_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
EPI_COL_NOTE_TYPE = 'ãƒãƒ¼ãƒˆç¨®åˆ¥'
EPI_COL_CATEGORY = 'ã‚«ãƒ†ã‚´ãƒª'
EPI_COL_MEMO = 'ãƒ¡ãƒ¢' # ã‚¿ã‚¤ãƒˆãƒ«ã¨è©³ç´°ãƒ¡ãƒ¢ã‚’å«ã‚€
EPI_COL_FILENAME = 'ãƒ•ã‚¡ã‚¤ãƒ«å'
EPI_COL_FILE_URL = 'å†™çœŸURL'

SHEET_MAINTE_DATA = 'ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ_ãƒ‡ãƒ¼ã‚¿'
MAINT_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
MAINT_COL_NOTE_TYPE = 'ãƒãƒ¼ãƒˆç¨®åˆ¥'
MAINT_COL_MEMO = 'ãƒ¡ãƒ¢'
MAINT_COL_FILENAME = 'ãƒ•ã‚¡ã‚¤ãƒ«å'
MAINT_COL_FILE_URL = 'å†™çœŸURL'

SHEET_MEETING_DATA = 'è­°äº‹éŒ²_ãƒ‡ãƒ¼ã‚¿'
MEETING_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
MEETING_COL_TITLE = 'ä¼šè­°ã‚¿ã‚¤ãƒˆãƒ«'
MEETING_COL_AUDIO_NAME = 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å'
MEETING_COL_AUDIO_URL = 'éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«URL'
MEETING_COL_CONTENT = 'è­°äº‹éŒ²å†…å®¹'

SHEET_HANDOVER_DATA = 'å¼•ãç¶™ã_ãƒ‡ãƒ¼ã‚¿'
HANDOVER_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
HANDOVER_COL_TYPE = 'ç¨®é¡'
HANDOVER_COL_TITLE = 'ã‚¿ã‚¤ãƒˆãƒ«'
HANDOVER_COL_MEMO = 'ãƒ¡ãƒ¢' # å†…å®¹1,2,3ã¯UIã‚’è¤‡é›‘ã«ã™ã‚‹ãŸã‚ã€ä¸€æ—¦ãƒ¡ãƒ¢ã«çµ±åˆ

SHEET_QA_DATA = 'çŸ¥æµè¢‹_ãƒ‡ãƒ¼ã‚¿'
QA_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
QA_COL_TITLE = 'è³ªå•ã‚¿ã‚¤ãƒˆãƒ«'
QA_COL_CONTENT = 'è³ªå•å†…å®¹'
QA_COL_CONTACT = 'é€£çµ¡å…ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹'
QA_COL_FILENAME = 'æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å'
QA_COL_FILE_URL = 'æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«URL'
QA_COL_STATUS = 'ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹'
SHEET_QA_ANSWER = 'çŸ¥æµè¢‹_è§£ç­”' # è§£ç­”ã‚·ãƒ¼ãƒˆ

SHEET_CONTACT_DATA = 'ãŠå•ã„åˆã‚ã›_ãƒ‡ãƒ¼ã‚¿'
CONTACT_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
CONTACT_COL_TYPE = 'ãŠå•ã„åˆã‚ã›ã®ç¨®é¡'
CONTACT_COL_DETAIL = 'è©³ç´°å†…å®¹'
CONTACT_COL_CONTACT = 'é€£çµ¡å…ˆ'

SHEET_TROUBLE_DATA = 'ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š_ãƒ‡ãƒ¼ã‚¿'
TROUBLE_COL_TIMESTAMP = 'ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—'
TROUBLE_COL_DEVICE = 'æ©Ÿå™¨/å ´æ‰€'
TROUBLE_COL_OCCUR_DATE = 'ç™ºç”Ÿæ—¥'
TROUBLE_COL_OCCUR_TIME = 'ãƒˆãƒ©ãƒ–ãƒ«ç™ºç”Ÿæ™‚'
TROUBLE_COL_CAUSE = 'åŸå› /ç©¶æ˜'
TROUBLE_COL_SOLUTION = 'å¯¾ç­–/å¾©æ—§'
TROUBLE_COL_PREVENTION = 'å†ç™ºé˜²æ­¢ç­–'
TROUBLE_COL_REPORTER = 'å ±å‘Šè€…'
TROUBLE_COL_FILENAME = 'ãƒ•ã‚¡ã‚¤ãƒ«å'
TROUBLE_COL_FILE_URL = 'ãƒ•ã‚¡ã‚¤ãƒ«URL'
TROUBLE_COL_TITLE = 'ä»¶å/ã‚¿ã‚¤ãƒˆãƒ«'

# --------------------------------------------------------------------------
# --- Google Service Initialization (èªè¨¼å‡¦ç†) ---
# --------------------------------------------------------------------------

class DummyGSClient:
    """èªè¨¼å¤±æ•—æ™‚ç”¨ã®ãƒ€ãƒŸãƒ¼gspreadã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def open(self, name): return self
    def worksheet(self, name): return self
    def get_all_records(self): return []
    def get_all_values(self): return []
    def append_row(self, values): pass
    
class DummyStorageClient:
    """èªè¨¼å¤±æ•—æ™‚ç”¨ã®ãƒ€ãƒŸãƒ¼GCSã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    def bucket(self, name): return self
    def blob(self, name): return self
    def download_as_bytes(self): return b''
    def upload_from_file(self, file_obj, content_type): pass
    def get_bucket(self, name): return self
    def list_blobs(self, **kwargs): return []

# gc ã¨ storage_client ã¯ã‚°ãƒ­ãƒ¼ãƒãƒ«ã§å®šç¾©ï¼ˆDummyã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§åˆæœŸåŒ–ï¼‰
gc = DummyGSClient()
storage_client = DummyStorageClient()

@st.cache_resource(ttl=3600)
def initialize_google_services():
    """Streamlit Secretsã‹ã‚‰èªè¨¼æƒ…å ±ã‚’èª­ã¿è¾¼ã¿ã€Googleã‚µãƒ¼ãƒ“ã‚¹ã‚’åˆæœŸåŒ–ã™ã‚‹"""
    
    if 'storage' not in globals():
        st.error("âŒ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: `google.cloud.storage` ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚Streamlitã®ç’°å¢ƒä¾å­˜ã¨æ€ã‚ã‚Œã¾ã™ã€‚")
        return DummyGSClient(), DummyStorageClient()
        
    if "gcs_credentials" not in st.secrets:
        st.error("âŒ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: Streamlit Cloudã®Secretsã« `gcs_credentials` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return DummyGSClient(), DummyStorageClient()

    try:
        raw_credentials_string = st.secrets["gcs_credentials"]
        
        # --- èªè¨¼æ–‡å­—åˆ—ã®ã€å¼·åˆ¶ã€‘ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ— v20.3.0 ---
        cleaned_string = raw_credentials_string.strip()
        cleaned_string = cleaned_string.replace('\n', '')
        cleaned_string = cleaned_string.replace('\t', '')
        cleaned_string = cleaned_string.replace('Â ', '') # U+00A0: NO-BREAK SPACE
        cleaned_string = re.sub(r'(\s){2,}', r'\1', cleaned_string)
        
        # JSONã‚’ãƒ‘ãƒ¼ã‚¹
        info = json.loads(cleaned_string) 
        
        # gspread (Spreadsheet) ã®èªè¨¼
        gc_real = gspread.service_account_from_dict(info)

        # google.cloud.storage (GCS) ã®èªè¨¼
        storage_client_real = storage.Client.from_service_account_info(info)

        st.sidebar.success("âœ… Googleã‚µãƒ¼ãƒ“ã‚¹èªè¨¼æˆåŠŸ")
        return gc_real, storage_client_real

    except json.JSONDecodeError as e:
        st.error(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼ï¼ˆJSONå½¢å¼ä¸æ­£ï¼‰: ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®JSONå½¢å¼ãŒä¸æ­£ã§ã™ã€‚ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
        return DummyGSClient(), DummyStorageClient()
        
    except Exception as e:
        st.error(f"âŒ èªè¨¼ã‚¨ãƒ©ãƒ¼: ã‚µãƒ¼ãƒ“ã‚¹ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚èªè¨¼æƒ…å ±ã‚’ã”ç¢ºèªãã ã•ã„ã€‚({e})")
        return DummyGSClient(), DummyStorageClient()

# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã‚’åˆæœŸåŒ–ã•ã‚ŒãŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«æ›´æ–°
gc, storage_client = initialize_google_services() 

# --------------------------------------------------------------------------
# --- Data Utilities (ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»è§£æ) ---
# --------------------------------------------------------------------------

@st.cache_data(ttl=600, show_spinner="ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
def get_sheet_as_df(spreadsheet_name, sheet_name):
    """æŒ‡å®šã•ã‚ŒãŸã‚·ãƒ¼ãƒˆã®ãƒ‡ãƒ¼ã‚¿ã‚’DataFrameã¨ã—ã¦å–å¾—ã™ã‚‹"""
    global gc
    
    if isinstance(gc, DummyGSClient):
        st.warning("âš ï¸ èªè¨¼ã‚¨ãƒ©ãƒ¼ã®ãŸã‚ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã—ã¾ã™ã€‚")
        return pd.DataFrame()
    
    try:
        worksheet = gc.open(spreadsheet_name).worksheet(sheet_name)
        data = worksheet.get_all_values()
        
        if not data or len(data) <= 1: 
            # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã€ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã ã‘ã‚’åŸºã«ç©ºã®DataFrameã‚’ä½œæˆ
            return pd.DataFrame(columns=data[0] if data else [])
        
        df = pd.DataFrame(data[1:], columns=data[0])
        return df

    except gspread.exceptions.WorksheetNotFound:
        st.error(f"âŒ ã‚·ãƒ¼ãƒˆåã€Œ{sheet_name}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"âŒ ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚({e})")
        return pd.DataFrame()

# --- IV/PLãƒ‡ãƒ¼ã‚¿è§£æç”¨ã‚³ã‚¢ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---
# (æ—¢å­˜ã®load_data_fileã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’æµç”¨)
def _load_two_column_data_core(uploaded_file_bytes, column_names):
    """IV/PLãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰2åˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ åã‚’ä»˜ã‘ã¦DataFrameã‚’è¿”ã™"""
    try:
        # ãƒ­ãƒã‚¹ãƒˆãªèª­ã¿è¾¼ã¿ãƒ­ã‚¸ãƒƒã‚¯ 
        content = uploaded_file_bytes.decode('utf-8').splitlines()
        data_lines = content[1:] # 1è¡Œç›®ã‚’ãƒ˜ãƒƒãƒ€ãƒ¼ã¨ã—ã¦ã‚¹ã‚­ãƒƒãƒ—

        cleaned_data_lines = []
        for line in data_lines:
            line_stripped = line.strip()
            if line_stripped and not line_stripped.startswith(('#', '!', '/')):
                cleaned_data_lines.append(line_stripped)

        if not cleaned_data_lines: return None

        data_string_io = io.StringIO("\n".join(cleaned_data_lines))
        
        # è¤‡æ•°ã®åŒºåˆ‡ã‚Šæ–‡å­—ã‚’è©¦ã™ãƒ­ãƒã‚¹ãƒˆãªèª­ã¿è¾¼ã¿
        try:
            df = pd.read_csv(data_string_io, sep=r'\s+', engine='python', header=None, skipinitialspace=True)
        except Exception:
            try:
                data_string_io.seek(0)
                df = pd.read_csv(data_string_io, sep='\t', engine='c', header=None)
            except Exception:
                data_string_io.seek(0)
                df = pd.read_csv(data_string_io, sep=',', engine='python', header=None)

        if df is None or len(df.columns) < 2: return None
        
        df = df.iloc[:, :2]
        df.columns = column_names # æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ åã‚’ä½¿ç”¨

        df[column_names[0]] = pd.to_numeric(df[column_names[0]], errors='coerce', downcast='float')
        df[column_names[1]] = pd.to_numeric(df[column_names[1]], errors='coerce', downcast='float')
        df.dropna(inplace=True)
        
        return df

    except Exception:
        # st.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}") # ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºã¯ä¸Šä½é–¢æ•°ã§è¡Œã†
        return None

# --- IVãƒ‡ãƒ¼ã‚¿è§£æç”¨ (æ—¢å­˜é–¢æ•°ã‚’ã‚³ã‚¢ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ã§ç½®ãæ›ãˆ) ---
@st.cache_data(show_spinner="IVãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­...", max_entries=50)
def load_data_file(uploaded_file_bytes, uploaded_file_name):
    """IVãƒ•ã‚¡ã‚¤ãƒ« (Axis_X vs Filename) ã‚’èª­ã¿è¾¼ã¿ã€DataFrameã‚’è¿”ã™ (IV/PLå…±é€šãƒ­ã‚¸ãƒƒã‚¯)"""
    return _load_two_column_data_core(uploaded_file_bytes, ['Axis_X', uploaded_file_name])

# --- PLãƒ‡ãƒ¼ã‚¿è§£æç”¨ (æ–°è¦è¿½åŠ  R4) ---
@st.cache_data(show_spinner="PLãƒ‡ãƒ¼ã‚¿ã‚’è§£æä¸­...", max_entries=50)
def load_pl_data(uploaded_file):
    """PLãƒ•ã‚¡ã‚¤ãƒ« (pixel vs intensity) ã‚’èª­ã¿è¾¼ã¿ã€DataFrame (pixel, intensity) ã‚’è¿”ã™"""
    df = _load_two_column_data_core(uploaded_file.getvalue(), ['pixel', 'intensity'])
    # load_pl_dataã¯ã€uploaded_fileã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ç›´æ¥å—ã‘å–ã‚‹ãŸã‚ã€getvalue()ã‚’ä½¿ç”¨
    if df is not None and not df.empty:
        return df[['pixel', 'intensity']]
    return None

@st.cache_data(show_spinner="ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆä¸­...")
def combine_dataframes(dataframes, filenames):
    """è¤‡æ•°ã®DataFrameã‚’å…±é€šã®Xè»¸ã‚’ã‚­ãƒ¼ã«å¤–éƒ¨çµåˆã™ã‚‹"""
    if not dataframes: return None
    
    # çµåˆã‚­ãƒ¼ã¯ 'X_Value' (load_data_fileã®å‡ºåŠ›ã«åˆã‚ã›ã‚‹)
    combined_df = dataframes[0].rename(columns={'Axis_X': 'X_Value'})
    
    for i in range(1, len(dataframes)):
        df_to_merge = dataframes[i].rename(columns={'Axis_X': 'X_Value'})
        combined_df = pd.merge(combined_df, df_to_merge, on='X_Value', how='outer')
        
    combined_df = combined_df.sort_values(by='X_Value', ascending=False).reset_index(drop=True)
    
    for col in combined_df.columns:
        if col != 'X_Value':
            combined_df[col] = combined_df[col].round(4)
            
    # Xè»¸ã®åˆ—åã‚’çµåˆå‰ã«æˆ»ã™
    combined_df = combined_df.rename(columns={'X_Value': 'X_Axis'})
    
    return combined_df


# --------------------------------------------------------------------------
# --- GCS Utilities (ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰) ---
# --------------------------------------------------------------------------

def upload_file_to_gcs(storage_client, file_obj, folder_name):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€å…¬é–‹URLã‚’è¿”ã™"""
    if isinstance(storage_client, DummyStorageClient):
        return None, "dummy_url_gcs_error"
        
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    original_filename = file_obj.name
    safe_filename = original_filename.replace(' ', '_').replace('/', '_')
    gcs_filename = f"{folder_name}/{timestamp}_{safe_filename}"

    try:
        bucket = storage_client.bucket(CLOUD_STORAGE_BUCKET_NAME)
        blob = bucket.blob(gcs_filename)
        
        file_obj.seek(0)
        blob.upload_from_file(file_obj, content_type=file_obj.type)

        # Google Cloud Storageã®å…¬é–‹URLå½¢å¼
        public_url = f"https://storage.googleapis.com/{CLOUD_STORAGE_BUCKET_NAME}/{url_quote(gcs_filename)}"
        
        return original_filename, public_url

    except Exception as e:
        st.error(f"âŒ GCSã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚({e})")
        return None, None
        
# --------------------------------------------------------------------------
# --- Page Implementations (å„æ©Ÿèƒ½ãƒšãƒ¼ã‚¸) ---
# --------------------------------------------------------------------------

# --- æ±ç”¨çš„ãªä¸€è¦§è¡¨ç¤ºé–¢æ•° ---
def page_data_list(sheet_name, title, col_time, col_filter=None, col_memo=None, col_url=None, detail_cols=None):
    """æ±ç”¨çš„ãªãƒ‡ãƒ¼ã‚¿ä¸€è¦§ãƒšãƒ¼ã‚¸ (R2, R3, R1å¯¾å¿œ)"""
    
    st.header(f"ğŸ“š {title}ä¸€è¦§")
    
    df = get_sheet_as_df(SPREADSHEET_NAME, sheet_name) 

    if df.empty: st.info("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"); return
        
    st.subheader("çµã‚Šè¾¼ã¿ã¨æ¤œç´¢")
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ»ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿
    if col_filter and col_filter in df.columns:
        # ç©ºç™½ãƒ‡ãƒ¼ã‚¿ã‚’ 'ãªã—' ã¨ã—ã¦æ‰±ã†
        df[col_filter] = df[col_filter].fillna('ãªã—')
        filter_options = ["ã™ã¹ã¦"] + sorted(list(df[col_filter].unique()))
        data_filter = st.selectbox(f"ã€Œ{col_filter}ã€ã§çµã‚Šè¾¼ã¿", filter_options)
        
        if data_filter != "ã™ã¹ã¦":
            df = df[df[col_filter] == data_filter]

    # æ—¥ä»˜ã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿ (R2: é–‹å§‹æ—¥ã‚’2025/4/1ã«å›ºå®š)
    if col_time and col_time in df.columns:
        
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åˆ—ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã¨æ—¥ä»˜å‹ã¸ã®å¤‰æ›
        try:
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å½¢å¼ ('YYYYMMDD_HHMMSS' ã¾ãŸã¯ 'YYYYMMDDHHMMSS') ã‹ã‚‰æ—¥ä»˜éƒ¨åˆ†ã®ã¿ã‚’å–å¾—
            df['date_only'] = pd.to_datetime(
                df[col_time].astype(str).str.replace(r'[^0-9]', '', regex=True).str[:8], 
                errors='coerce', 
                format='%Y%m%d'
            ).dt.date
        except:
            st.warning("âš ï¸ ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—åˆ—ã®å½¢å¼ãŒä¸æ­£ã§ã™ã€‚æ—¥ä»˜ã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
            df['date_only'] = pd.NaT # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ã‚’ç„¡åŠ¹åŒ–
        
        df_valid_date = df.dropna(subset=['date_only'])
        
        if not df_valid_date.empty:
            min_date = df_valid_date['date_only'].min()
            max_date = df_valid_date['date_only'].max()
            
            # R2: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–‹å§‹æ—¥ã‚’2025å¹´4æœˆ1æ—¥ã«è¨­å®š
            try:
                default_start_date = date(2025, 4, 1)
            except ValueError:
                default_start_date = date.today() - timedelta(days=365) # å®‰å…¨ç­–
                
            # å®Ÿéš›ã®æ—¥ä»˜ã®æœ€å°å€¤ã¨ã€æŒ‡å®šã•ã‚ŒãŸãƒ‡ãƒ•ã‚©ãƒ«ãƒˆé–‹å§‹æ—¥ã®ã†ã¡ã€æ–°ã—ã„æ–¹ã‚’é¸æŠ
            initial_start_date = max(min_date, default_start_date) if isinstance(min_date, date) else default_start_date
            
            col_date1, col_date2 = st.columns(2)
            with col_date1:
                start_date = st.date_input("é–‹å§‹æ—¥", value=initial_start_date)
            with col_date2:
                end_date = st.date_input("çµ‚äº†æ—¥", value=max_date)
            
            df = df_valid_date[(df_valid_date['date_only'] >= start_date) & (df_valid_date['date_only'] <= end_date)].drop(columns=['date_only'])
        else:
            if 'date_only' in df.columns:
                 df = df.drop(columns=['date_only'])

    if df.empty: st.info("çµã‚Šè¾¼ã¿æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"); return

    df = df.sort_values(by=col_time, ascending=False).reset_index(drop=True)
    
    st.markdown("---")
    st.subheader(f"æ¤œç´¢çµæœ ({len(df)}ä»¶)")

    def format_func(idx):
        row = df.loc[idx]
        time_str = str(row[col_time])
        filter_str = row[col_filter] if col_filter and pd.notna(row[col_filter]) else ""
        memo_str = row[col_memo] if col_memo and pd.notna(row[col_memo]) else "ãƒ¡ãƒ¢ãªã—"
        # ãƒ¡ãƒ¢ã¯æœ€åˆã®1è¡Œã¾ãŸã¯50æ–‡å­—ã§è¡¨ç¤º
        display_memo = memo_str.split('\n')[0] if '\n' in memo_str else memo_str
        return f"[{time_str.split('_')[0]}] {filter_str} - {display_memo[:50].replace('\n', ' ')}..."

    df['display_index'] = df.index
    selected_index = st.selectbox(
        "è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹è¨˜éŒ²ã‚’é¸æŠ", 
        options=df['display_index'], 
        format_func=format_func
    )

    if selected_index is not None:
        row = df.loc[selected_index]
        st.markdown(f"#### é¸æŠã•ã‚ŒãŸè¨˜éŒ² (ID: {selected_index+1})")
        
        if detail_cols:
            for col in detail_cols:
                if col in row and pd.notna(row[col]):
                    if col_memo == col or 'å†…å®¹' in col: # ãƒ¡ãƒ¢ã‚„å†…å®¹ãŒå¤šã„å ´åˆã¯ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã§è¡¨ç¤º
                        st.markdown(f"**{col}:**"); st.text(row[col])
                    elif 'URL' in col: # URLã¯æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§å‡¦ç†
                         continue
                    else:
                        st.write(f"**{col}:** {row[col]}")
        
        # æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« (R3: ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³ç”»åƒè¡¨ç¤ºå¯¾å¿œ)
        if col_url and col_url in row:
            st.markdown("##### æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«")
            
            try:
                # JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚’è©¦ã¿ã‚‹ (æœ€æ–°ã®ä¿å­˜å½¢å¼)
                urls = json.loads(row[col_url])
                filenames = json.loads(row[EPI_COL_FILENAME]) if EPI_COL_FILENAME in row and row[EPI_COL_FILENAME] else ['ãƒ•ã‚¡ã‚¤ãƒ«'] * len(urls)
                
                if urls:
                    for filename, url in zip(filenames, urls):
                        if url:
                            is_image = url.lower().endswith(('.png', '.jpg', '.jpeg'))
                            
                            if is_image and ("storage.googleapis.com" in url or "drive.google.com" in url):
                                # ç”»åƒã®å ´åˆã¯ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³è¡¨ç¤º (R3)
                                st.markdown(f"**ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«:** {filename}")
                                st.image(url, caption=filename, use_column_width=True)
                            elif "drive.google.com" in url:
                                # Google Driveã®ãƒªãƒ³ã‚¯
                                st.markdown(f"ğŸ”— **Google Drive:** [{filename}](<{url}>)")
                            else:
                                # ãã®ä»–ã®URLï¼ˆGCSãªã©ï¼‰
                                st.markdown(f"ğŸ”— [æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«]({url}) ({filename})")
                        
                else:
                    st.info("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

            except Exception:
                # JSONå½¢å¼ã§ã¯ãªã„å ´åˆï¼ˆå¤ã„ãƒ‡ãƒ¼ã‚¿ã‚„æ‰‹å‹•å…¥åŠ›ã€å˜ä¸€URLã®ç›´æ¥ä¿å­˜ï¼‰
                if pd.notna(row[col_url]) and row[col_url]:
                    url_list = row[col_url].split(',')
                    for url in url_list:
                         url = url.strip().strip('"')
                         if url:
                            is_image = url.lower().endswith(('.png', '.jpg', '.jpeg'))
                            if is_image and ("storage.googleapis.com" in url or "drive.google.com" in url):
                                st.image(url, caption="æ·»ä»˜ç”»åƒ", use_column_width=True) # R3
                            else:
                                st.markdown(f"ğŸ”— [æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«URL]({url})")
                else:
                    st.info("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")


# 1. ã‚¨ãƒ”ãƒãƒ¼ãƒˆæ©Ÿèƒ½
def page_epi_note_recording():
    st.markdown("#### ğŸ“ æ–°ã—ã„ã‚¨ãƒ”ãƒãƒ¼ãƒˆã‚’è¨˜éŒ²")
    
    with st.form(key='epi_note_form'):
        col1, col2 = st.columns(2)
        with col1:
            # R6: ã‚«ãƒ†ã‚´ãƒªã‚’D1/D2ã®é¸æŠå¼ã«
            ep_category = st.selectbox(f"{EPI_COL_CATEGORY} (è£…ç½®ç¨®åˆ¥)", ["D1", "D2", "ãã®ä»–"], key='ep_category_input')
        with col2:
            # R8: ã‚¿ã‚¤ãƒˆãƒ«/è¦ç´„ã‚’ã€Œç•ªå·(ä¾‹ï¼š791)ã€ã«å¤‰æ›´ (å¿…é ˆãƒã‚§ãƒƒã‚¯)
            ep_title = st.text_input("ç•ªå· (ä¾‹: 791) (å¿…é ˆ)", key='ep_title_input')
        
        # R9: è©³ç´°ãƒ¡ãƒ¢ã‚’ã€Œæ§‹é€ ï¼ˆç©ºç™½ã§ã‚‚å¯ï¼‰ã€ã«å¤‰æ›´
        ep_memo = st.text_area("æ§‹é€  (ä¾‹: 10nm GaAs/AlGaAs/GaAs) (ç©ºç™½ã§ã‚‚å¯)", height=100, key='ep_memo_input')
        
        uploaded_files = st.file_uploader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« (ç”»åƒã€ã‚°ãƒ©ãƒ•ãªã©)", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], accept_multiple_files=True)
        
        st.markdown("---")
        submit_button = st.form_submit_button(label='è¨˜éŒ²ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜')

    if submit_button:
        if not ep_title:
            st.warning("ç•ªå· (ä¾‹: 791) ã¯å¿…é ˆé …ç›®ã§ã™ã€‚")
            return
        
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    filename, url = upload_file_to_gcs(storage_client, file_obj, "ep_notes")
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)

        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # R8, R9: ãƒ¡ãƒ¢æ¬„ã«ã¯ã€Œç•ªå·\næ§‹é€ ã€ã®å½¢å¼ã§ä¿å­˜
        memo_content = f"{ep_title}\n{ep_memo}"
        row_data = [
            timestamp, EPI_COL_NOTE_TYPE, ep_category, 
            memo_content, filenames_json, urls_json
        ]
        
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_EPI_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ã‚¨ãƒ”ãƒãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼"); st.cache_data.clear(); st.rerun() # R7: æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        except Exception:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ãƒ¼ãƒˆå '{SHEET_EPI_DATA}' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def page_epi_note_list():
    detail_cols = [EPI_COL_TIMESTAMP, EPI_COL_CATEGORY, EPI_COL_NOTE_TYPE, EPI_COL_MEMO, EPI_COL_FILENAME]
    page_data_list(
        sheet_name=SHEET_EPI_DATA,
        title="ã‚¨ãƒ”ãƒãƒ¼ãƒˆ",
        col_time=EPI_COL_TIMESTAMP,
        col_filter=EPI_COL_CATEGORY,
        col_memo=EPI_COL_MEMO,
        col_url=EPI_COL_FILE_URL,
        detail_cols=detail_cols
    )
    
def page_epi_note():
    st.header("ã‚¨ãƒ”ãƒãƒ¼ãƒˆæ©Ÿèƒ½")
    st.markdown("---")
    tab_selection = st.radio("è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="epi_tab", horizontal=True)
    
    if tab_selection == "ğŸ“ è¨˜éŒ²": page_epi_note_recording()
    elif tab_selection == "ğŸ“š ä¸€è¦§": page_epi_note_list()


# 2. ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆæ©Ÿèƒ½
def page_mainte_recording():
    st.markdown("#### ğŸ› ï¸ æ–°ã—ã„ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆã‚’è¨˜éŒ²")
    
    with st.form(key='mainte_note_form'):
        
        # R10: é¸æŠå¼ã‹ã‚‰è¨˜å…¥å¼ã¸å¤‰æ›´ & ãƒ©ãƒ™ãƒ«å¤‰æ›´
        mainte_title = st.text_input("ãƒ¡ãƒ³ãƒ†ã‚¿ã‚¤ãƒˆãƒ« (ä¾‹: D1 ãƒ‰ãƒ©ã‚¤ãƒãƒ³ãƒ—äº¤æ›) (å¿…é ˆ)", key='mainte_title_input')
        memo_content = st.text_area("è©³ç´°ãƒ¡ãƒ¢", height=150, key='mainte_memo_input')
        uploaded_files = st.file_uploader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« (ç”»åƒã€ã‚°ãƒ©ãƒ•ãªã©)", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], accept_multiple_files=True)
        
        st.markdown("---")
        submit_button = st.form_submit_button(label='è¨˜éŒ²ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜')

    if submit_button:
        if not mainte_title:
            st.warning("ãƒ¡ãƒ³ãƒ†ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    filename, url = upload_file_to_gcs(storage_client, file_obj, "mainte_notes")
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)

        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # R10: çµåˆæ–¹æ³•ã‚’å¤‰æ›´ (ã‚¿ã‚¤ãƒˆãƒ«ã¨ãƒ¡ãƒ¢ã‚’çµåˆ)
        memo_to_save = f"[{mainte_title}]\n{memo_content}"
        row_data = [
            timestamp, MAINT_COL_NOTE_TYPE, memo_to_save, 
            filenames_json, urls_json
        ]
        
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_MAINTE_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼"); st.cache_data.clear(); st.rerun() # R7: æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        except Exception:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ãƒ¼ãƒˆå '{SHEET_MAINTE_DATA}' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def page_mainte_list():
    detail_cols = [MAINT_COL_TIMESTAMP, MAINT_COL_NOTE_TYPE, MAINT_COL_MEMO, MAINT_COL_FILENAME]
    page_data_list(
        sheet_name=SHEET_MAINTE_DATA,
        title="ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ",
        col_time=MAINT_COL_TIMESTAMP,
        col_filter=MAINT_COL_NOTE_TYPE, 
        col_memo=MAINT_COL_MEMO,
        col_url=MAINT_COL_FILE_URL,
        detail_cols=detail_cols
    )

def page_mainte_note():
    st.header("ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆæ©Ÿèƒ½")
    st.markdown("---")
    tab_selection = st.radio("è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="mainte_tab", horizontal=True)
    
    if tab_selection == "ğŸ“ è¨˜éŒ²": page_mainte_recording()
    elif tab_selection == "ğŸ“š ä¸€è¦§": page_mainte_list()


# 3. è­°äº‹éŒ²ãƒ»ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ãƒ¢æ©Ÿèƒ½
def page_meeting_recording():
    st.markdown("#### ğŸ“ æ–°ã—ã„è­°äº‹éŒ²ã‚’è¨˜éŒ²")
    
    with st.form(key='meeting_form'):
        meeting_title = st.text_input(f"{MEETING_COL_TITLE} (ä¾‹: 2025-10-28 å®šä¾‹ä¼šè­°)", key='meeting_title_input')
        meeting_content = st.text_area(f"{MEETING_COL_CONTENT}", height=300, key='meeting_content_input')
        col1, col2 = st.columns(2)
        with col1:
            audio_name = st.text_input(f"{MEETING_COL_AUDIO_NAME} (ä¾‹: audio.m4a)", key='audio_name_input')
        with col2:
            audio_url = st.text_input(f"{MEETING_COL_AUDIO_URL} (Google Drive URLãªã©)", key='audio_url_input')

        submit_button = st.form_submit_button(label='è¨˜éŒ²ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜')
        
    if submit_button:
        if not meeting_title or not meeting_content:
            st.warning("ä¼šè­°ã‚¿ã‚¤ãƒˆãƒ«ã¨è­°äº‹éŒ²å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
            
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        row_data = [
            timestamp, meeting_title, audio_name, 
            audio_url, meeting_content
        ]
        
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_MEETING_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… è­°äº‹éŒ²ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼"); st.cache_data.clear(); st.rerun() # R7: æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        except Exception:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ãƒ¼ãƒˆå '{SHEET_MEETING_DATA}' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def page_meeting_list():
    detail_cols = [MEETING_COL_TIMESTAMP, MEETING_COL_TITLE, MEETING_COL_CONTENT, MEETING_COL_AUDIO_NAME, MEETING_COL_AUDIO_URL]
    page_data_list(
        sheet_name=SHEET_MEETING_DATA,
        title="è­°äº‹éŒ²",
        col_time=MEETING_COL_TIMESTAMP,
        col_filter=MEETING_COL_TITLE,
        col_memo=MEETING_COL_CONTENT,
        col_url=MEETING_COL_AUDIO_URL,
        detail_cols=detail_cols
    )

def page_meeting_note():
    st.header("è­°äº‹éŒ²ãƒ»ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ãƒ¢æ©Ÿèƒ½")
    st.markdown("---")
    tab_selection = st.radio("è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="meeting_tab", horizontal=True)
    
    if tab_selection == "ğŸ“ è¨˜éŒ²": page_meeting_recording()
    elif tab_selection == "ğŸ“š ä¸€è¦§": page_meeting_list()


# 4. çŸ¥æµè¢‹ãƒ»è³ªå•ç®±æ©Ÿèƒ½
def page_qa_recording():
    st.markdown("#### ğŸ’¡ æ–°ã—ã„è³ªå•ã‚’æŠ•ç¨¿")
    
    with st.form(key='qa_form'):
        qa_title = st.text_input(f"{QA_COL_TITLE} (ä¾‹: XRDã®æ¸¬å®šæ‰‹é †ã«ã¤ã„ã¦)", key='qa_title_input')
        qa_content = st.text_area(f"{QA_COL_CONTENT}", height=200, key='qa_content_input')
        col1, col2 = st.columns(2)
        with col1:
            qa_contact = st.text_input(f"{QA_COL_CONTACT} (ä»»æ„)", key='qa_contact_input')
        with col2:
            uploaded_files = st.file_uploader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], accept_multiple_files=True)
            
        st.markdown("---")
        submit_button = st.form_submit_button(label='è³ªå•ã‚’æŠ•ç¨¿')

    if submit_button:
        if not qa_title or not qa_content:
            st.warning("è³ªå•ã‚¿ã‚¤ãƒˆãƒ«ã¨è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
        
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    filename, url = upload_file_to_gcs(storage_client, file_obj, "qa_files")
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)

        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        row_data = [
            timestamp, qa_title, qa_content, qa_contact, 
            filenames_json, urls_json, "æœªè§£æ±º" # åˆæœŸã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
        ]
        
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_QA_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… è³ªå•ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼å›ç­”ãŒã‚ã‚‹ã¾ã§ãŠå¾…ã¡ãã ã•ã„ã€‚"); st.cache_data.clear(); st.rerun() # R7: æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        except Exception:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ãƒ¼ãƒˆå '{SHEET_QA_DATA}' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def page_qa_list():
    detail_cols = [QA_COL_TIMESTAMP, QA_COL_TITLE, QA_COL_CONTENT, QA_COL_CONTACT, QA_COL_STATUS, QA_COL_FILENAME]
    page_data_list(
        sheet_name=SHEET_QA_DATA,
        title="çŸ¥æµè¢‹ãƒ»è³ªå•ç®±",
        col_time=QA_COL_TIMESTAMP,
        col_filter=QA_COL_STATUS, 
        col_memo=QA_COL_CONTENT,
        col_url=QA_COL_FILE_URL,
        detail_cols=detail_cols
    )
    st.info("â€» å›ç­”ã®é–²è¦§æ©Ÿèƒ½ã¯ç¾åœ¨é–‹ç™ºä¸­ã§ã™ã€‚")

def page_qa_box():
    st.header("çŸ¥æµè¢‹ãƒ»è³ªå•ç®±æ©Ÿèƒ½")
    st.markdown("---")
    tab_selection = st.radio("è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ", ["ğŸ’¡ è³ªå•æŠ•ç¨¿", "ğŸ“š è³ªå•ä¸€è¦§"], key="qa_tab", horizontal=True)
    
    if tab_selection == "ğŸ’¡ è³ªå•æŠ•ç¨¿": page_qa_recording()
    elif tab_selection == "ğŸ“š è³ªå•ä¸€è¦§": page_qa_list()


# 5. è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢æ©Ÿèƒ½
def page_handover_recording():
    st.markdown("#### ğŸ¤ æ–°ã—ã„å¼•ãç¶™ããƒ¡ãƒ¢ã‚’è¨˜éŒ²")
    
    with st.form(key='handover_form'):
        
        handover_type = st.selectbox(f"{HANDOVER_COL_TYPE} (ã‚«ãƒ†ã‚´ãƒª)", ["ãƒãƒ‹ãƒ¥ã‚¢ãƒ«", "è£…ç½®è¨­å®š", "ãã®ä»–ãƒ¡ãƒ¢"])
        handover_title = st.text_input(f"{HANDOVER_COL_TITLE} (ä¾‹: D1 MBEèµ·å‹•æ‰‹é †)", key='handover_title_input')
        handover_memo = st.text_area(f"{HANDOVER_COL_MEMO}", height=150, key='handover_memo_input', help="è©³ç´°ãªèª¬æ˜ã‚„ãƒªãƒ³ã‚¯ãªã©ã‚’è¨˜å…¥ã—ã¦ãã ã•ã„ã€‚")
        
        st.markdown("---")
        submit_button = st.form_submit_button(label='è¨˜éŒ²ã‚’ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜')

    if submit_button:
        if not handover_title:
            st.warning("ã‚¿ã‚¤ãƒˆãƒ«ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
            
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # æ—¢å­˜ã®ã‚·ãƒ¼ãƒˆæ§‹é€ ã«åˆã‚ã›ã‚‹ï¼ˆå†…å®¹1, 2, 3ã¯ç©ºã«ã—ã€ãƒ¡ãƒ¢ã«é›†ç´„ï¼‰
        row_data = [
            timestamp, handover_type, handover_title, 
            handover_memo, "", "", ""
        ]
        
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_HANDOVER_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… å¼•ãç¶™ããƒ¡ãƒ¢ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼"); st.cache_data.clear(); st.rerun() # R7: æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        except Exception:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ãƒ¼ãƒˆå '{SHEET_HANDOVER_DATA}' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def page_handover_list():
    detail_cols = [HANDOVER_COL_TIMESTAMP, HANDOVER_COL_TYPE, HANDOVER_COL_TITLE, 'å†…å®¹1', 'å†…å®¹2', 'å†…å®¹3', HANDOVER_COL_MEMO]
    page_data_list(
        sheet_name=SHEET_HANDOVER_DATA,
        title="è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢",
        col_time=HANDOVER_COL_TIMESTAMP,
        col_filter=HANDOVER_COL_TYPE,
        col_memo=HANDOVER_COL_TITLE,
        col_url='å†…å®¹1', 
        detail_cols=detail_cols
    )

def page_handover_note():
    st.header("è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢æ©Ÿèƒ½")
    st.markdown("---")
    tab_selection = st.radio("è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="handover_tab", horizontal=True)
    
    if tab_selection == "ğŸ“ è¨˜éŒ²": page_handover_recording()
    elif tab_selection == "ğŸ“š ä¸€è¦§": page_handover_list()


# 6. ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šæ©Ÿèƒ½
def page_trouble_recording():
    st.markdown("#### ğŸš¨ æ–°ã—ã„ãƒˆãƒ©ãƒ–ãƒ«ã‚’å ±å‘Š")
    
    # R5: æ©Ÿå™¨/å ´æ‰€ã®é¸æŠè‚¢
    DEVICE_OPTIONS = ["MBE", "XRD", "PL", "IV", "TEMãƒ»SEM", "æŠµæŠ—åŠ ç†±è’¸ç€", "RTA", "ãƒ•ã‚©ãƒˆãƒªã‚½", "ãƒ‰ãƒ©ãƒ•ã‚¿ãƒ¼", "ãã®ä»–"]

    with st.form(key='trouble_form'):
        
        st.subheader("åŸºæœ¬æƒ…å ±")
        col1, col2 = st.columns(2)
        with col1:
            report_date = st.date_input(f"{TROUBLE_COL_OCCUR_DATE} (ç™ºç”Ÿæ—¥)", datetime.now().date())
        with col2:
            # R5: é¸æŠè‚¢ã«å¤‰æ›´
            device_to_save = st.selectbox(f"{TROUBLE_COL_DEVICE} (æ©Ÿå™¨/å ´æ‰€)", DEVICE_OPTIONS, key='device_input')
            
        report_title = st.text_input(f"{TROUBLE_COL_TITLE} (ä»¶å/ã‚¿ã‚¤ãƒˆãƒ«) (å¿…é ˆ)", key='trouble_title_input')
        occur_time = st.text_area(f"{TROUBLE_COL_OCCUR_TIME} (çŠ¶æ³è©³ç´°)", height=100)
        
        st.subheader("å¯¾å¿œã¨è€ƒå¯Ÿ")
        cause = st.text_area(f"{TROUBLE_COL_CAUSE} (åŸå› /ç©¶æ˜)", height=100)
        solution = st.text_area(f"{TROUBLE_COL_SOLUTION} (å¯¾ç­–/å¾©æ—§)", height=100)
        prevention = st.text_area(f"{TROUBLE_COL_PREVENTION} (å†ç™ºé˜²æ­¢ç­–)", height=100)

        col3, col4 = st.columns(2)
        with col3:
            reporter_name = st.text_input(f"{TROUBLE_COL_REPORTER} (å ±å‘Šè€…) (å¿…é ˆ)", key='reporter_input')
        with col4:
            uploaded_files = st.file_uploader("æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«", type=['jpg', 'jpeg', 'png', 'pdf', 'txt'], accept_multiple_files=True)
            
        st.markdown("---")
        submit_button = st.form_submit_button(label='ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šã‚’ä¿å­˜')

    if submit_button:
        if not report_title or not reporter_name:
            st.warning("ã‚¿ã‚¤ãƒˆãƒ«ã¨å ±å‘Šè€…åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
            
        filenames_list = []; urls_list = []
        if uploaded_files:
            with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚’GCSã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
                for file_obj in uploaded_files:
                    filename, url = upload_file_to_gcs(storage_client, file_obj, "trouble_reports")
                    if url:
                        filenames_list.append(filename)
                        urls_list.append(url)

        filenames_json = json.dumps(filenames_list)
        urls_json = json.dumps(urls_list)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        row_data = [
            timestamp, device_to_save, report_date.isoformat(), occur_time,
            cause, solution, prevention, reporter_name,
            filenames_json, urls_json, report_title
        ]
        
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_TROUBLE_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸï¼"); st.cache_data.clear(); st.rerun() # R7: æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        except Exception:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ãƒ¼ãƒˆå '{SHEET_TROUBLE_DATA}' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def page_trouble_list():
    detail_cols = [
        TROUBLE_COL_TIMESTAMP, TROUBLE_COL_TITLE, TROUBLE_COL_DEVICE, TROUBLE_COL_OCCUR_DATE, 
        TROUBLE_COL_OCCUR_TIME, TROUBLE_COL_CAUSE, TROUBLE_COL_SOLUTION, TROUBLE_COL_PREVENTION, 
        TROUBLE_COL_REPORTER, TROUBLE_COL_FILENAME
    ]
    page_data_list(
        sheet_name=SHEET_TROUBLE_DATA,
        title="ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š",
        col_time=TROUBLE_COL_TIMESTAMP,
        col_filter=TROUBLE_COL_DEVICE,
        col_memo=TROUBLE_COL_TITLE,
        col_url=TROUBLE_COL_FILE_URL,
        detail_cols=detail_cols
    )

def page_trouble_report():
    st.header("ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šæ©Ÿèƒ½")
    st.markdown("---")
    tab_selection = st.radio("è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="trouble_tab", horizontal=True)
    
    if tab_selection == "ğŸ“ è¨˜éŒ²": page_trouble_recording()
    elif tab_selection == "ğŸ“š ä¸€è¦§": page_trouble_list()


# 7. é€£çµ¡ãƒ»å•ã„åˆã‚ã›æ©Ÿèƒ½
def page_contact_recording():
    st.markdown("#### âœ‰ï¸ æ–°ã—ã„å•ã„åˆã‚ã›ã‚’è¨˜éŒ²")
    
    with st.form(key='contact_form'):
        
        contact_type = st.selectbox(f"{CONTACT_COL_TYPE}", ["ãƒã‚°å ±å‘Š", "æ©Ÿèƒ½è¦æœ›", "ãƒ‡ãƒ¼ã‚¿ä¿®æ­£ä¾é ¼", "ãã®ä»–"])
        contact_detail = st.text_area(f"{CONTACT_COL_DETAIL}", height=150, key='contact_detail_input')
        contact_info = st.text_input(f"{CONTACT_COL_CONTACT} (ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ãªã©ã€ä»»æ„)", key='contact_info_input')
        
        st.markdown("---")
        submit_button = st.form_submit_button(label='é€ä¿¡')

    if submit_button:
        if not contact_detail:
            st.warning("è©³ç´°å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return
            
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        row_data = [
            timestamp, contact_type, contact_detail, contact_info
        ]
        
        try:
            worksheet = gc.open(SPREADSHEET_NAME).worksheet(SHEET_CONTACT_DATA)
            worksheet.append_row(row_data)
            st.success("âœ… ãŠå•ã„åˆã‚ã›ã‚’é€ä¿¡ã—ã¾ã—ãŸã€‚"); st.cache_data.clear(); st.rerun() # R7: æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        except Exception:
            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ã‚·ãƒ¼ãƒˆå '{SHEET_CONTACT_DATA}' ãŒå­˜åœ¨ã™ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

def page_contact_list():
    detail_cols = [CONTACT_COL_TIMESTAMP, CONTACT_COL_TYPE, CONTACT_COL_DETAIL, CONTACT_COL_CONTACT]
    page_data_list(
        sheet_name=SHEET_CONTACT_DATA,
        title="é€£çµ¡ãƒ»å•ã„åˆã‚ã›",
        col_time=CONTACT_COL_TIMESTAMP,
        col_filter=CONTACT_COL_TYPE,
        col_memo=CONTACT_COL_DETAIL,
        detail_cols=detail_cols
    )

def page_contact_form():
    st.header("é€£çµ¡ãƒ»å•ã„åˆã‚ã›æ©Ÿèƒ½")
    st.markdown("---")
    tab_selection = st.radio("è¡¨ç¤ºåˆ‡ã‚Šæ›¿ãˆ", ["ğŸ“ è¨˜éŒ²", "ğŸ“š ä¸€è¦§"], key="contact_tab", horizontal=True)
    
    if tab_selection == "ğŸ“ è¨˜éŒ²": page_contact_recording()
    elif tab_selection == "ğŸ“š ä¸€è¦§": page_contact_list()


# 8. IVãƒ‡ãƒ¼ã‚¿è§£æ
def page_iv_analysis():
    """âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æãƒšãƒ¼ã‚¸ï¼ˆæ—¥æœ¬èªå¯¾å¿œï¼‰"""
    st.header("âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ")
    
    uploaded_files = st.file_uploader(
        "IVæ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« (.txt) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
        type=['txt'], 
        accept_multiple_files=True
    )

    if uploaded_files:
        valid_dataframes = []
        filenames = []
        
        st.subheader("ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã¨è§£æ")
        
        for uploaded_file in uploaded_files:
            df = load_data_file(uploaded_file.getvalue(), uploaded_file.name)
            
            if df is not None and not df.empty:
                valid_dataframes.append(df)
                filenames.append(uploaded_file.name)
        
        if valid_dataframes:
            
            combined_df = combine_dataframes(valid_dataframes, filenames)
            
            st.success(f"{len(valid_dataframes)}å€‹ã®æœ‰åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€çµåˆã—ã¾ã—ãŸã€‚")
            
            st.subheader("ã‚¹ãƒ†ãƒƒãƒ—2: ã‚°ãƒ©ãƒ•è¡¨ç¤º (æ—¥æœ¬èªå¯¾å¿œ)")
            
            fig, ax = plt.subplots(figsize=(12, 7)) 
            
            for filename in filenames:
                ax.plot(combined_df['X_Axis'], combined_df[filename], label=filename)
            
            ax.set_xlabel("Voltage (V)") # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«
            ax.set_ylabel("Current (A)") # æ—¥æœ¬èªãƒ©ãƒ™ãƒ«
            ax.grid(True)
            ax.legend(title="ãƒ•ã‚¡ã‚¤ãƒ«å", loc='best')
            ax.set_title("IV Characteristic Plot") # æ—¥æœ¬èªã‚¿ã‚¤ãƒˆãƒ«
            
            st.pyplot(fig, use_container_width=True) 
            
            st.subheader("ã‚¹ãƒ†ãƒƒãƒ—3: çµåˆãƒ‡ãƒ¼ã‚¿")
            combined_df = combined_df.rename(columns={'X_Axis': 'Voltage_V'}) # è¡¨ç¤ºç”¨
            st.dataframe(combined_df, use_container_width=True)
            
            # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            output = BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                combined_df.to_excel(writer, sheet_name='Combined IV Data', index=False)
            
            st.download_button(
                label="ğŸ“ˆ çµåˆExcelãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=output.getvalue(),
                file_name=f"iv_analysis_combined_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


# 9. PLãƒ‡ãƒ¼ã‚¿è§£æ (ãƒ¦ãƒ¼ã‚¶ãƒ¼æä¾›ã®é«˜åº¦ãªæ³¢é•·æ ¡æ­£ãƒ­ã‚¸ãƒƒã‚¯ã«ç½®ãæ›ãˆ R4)
def page_pl_analysis():
    st.header("ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ")
    
    with st.expander("ã‚¹ãƒ†ãƒƒãƒ—1ï¼šæ³¢é•·æ ¡æ­£", expanded=True):
        st.write("2ã¤ã®åŸºæº–æ³¢é•·ã®åå°„å…‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€åˆ†å…‰å™¨ã®å‚¾ãï¼ˆnm/pixelï¼‰ã‚’æ ¡æ­£ã—ã¾ã™ã€‚")
        col1, col2 = st.columns(2)
        with col1:
            cal1_wavelength = st.number_input("åŸºæº–æ³¢é•·1 (nm)", value=1500)
            cal1_file = st.file_uploader(f"{cal1_wavelength}nm ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ« (.txt)", type=['txt'], key="cal1")
        with col2:
            cal2_wavelength = st.number_input("åŸºæº–æ³¢é•·2 (nm)", value=1570)
            cal2_file = st.file_uploader(f"{cal2_wavelength}nm ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ« (.txt)", type=['txt'], key="cal2")
            
        if st.button("æ ¡æ­£ã‚’å®Ÿè¡Œ", key="run_calibration"):
            if cal1_file and cal2_file:
                # load_pl_data (pixel, intensity) ã‚’ä½¿ç”¨
                df1 = load_pl_data(cal1_file)
                df2 = load_pl_data(cal2_file)
                
                if df1 is not None and df2 is not None:
                    # ãƒ”ãƒ¼ã‚¯ä½ç½®ã®è¨ˆç®—
                    peak_pixel1 = df1['pixel'].iloc[df1['intensity'].idxmax()]
                    peak_pixel2 = df2['pixel'].iloc[df2['intensity'].idxmax()]
                    
                    st.write("---"); st.subheader("æ ¡æ­£çµæœ")
                    col_res1, col_res2, col_res3 = st.columns(3)
                    col_res1.metric(f"{cal1_wavelength}nmã®ãƒ”ãƒ¼ã‚¯ä½ç½®", f"{int(peak_pixel1)} pixel")
                    col_res2.metric(f"{cal2_wavelength}nmã®ãƒ”ãƒ¼ã‚¯ä½ç½®", f"{int(peak_pixel2)} pixel")
                    
                    try:
                        delta_wave = float(cal2_wavelength - cal1_wavelength)
                        # ãƒ”ã‚¯ã‚»ãƒ«å€¤ã®å·®åˆ†è¨ˆç®— (ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ã‚¸ãƒƒã‚¯ã®æ–¹å‘ã‚’ç¶­æŒ)
                        delta_pixel = float(peak_pixel1 - peak_pixel2) 
                        
                        if delta_pixel == 0:
                            st.error("2ã¤ã®ãƒ”ãƒ¼ã‚¯ä½ç½®ãŒåŒã˜ã§ã™ã€‚ç•°ãªã‚‹æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã™ã‚‹ã‹ã€ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        else:
                            slope = delta_wave / delta_pixel
                            col_res3.metric("æ ¡æ­£ä¿‚æ•° (nm/pixel)", f"{slope:.4f}")
                            st.session_state['pl_calibrated'] = True
                            st.session_state['pl_slope'] = slope
                            st.session_state['pl_center_wl_cal'] = cal1_wavelength
                            st.session_state['pl_center_pixel_cal'] = peak_pixel1
                            st.success("âœ… æ ¡æ­£ä¿‚æ•°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒƒãƒ—2ã«é€²ã‚“ã§ãã ã•ã„ã€‚")
                    except Exception as e:
                        st.error(f"æ ¡æ­£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                else:
                    st.error("æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            else:
                st.warning("ä¸¡æ–¹ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

    st.write("---")
    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—2ï¼šæ¸¬å®šãƒ‡ãƒ¼ã‚¿è§£æ")
    if 'pl_calibrated' not in st.session_state or not st.session_state['pl_calibrated']:
        st.info("ğŸ’¡ ã¾ãšã€ã‚¹ãƒ†ãƒƒãƒ—1ã®æ³¢é•·æ ¡æ­£ã‚’å®Œäº†ã•ã›ã¦ãã ã•ã„ã€‚")
    else:
        st.success(f"âœ… æ³¢é•·æ ¡æ­£æ¸ˆã¿ã§ã™ã€‚ï¼ˆæ ¡æ­£ä¿‚æ•°: **{st.session_state['pl_slope']:.4f} nm/pixel**ï¼‰")
        
        with st.container(border=True):
            center_wavelength_input = st.number_input(
                "æ¸¬å®šæ™‚ã®ä¸­å¿ƒæ³¢é•· (nm)", min_value=0, value=1700, step=10,
                help="ã“ã®æ¸¬å®šã§è£…ç½®ã«è¨­å®šã—ãŸä¸­å¿ƒæ³¢é•·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
            )
            uploaded_files = st.file_uploader("æ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['txt'], accept_multiple_files=True)
            
            if uploaded_files:
                st.subheader("è§£æçµæœ")
                fig, ax = plt.subplots(figsize=(10, 6))
                
                all_dataframes = []
                
                for uploaded_file in uploaded_files:
                    df = load_pl_data(uploaded_file)
                    if df is not None:
                        slope = st.session_state['pl_slope']
                        # ã‚»ãƒ³ã‚¿ãƒ¼ãƒ”ã‚¯ã‚»ãƒ«ã¯ 256.5 ã‚’ä½¿ç”¨ (ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¶­æŒ)
                        center_pixel = 256.5 
                        
                        # æ³¢é•·å¤‰æ›ã®å®Ÿè¡Œ: Wavelength = (Pixel - Center_Pixel) * Slope + Center_Wavelength
                        df['wavelength_nm'] = (df['pixel'] - center_pixel) * slope + center_wavelength_input
                        
                        base_name = os.path.splitext(uploaded_file.name)[0]
                        # å‡¡ä¾‹ã®è‡ªå‹•æ•´å½¢ (ä¸­å¿ƒæ³¢é•·éƒ¨åˆ†ã‚’å‰Šé™¤)
                        cleaned_label = base_name.replace(str(int(center_wavelength_input)), "").strip(' _-')
                        label = cleaned_label if cleaned_label else base_name
                        
                        ax.plot(df['wavelength_nm'], df['intensity'], label=label, linewidth=2.5)
                        
                        export_df = df[['wavelength_nm', 'intensity']].copy()
                        export_df.rename(columns={'intensity': base_name}, inplace=True)
                        all_dataframes.append(export_df)

                if all_dataframes:
                    # æ³¢é•·ã‚’ã‚­ãƒ¼ã«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’çµåˆ
                    final_df = all_dataframes[0].rename(columns={'wavelength_nm': 'wavelength_nm'})
                    for i in range(1, len(all_dataframes)):
                        final_df = pd.merge(final_df, all_dataframes[i], on='wavelength_nm', how='outer')
                        
                    final_df = final_df.sort_values(by='wavelength_nm').reset_index(drop=True)

                    # ã‚°ãƒ©ãƒ•è¨­å®š
                    ax.set_title(f"PL spectrum (Center: {center_wavelength_input} nm)")
                    ax.set_xlabel("Wavelength [nm]"); ax.set_ylabel("PL intensity [a.u.]")
                    ax.legend(loc='upper left', frameon=False, fontsize=10)
                    ax.grid(axis='y', linestyle='-', color='lightgray', zorder=0)
                    ax.tick_params(direction='in', top=True, right=True, which='both')
                    
                    min_wl = final_df['wavelength_nm'].min()
                    max_wl = final_df['wavelength_nm'].max()
                    padding = (max_wl - min_wl) * 0.05
                    ax.set_xlim(min_wl - padding, max_wl + padding)
                    
                    st.pyplot(fig)
                    
                    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer: # openpyxlã‚’xlsxwriterã«å¤‰æ›´
                        final_df.to_excel(writer, index=False, sheet_name='Combined PL Data')

                    processed_data = output.getvalue()
                    st.download_button(label="ğŸ“ˆ Excelãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=processed_data, file_name=f"pl_analysis_combined_{center_wavelength_input}nm.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
                else:
                    st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            else:
                 st.info("æ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

# --- Dummy Pages (æœªå®Ÿè£…ã®ãƒšãƒ¼ã‚¸) ---
def page_calendar(): st.header("ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„"); st.info("ã“ã®ãƒšãƒ¼ã‚¸ã¯æœªå®Ÿè£…ã§ã™ã€‚")

# --------------------------------------------------------------------------
# --- Main App Execution ---
# --------------------------------------------------------------------------
def main():
    st.sidebar.title("å±±æ ¹ç ” ãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ")
    
    # ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’è¨˜éŒ²ãƒ»ä¸€è¦§ã§çµ±åˆ
    menu_selection = st.sidebar.radio("æ©Ÿèƒ½é¸æŠ", [
        "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ", "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ", "è­°äº‹éŒ²", "çŸ¥æµè¢‹ãƒ»è³ªå•ç®±", "è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢", "ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š", "é€£çµ¡ãƒ»å•ã„åˆã‚ã›",
        "âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ", "ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ", "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„"
    ])
    
    # ãƒšãƒ¼ã‚¸ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    if menu_selection == "ã‚¨ãƒ”ãƒãƒ¼ãƒˆ": page_epi_note()
    elif menu_selection == "ãƒ¡ãƒ³ãƒ†ãƒãƒ¼ãƒˆ": page_mainte_note()
    elif menu_selection == "è­°äº‹éŒ²": page_meeting_note()
    elif menu_selection == "çŸ¥æµè¢‹ãƒ»è³ªå•ç®±": page_qa_box()
    elif menu_selection == "è£…ç½®å¼•ãç¶™ããƒ¡ãƒ¢": page_handover_note()
    elif menu_selection == "ãƒˆãƒ©ãƒ–ãƒ«å ±å‘Š": page_trouble_report()
    elif menu_selection == "é€£çµ¡ãƒ»å•ã„åˆã‚ã›": page_contact_form()
    elif menu_selection == "âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ": page_iv_analysis()
    elif menu_selection == "ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ": page_pl_analysis()
    elif menu_selection == "ğŸ—“ï¸ ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ»è£…ç½®äºˆç´„": page_calendar()


if __name__ == "__main__":
    main()




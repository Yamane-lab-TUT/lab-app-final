# --------------------------------------------------------------------------
# Yamane Lab Convenience Tool - Streamlit Application
#
# v18.10.4 (Final IV Data Fix):
# - REVERTED: IV data export logic is reverted to combine all files into a SINGLE Excel sheet.
# - OPTIMIZED: The pd.merge process is optimized to handle memory constraints by merging files sequentially.
# - PREVIOUS FIXES (loading stability, plot size) are maintained.
# --------------------------------------------------------------------------

import streamlit as st
import gspread
import pandas as pd
import os
import io
import re
import json
import matplotlib.pyplot as plt
import numpy as np
from datetime import datetime, time, timedelta
from urllib.parse import quote as url_quote
from io import BytesIO

# Google API client libraries
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from google.cloud import storage
from google.auth.exceptions import DefaultCredentialsError
from google.api_core import exceptions

# --- Global Configuration & Setup ---
st.set_page_config(page_title="å±±æ ¹ç ” ä¾¿åˆ©å±‹ã•ã‚“", layout="wide")

# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…
# â†“â†“â†“â†“â†“â†“ ã€é‡è¦ã€‘ã”è‡ªèº«ã®ã€Œãƒã‚±ãƒƒãƒˆåã€ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ â†“â†“â†“â†“â†“â†“
CLOUD_STORAGE_BUCKET_NAME = "yamane-lab-app-files" # placeholder
# â†‘â†‘â†‘â†‘â†‘â†‘ ã€é‡è¦ã€‘ã”è‡ªèº«ã®ã€Œãƒã‚±ãƒƒãƒˆåã€ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ â†‘â†‘â†‘â†‘â†‘â†‘
# â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…â˜…

SPREADSHEET_NAME = 'ã‚¨ãƒ”ãƒãƒ¼ãƒˆ'
DEFAULT_CALENDAR_ID = 'yamane.lab.6747@gmail.com'
INQUIRY_RECIPIENT_EMAIL = 'kyuno.yamato.ns@tut.ac.jp'

# --- Initialize Google Services ---
@st.cache_resource(show_spinner="Googleã‚µãƒ¼ãƒ“ã‚¹ã«æ¥ç¶šä¸­...")
def initialize_google_services():
    """Googleã‚µãƒ¼ãƒ“ã‚¹ï¼ˆSpreadsheet, Calendar, Storageï¼‰ã‚’åˆæœŸåŒ–ã—ã€èªè¨¼æƒ…å ±ã‚’è¨­å®šã™ã‚‹ã€‚"""
    try:
        scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive', 'https://www.googleapis.com/auth/calendar', 'https://www.googleapis.com/auth/devstorage.read_write']
        
        if "gcs_credentials" not in st.secrets:
            # å®Ÿéš›ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã“ã“ã«é©åˆ‡ãªã‚¨ãƒ©ãƒ¼å‡¦ç†ãŒå¿…è¦
            st.error("âŒ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: Streamlit Cloudã®Secretsã« `gcs_credentials` ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
            # ãƒ‡ãƒ¢ç”¨ã«ãƒ€ãƒŸãƒ¼ã®èªè¨¼æƒ…å ±ã‚’è¨­å®šï¼ˆæœ¬ç•ªç’°å¢ƒã§ã¯å‰Šé™¤ï¼‰
            class DummyGSClient:
                def open(self, name):
                    class DummyWorksheet:
                        def append_row(self, row): pass
                        def get_all_values(self): return [[]]
                    class DummySpreadsheet:
                        def worksheet(self, name): return DummyWorksheet()
                    return DummySpreadsheet()
            class DummyCalendarService:
                def events(self):
                    class DummyEvents:
                        def list(self, **kwargs): return {"items": []}
                        def insert(self, **kwargs): return {"summary": "ãƒ€ãƒŸãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ", "htmlLink": "#"}
                    return DummyEvents()
            class DummyStorageClient:
                def bucket(self, name):
                    class DummyBlob:
                        def upload_from_file(self, file, content_type): pass
                        def generate_signed_url(self, expiration): return "#"
                    class DummyBucket:
                        def blob(self, name): return DummyBlob()
                    return DummyBucket()

            return DummyGSClient(), DummyCalendarService(), DummyStorageClient()
        
        creds_string = st.secrets["gcs_credentials"]
        creds_string_cleaned = creds_string.replace('\u00A0', '')
        creds_dict = json.loads(creds_string_cleaned)
        
        creds = Credentials.from_service_account_info(creds_dict, scopes=scopes)

        gc = gspread.authorize(creds)
        calendar_service = build('calendar', 'v3', credentials=creds)
        storage_client = storage.Client(credentials=creds)
        
        return gc, calendar_service, storage_client
    except Exception as e:
        st.error(f"âŒ è‡´å‘½çš„ãªã‚¨ãƒ©ãƒ¼: ã‚µãƒ¼ãƒ“ã‚¹ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸã€‚"); st.exception(e); st.stop()

gc, calendar_service, storage_client = initialize_google_services()

# --- Utility Functions ---
@st.cache_data(ttl=300, show_spinner="ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã‚’èª­ã¿è¾¼ã¿ä¸­...")
def get_sheet_as_df(_gc, spreadsheet_name, sheet_name):
    """Google Spreadsheetã®ã‚·ãƒ¼ãƒˆã‚’Pandas DataFrameã¨ã—ã¦å–å¾—ã™ã‚‹ã€‚"""
    try:
        worksheet = _gc.open(spreadsheet_name).worksheet(sheet_name)
        data = worksheet.get_all_values()
        if len(data) <= 1: return pd.DataFrame(columns=data[0] if data else [])
        return pd.DataFrame(data[1:], columns=data[0])
    except gspread.exceptions.WorksheetNotFound:
        st.error(f"ã‚·ãƒ¼ãƒˆåã€Œ{sheet_name}ã€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"); return pd.DataFrame()
    except Exception:
        st.warning(f"ã‚·ãƒ¼ãƒˆã€Œ{sheet_name}ã€ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã€‚ç©ºã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚"); return pd.DataFrame()

def upload_file_to_gcs(storage_client, bucket_name, file_uploader_obj, memo_content=""):
    """å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Google Cloud Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ç½²åä»˜ãURLã‚’ç”Ÿæˆã™ã‚‹ã€‚ï¼ˆã‚¨ãƒ”ãƒãƒ¼ãƒˆã€è­°äº‹éŒ²ã€çŸ¥æµè¢‹ç”¨ï¼‰"""
    if not file_uploader_obj: return "", ""
    try:
        bucket = storage_client.bucket(bucket_name)
        
        timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
        file_extension = os.path.splitext(file_uploader_obj.name)[1]
        sanitized_memo = re.sub(r'[\\/:*?"<>|\r\n]+', '', memo_content)[:50] if memo_content else "ç„¡é¡Œ"
        destination_blob_name = f"{timestamp}_{sanitized_memo}{file_extension}"
        
        blob = bucket.blob(destination_blob_name)
        
        with st.spinner(f"'{file_uploader_obj.name}'ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
            file_uploader_obj.seek(0) # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å…ˆé ­ã«æˆ»ã™
            blob.upload_from_file(file_uploader_obj, content_type=file_uploader_obj.type)

        expiration_time = timedelta(days=365 * 100)
        signed_url = blob.generate_signed_url(expiration=expiration_time)

        st.success(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ« '{destination_blob_name}' ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        return destination_blob_name, signed_url
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"); return "ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¤±æ•—", ""

def upload_files_to_gcs(storage_client, bucket_name, file_uploader_obj_list, memo_content=""):
    """
    è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Google Cloud Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«åã¨URLã®ãƒªã‚¹ãƒˆã‚’JSONæ–‡å­—åˆ—ã¨ã—ã¦ç”Ÿæˆã™ã‚‹ã€‚ï¼ˆãƒˆãƒ©ãƒ–ãƒ«å ±å‘Šç”¨ï¼‰
    
    æˆ»ã‚Šå€¤: (filenames_json_string, urls_json_string)
    """
    if not file_uploader_obj_list: return "[]", "[]"
    
    uploaded_data = []
    bucket = storage_client.bucket(bucket_name)

    try:
        with st.spinner(f"{len(file_uploader_obj_list)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­..."):
            for uploaded_file in file_uploader_obj_list:
                timestamp = datetime.now().strftime("%Y%m%d-%H%M%S-%f") # ã‚ˆã‚Šãƒ¦ãƒ‹ãƒ¼ã‚¯ãªã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
                file_extension = os.path.splitext(uploaded_file.name)[1]
                sanitized_memo = re.sub(r'[\\/:*?"<>|\r\n]+', '', memo_content)[:30] if memo_content else "ç„¡é¡Œ"
                destination_blob_name = f"{timestamp}_{sanitized_memo}_{uploaded_file.name}"
                
                blob = bucket.blob(destination_blob_name)
                
                # ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å…ˆé ­ã«æˆ»ã—ã¦ã‹ã‚‰ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
                uploaded_file.seek(0) 
                blob.upload_from_file(uploaded_file, content_type=uploaded_file.type)

                expiration_time = timedelta(days=365 * 100)
                signed_url = blob.generate_signed_url(expiration=expiration_time)
                
                uploaded_data.append({
                    "name": uploaded_file.name,
                    "blob": destination_blob_name, # GCSä¸Šã§ã®ãƒ•ã‚¡ã‚¤ãƒ«å
                    "url": signed_url
                })

        st.success(f"ğŸ“„ {len(uploaded_data)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ã¯ã€ãƒ•ã‚¡ã‚¤ãƒ«åã¨URLã®ãƒªã‚¹ãƒˆã‚’JSONæ–‡å­—åˆ—ã¨ã—ã¦ä¿å­˜ã™ã‚‹
        # â˜…é‡è¦: ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®åˆ—æ§‹æˆã«åˆã‚ã›ã¦ã€ãƒ•ã‚¡ã‚¤ãƒ«åã¨URLã¯å…ƒã®å½¢å¼ï¼ˆblobåã¨ç½²åURLï¼‰ã§JSONåŒ–ã—ã¦ä¿å­˜ã™ã‚‹
        filenames_list = [item['blob'] for item in uploaded_data]
        urls_list = [item['url'] for item in uploaded_data]
        
        return json.dumps(filenames_list), json.dumps(urls_list)
        
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}"); return "[]", "[]"


def generate_gmail_link(recipient, subject, body):
    """Gmailã®æ–°è¦ä½œæˆãƒªãƒ³ã‚¯ã‚’ç”Ÿæˆã™ã‚‹ã€‚"""
    return f"https://mail.google.com/mail/?view=cm&fs=1&to={url_quote(recipient)}&su={url_quote(subject)}&body={url_quote(body)}"

# --- PLãƒ‡ãƒ¼ã‚¿è§£æç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---
def load_pl_data(uploaded_file):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸtxtãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€Pandas DataFrameã‚’è¿”ã™é–¢æ•°ã€‚
    ãƒ‡ãƒ¼ã‚¿ã¯2åˆ—ï¼ˆpixel, intensityï¼‰ã®å½¢å¼ã‚’æƒ³å®šã—ã€ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è‡ªå‹•ã§ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚
    """
    try:
        content = uploaded_file.getvalue().decode('utf-8').splitlines()
        data_start_line = 0
        for i, line in enumerate(content):
            if any(char.isdigit() for char in line):
                data_start_line = i
                break
        
        data_string_io = io.StringIO("\n".join(content[data_start_line:]))
        df = pd.read_csv(data_string_io, sep=',', header=None, names=['pixel', 'intensity'])

        df['pixel'] = pd.to_numeric(df['pixel'], errors='coerce')
        df['intensity'] = pd.to_numeric(df['intensity'], errors='coerce')
        df.dropna(inplace=True)

        if df.empty:
            st.warning(f"è­¦å‘Šï¼š'{uploaded_file.name}'ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return None
        
        return df

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ï¼š'{uploaded_file.name}'ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚({e})")
        return None

# --- IVãƒ‡ãƒ¼ã‚¿è§£æç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ (æœ€çµ‚ä¿®æ­£ç‰ˆ) ---
def load_iv_data(uploaded_file):
    """
    ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸIVç‰¹æ€§ã®txtãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€Pandas DataFrameã‚’è¿”ã™é–¢æ•°ã€‚
    æ–‡å­—åˆ—ã®å‰å‡¦ç†ã‚’è¡Œã„ã€ç¢ºå®Ÿã«ãƒ‡ãƒ¼ã‚¿åˆ—ï¼ˆ2åˆ—ï¼‰ã‚’æŠ½å‡ºã—ã¾ã™ã€‚
    """
    try:
        # 1. ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’UTF-8ã§èª­ã¿è¾¼ã¿
        content = uploaded_file.getvalue().decode('utf-8')
        
        # 2. è¡Œã”ã¨ã«åˆ†å‰²ã—ã€ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ(1è¡Œç›®)ã¨ç©ºè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãƒ‡ãƒ¼ã‚¿è¡Œã ã‘ã‚’æŠ½å‡º
        lines = content.splitlines()
        data_lines = lines[1:] # 1è¡Œç›®ã®ãƒ˜ãƒƒãƒ€ãƒ¼ "VF(V) IF(A)" ã‚’ã‚¹ã‚­ãƒƒãƒ—
        
        cleaned_lines = []
        for line in data_lines:
            # è¡Œé ­/è¡Œæœ«ã®ç©ºç™½ã‚’å‰Šé™¤ã—ã€è¤‡æ•°ã®ç©ºç™½æ–‡å­—ï¼ˆ\s+ï¼‰ã‚’å˜ä¸€ã®ã‚¿ãƒ–ï¼ˆ\tï¼‰ã«ç½®æ›
            cleaned_line = re.sub(r'\s+', '\t', line.strip())
            if cleaned_line: # ç©ºè¡Œã‚’é™¤å¤–
                cleaned_lines.append(cleaned_line)

        # 3. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’è¡Œã¨ã—ã¦StringIOã«æ ¼ç´
        processed_data = '\n'.join(cleaned_lines)
        if not processed_data:
            st.warning(f"è­¦å‘Šï¼š'{uploaded_file.name}'ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return None
        
        data_string_io = io.StringIO(processed_data)
        
        # 4. é«˜é€ŸãªCã‚¨ãƒ³ã‚¸ãƒ³ã§ã‚¿ãƒ–åŒºåˆ‡ã‚Šã¨ã—ã¦èª­ã¿è¾¼ã¿
        df = pd.read_csv(data_string_io, sep='\t', engine='c', header=None)
        
        # æœ€åˆã®2åˆ—ã®ã¿ã‚’ä½¿ç”¨ã—ã€åˆ—åã‚’å†è¨­å®š
        if df is None or len(df.columns) < 2:
            st.warning(f"è­¦å‘Šï¼š'{uploaded_file.name}'ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚ï¼ˆãƒ‡ãƒ¼ã‚¿åˆ—ä¸è¶³ï¼‰")
            return None
        
        df = df.iloc[:, :2]
        df.columns = ['Voltage_V', 'Current_A']

        # æ•°å€¤å‹ã«å¤‰æ›ã—ã€å¤‰æ›ã§ããªã„è¡Œã¯å‰Šé™¤
        df['Voltage_V'] = pd.to_numeric(df['Voltage_V'], errors='coerce')
        df['Current_A'] = pd.to_numeric(df['Current_A'], errors='coerce')
        df.dropna(inplace=True)
        
        if df.empty:
            st.warning(f"è­¦å‘Šï¼š'{uploaded_file.name}'ã«æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return None
        
        return df

    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ï¼š'{uploaded_file.name}'ã®èª­ã¿è¾¼ã¿ä¸­ã«äºˆæœŸã›ã¬å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚({e})")
        return None


# --- UI Page Functions ---

# ... (page_note_recording, page_note_list, page_calendar, page_minutes, page_qa, page_handover, page_inquiry ã¯çœç•¥ã€‚å¤‰æ›´ãªã—) ...

def page_pl_analysis():
    # ... (PLãƒ‡ãƒ¼ã‚¿è§£æé–¢æ•°ã¯å¤‰æ›´ãªã—ã€‚ãŸã ã—ã€IVè§£æã¨åŒæ§˜ã«Excelã¸ã®æ›¸ãå‡ºã—æ–¹æ³•ã‚’å¤‰æ›´ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€
    #      ä»Šå›ã¯IVè§£æã®ã¿ã‚’è¦æ±‚ã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€PLè§£æã®Excelæ›¸ãå‡ºã—ãƒ­ã‚¸ãƒƒã‚¯ã¯å‰å›ä¿®æ­£ç‰ˆã®ã¾ã¾ã¨ã™ã‚‹)
    st.header("ğŸ”¬ PLãƒ‡ãƒ¼ã‚¿è§£æ")
    with st.expander("ã‚¹ãƒ†ãƒƒãƒ—1ï¼šæ³¢é•·æ ¡æ­£", expanded=True):
        st.write("2ã¤ã®åŸºæº–æ³¢é•·ã®åå°„å…‰ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ã€åˆ†å…‰å™¨ã®å‚¾ãï¼ˆnm/pixelï¼‰ã‚’æ ¡æ­£ã—ã¾ã™ã€‚")
        col1, col2 = st.columns(2)
        with col1:
            cal1_wavelength = st.number_input("åŸºæº–æ³¢é•·1 (nm)", value=1500)
            cal1_file = st.file_uploader(f"{cal1_wavelength}nm ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ« (.txt)", type=['txt'], key="cal1")
        with col2:
            cal2_wavelength = st.number_input("åŸºæº–æ³¢é•·2 (nm)", value=1570)
            cal2_file = st.file_uploader(f"{cal2_wavelength}nm ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ« (.txt)", type=['txt'], key="cal2")
        if st.button("æ ¡æ­£ã‚’å®Ÿè¡Œ", key="run_calibration"):
            if cal1_file and cal2_file:
                df1 = load_pl_data(cal1_file)
                df2 = load_pl_data(cal2_file)
                if df1 is not None and df2 is not None:
                    peak_pixel1 = df1['pixel'].iloc[df1['intensity'].idxmax()]
                    peak_pixel2 = df2['pixel'].iloc[df2['intensity'].idxmax()]
                    st.write("---"); st.subheader("æ ¡æ­£çµæœ")
                    col_res1, col_res2, col_res3 = st.columns(3)
                    col_res1.metric(f"{cal1_wavelength}nmã®ãƒ”ãƒ¼ã‚¯ä½ç½®", f"{int(peak_pixel1)} pixel")
                    col_res2.metric(f"{cal2_wavelength}nmã®ãƒ”ãƒ¼ã‚¯ä½ç½®", f"{int(peak_pixel2)} pixel")
                    try:
                        delta_wave = float(cal2_wavelength - cal1_wavelength)
                        delta_pixel = float(peak_pixel1 - peak_pixel2)
                        if delta_pixel == 0:
                            st.error("2ã¤ã®ãƒ”ãƒ¼ã‚¯ä½ç½®ãŒåŒã˜ã§ã™ã€‚ç•°ãªã‚‹æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã™ã‚‹ã‹ã€ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                        else:
                            slope = delta_wave / delta_pixel
                            col_res3.metric("æ ¡æ­£ä¿‚æ•° (nm/pixel)", f"{slope:.4f}")
                            st.session_state['pl_calibrated'] = True
                            st.session_state['pl_slope'] = slope
                            st.success("æ ¡æ­£ä¿‚æ•°ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚ã‚¹ãƒ†ãƒƒãƒ—2ã«é€²ã‚“ã§ãã ã•ã„ã€‚")
                    except Exception as e:
                        st.error(f"æ ¡æ­£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨ˆç®—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            else:
                st.warning("ä¸¡æ–¹ã®æ ¡æ­£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")

    st.write("---")
    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—2ï¼šæ¸¬å®šãƒ‡ãƒ¼ã‚¿è§£æ")
    if 'pl_calibrated' not in st.session_state or not st.session_state['pl_calibrated']:
        st.info("ã¾ãšã€ã‚¹ãƒ†ãƒƒãƒ—1ã®æ³¢é•·æ ¡æ­£ã‚’å®Œäº†ã•ã›ã¦ãã ã•ã„ã€‚")
    else:
        st.success(f"æ³¢é•·æ ¡æ­£æ¸ˆã¿ã§ã™ã€‚ï¼ˆæ ¡æ­£ä¿‚æ•°: {st.session_state['pl_slope']:.4f} nm/pixelï¼‰")
        with st.container(border=True):
            center_wavelength_input = st.number_input(
                "æ¸¬å®šæ™‚ã®ä¸­å¿ƒæ³¢é•· (nm)", min_value=0, value=1700, step=10,
                help="ã“ã®æ¸¬å®šã§è£…ç½®ã«è¨­å®šã—ãŸä¸­å¿ƒæ³¢é•·ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚å‡¡ä¾‹ã®è‡ªå‹•æ•´å½¢ã«ã‚‚ä½¿ã‚ã‚Œã¾ã™ã€‚"
            )
            uploaded_files = st.file_uploader("æ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=['txt'], accept_multiple_files=True)
            if uploaded_files:
                st.subheader("è§£æçµæœ")
                
                # â˜…ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºã‚’å¤§ããã™ã‚‹
                fig, ax = plt.subplots(figsize=(12, 7)) 
                
                all_dataframes = []
                
                for uploaded_file in uploaded_files:
                    df = load_pl_data(uploaded_file)
                    if df is not None:
                        slope = st.session_state['pl_slope']
                        center_pixel = 256.5
                        df['wavelength_nm'] = (df['pixel'] - center_pixel) * slope + center_wavelength_input
                        
                        base_name = os.path.splitext(uploaded_file.name)[0]
                        cleaned_label = base_name.replace(str(int(center_wavelength_input)), "").strip(' _-')
                        label = cleaned_label if cleaned_label else base_name
                        
                        ax.plot(df['wavelength_nm'], df['intensity'], label=label, linewidth=2.5)
                        
                        # ã‚¨ã‚¯ã‚»ãƒ«å‡ºåŠ›ç”¨ã«ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æº–å‚™ (PLã¯å…ƒã®ãƒ­ã‚¸ãƒƒã‚¯ã®ã¾ã¾)
                        export_df = df[['wavelength_nm', 'intensity']].copy()
                        export_df.columns = ['wavelength_nm', f"intensity ({base_name})"] # ãƒ•ã‚¡ã‚¤ãƒ«åä»˜ãã®ãƒ˜ãƒƒãƒ€ãƒ¼
                        all_dataframes.append(export_df)

                if all_dataframes:
                    
                    ax.set_title(f"PL spectrum (Center wavelength: {center_wavelength_input} nm)")
                    ax.set_xlabel("wavelength [nm]"); ax.set_ylabel("PL intensity")
                    ax.legend(loc='upper left', frameon=False, fontsize=10)
                    ax.grid(axis='y', linestyle='-', color='lightgray', zorder=0)
                    ax.tick_params(direction='in', top=True, right=True, which='both')
                    
                    min_wl = min(df['wavelength_nm'].min() for df in all_dataframes)
                    max_wl = max(df['wavelength_nm'].max() for df in all_dataframes)
                    padding = (max_wl - min_wl) * 0.05
                    ax.set_xlim(min_wl - padding, max_wl + padding)
                    
                    # â˜…ä¿®æ­£: use_container_width=Trueã§å¹…ã‚’åºƒã’ã‚‹
                    st.pyplot(fig, use_container_width=True) 
                    
                    output = BytesIO()
                    # ãƒ‡ãƒ¼ã‚¿çµåˆã‚’ã›ãšã€å€‹åˆ¥ã®DataFrameã‚’ã‚·ãƒ¼ãƒˆã¨ã—ã¦æ›¸ãå‡ºã™ (å‰å›ã®PLãƒ­ã‚¸ãƒƒã‚¯ã®ã¾ã¾)
                    with pd.ExcelWriter(output, engine='openpyxl') as writer:
                        for export_df in all_dataframes:
                            sheet_name_full = export_df.columns[1].replace('intensity (', '').replace(')', '').strip()
                            sheet_name = sheet_name_full[:31] 
                            
                            df_to_write = export_df.copy()
                            df_to_write.columns = ['wavelength_nm', 'intensity']
                            df_to_write.to_excel(writer, index=False, sheet_name=sheet_name)

                    processed_data = output.getvalue()
                    st.download_button(label="ğŸ“ˆ Excelãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=processed_data, file_name=f"pl_analysis_combined_{center_wavelength_input}nm.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
                else:
                    st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# --- IVãƒ‡ãƒ¼ã‚¿è§£æãƒšãƒ¼ã‚¸ (å†ã€…ä¿®æ­£æ¸ˆã¿ - å˜ä¸€ã‚·ãƒ¼ãƒˆçµåˆ) ---
def page_iv_analysis():
    st.header("âš¡ IVãƒ‡ãƒ¼ã‚¿è§£æ")
    st.write("è¤‡æ•°ã®é›»æµ-é›»åœ§ (IV) ç‰¹æ€§ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ—ãƒ­ãƒƒãƒˆã—ã€**ä¸€ã¤ã®Excelã‚·ãƒ¼ãƒˆã«çµåˆ**ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
    st.info("ğŸ’¡ å‡¦ç†è² è·è»½æ¸›ã®ãŸã‚ã€ä¸€åº¦ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã¯æœ€å¤§10å€‹ç¨‹åº¦ã«æŠ‘ãˆã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚")


    with st.container(border=True):
        uploaded_files = st.file_uploader(
            "IVæ¸¬å®šãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
            type=['txt', 'csv'],
            accept_multiple_files=True
        )

        if uploaded_files:
            st.subheader("è§£æçµæœ")
            
            # â˜…ã‚°ãƒ©ãƒ•ã‚µã‚¤ã‚ºã‚’å¤§ããã™ã‚‹
            fig, ax = plt.subplots(figsize=(12, 7))
            
            all_dfs = [] # èª­ã¿è¾¼ã‚“ã å…¨ã¦ã®DataFrameã‚’æ ¼ç´
            
            # 1. å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ãƒªã‚¹ãƒˆã«æ ¼ç´
            for uploaded_file in uploaded_files:
                df = load_iv_data(uploaded_file)
                
                if df is not None:
                    base_name = os.pathin.splitext(uploaded_file.name)[0]
                    label = base_name
                    
                    # ã‚°ãƒ©ãƒ•æç”»
                    ax.plot(df['Voltage_V'], df['Current_A'], label=label, linewidth=2.5)
                    
                    # Excelçµåˆç”¨ã«åˆ—åã‚’å¤‰æ›´
                    df_to_merge = df.rename(columns={'Current_A': f"Current_A ({base_name})"})
                    all_dfs.append(df_to_merge)

            if all_dfs:
                
                # 2. ãƒ‡ãƒ¼ã‚¿çµåˆå‡¦ç† (ã‚¯ãƒ©ãƒƒã‚·ãƒ¥å¯¾ç­–ã®æœ€é©åŒ–)
                with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆä¸­...ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«æ•°ãŒå¤šã„ã¨æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã™ï¼‰"):
                    # æœ€åˆã®DataFrameã‚’åŸºæº–ã¨ã™ã‚‹
                    final_df = all_dfs[0]
                    
                    # 2ç•ªç›®ä»¥é™ã®DataFrameã‚’é †ç•ªã«ãƒãƒ¼ã‚¸
                    for i in range(1, len(all_dfs)):
                        # 'Voltage_V' ã‚’ã‚­ãƒ¼ã«å¤–éƒ¨çµåˆ (outer join) ã‚’å®Ÿè¡Œ
                        final_df = pd.merge(final_df, all_dfs[i], on='Voltage_V', how='outer')
                        
                # ãƒãƒ¼ã‚¸å¾Œã®ãƒ‡ãƒ¼ã‚¿ã§Voltage_Vã‚’ã‚½ãƒ¼ãƒˆ
                final_df.sort_values(by='Voltage_V', inplace=True)
                
                # 3. ã‚°ãƒ©ãƒ•æç”»ã®èª¿æ•´
                ax.set_title("IV Characteristic")
                ax.set_xlabel("Voltage [V]"); ax.set_ylabel("Current [A]")
                ax.legend(loc='best', frameon=True, fontsize=10)
                ax.grid(axis='both', linestyle='--', color='lightgray', zorder=0)
                ax.axhline(0, color='black', linestyle='-', linewidth=1.0, zorder=1)
                ax.axvline(0, color='black', linestyle='-', linewidth=1.0, zorder=1)
                
                # â˜…ä¿®æ­£: use_container_width=Trueã§å¹…ã‚’åºƒã’ã‚‹
                st.pyplot(fig, use_container_width=True)
                
                # 4. Excelå‡ºåŠ› (å˜ä¸€ã‚·ãƒ¼ãƒˆ)
                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    # æœ€åˆã®ã‚·ãƒ¼ãƒˆã«çµåˆã—ãŸå…¨ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›
                    final_df.to_excel(writer, index=False, sheet_name="Combined_IV_Data")

                processed_data = output.getvalue()
                st.download_button(
                    label="ğŸ“ˆ çµåˆExcelãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=processed_data,
                    file_name=f"iv_analysis_combined_{datetime.now().strftime('%Y%m%d')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                st.warning("æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# ... (page_trouble_report, main é–¢æ•°ã¯çœç•¥ã€‚å¤‰æ›´ãªã—) ...
